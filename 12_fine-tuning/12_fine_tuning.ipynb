{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ LLM Fine-Tuning: Modern Approaches and When to Use Them\n",
    "\n",
    "Welcome to the comprehensive guide on fine-tuning Large Language Models!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "1. **Understand the modern philosophy** of fine-tuning (what changed and why)\n",
    "2. **Master three fine-tuning approaches:**\n",
    "   - **Supervised Fine-Tuning (SFT)** - Traditional approach for teaching formats and styles\n",
    "   - **Preference-Based Fine-Tuning** - Learning from comparisons and rankings\n",
    "   - **Reinforcement Learning from Human Feedback (RLHF)** - Advanced behavioral alignment\n",
    "3. **Calculate costs** and understand economic trade-offs\n",
    "4. **Make informed decisions** about which approach to use for your use case\n",
    "5. **Prepare datasets** appropriate for each method\n",
    "6. **Evaluate results** with proper metrics\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important Note About This Notebook\n",
    "\n",
    "**This notebook is primarily educational and will NOT execute actual fine-tuning.**\n",
    "\n",
    "Why?\n",
    "- Fine-tuning is **expensive** (can cost hundreds to thousands of dollars)\n",
    "- It requires significant compute time (hours to days)\n",
    "- Mock datasets are used for illustration purposes\n",
    "\n",
    "**What you WILL get:**\n",
    "- ‚úÖ Complete code examples showing how to fine-tune on OpenAI's platform\n",
    "- ‚úÖ Mock datasets demonstrating proper data formatting\n",
    "- ‚úÖ Cost calculations and economic analysis\n",
    "- ‚úÖ Decision frameworks for choosing approaches\n",
    "- ‚úÖ Best practices and evaluation strategies\n",
    "\n",
    "**What you WON'T do:**\n",
    "- ‚ùå Actually train models (too expensive for a tutorial)\n",
    "- ‚ùå Use real API keys for fine-tuning\n",
    "- ‚ùå Wait hours for training to complete\n",
    "\n",
    "Think of this as a **comprehensive blueprint** - when you're ready to fine-tune for real, you'll know exactly what to do!\n",
    "\n",
    "---\n",
    "\n",
    "## üó∫Ô∏è Tutorial Structure\n",
    "\n",
    "**Part 1:** Introduction & Modern Philosophy (15-20 min)\n",
    "\n",
    "**Part 2:** Cost Understanding (10 min)\n",
    "\n",
    "**Part 3:** Supervised Fine-Tuning (SFT) - 30 min\n",
    "\n",
    "**Part 4:** Preference-Based Fine-Tuning - 30 min\n",
    "\n",
    "**Part 5:** RLHF - 30 min\n",
    "\n",
    "**Part 6:** Decision Framework - 20 min\n",
    "\n",
    "**Part 7:** Best Practices & Evaluation - 15 min\n",
    "\n",
    "**Part 8:** Summary & Resources - 10 min\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: The Paradigm Shift in Fine-Tuning\n",
    "\n",
    "## üîÑ The Old Approach vs. The New Approach\n",
    "\n",
    "### The Old Days (2018-2020)\n",
    "\n",
    "**The Problem:**\n",
    "- Base models (BERT, GPT-2) had limited general knowledge\n",
    "- Needed fine-tuning to teach them domain-specific facts\n",
    "- Fine-tuning was about **adding knowledge**\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "‚ùå Base GPT-2: \"What is Kubernetes?\" ‚Üí Confused or wrong answer\n",
    "‚úÖ Fine-tuned GPT-2: Train on DevOps docs ‚Üí Now knows Kubernetes\n",
    "```\n",
    "\n",
    "### The Modern Era (2023+)\n",
    "\n",
    "**The Revolution:**\n",
    "- Modern LLMs (GPT-4, Claude, Gemini) are trained on massive datasets\n",
    "- They **already know** most facts, concepts, and domains\n",
    "- Fine-tuning is now about **behavior, style, and format**\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "‚úÖ GPT-4: \"What is Kubernetes?\" ‚Üí Already knows perfectly well\n",
    "üéØ Fine-tuned GPT-4: Make it respond in your company's specific tone, \n",
    "                      format output as JSON, follow brand guidelines\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What Fine-Tuning IS Good For (Modern Use Cases)\n",
    "\n",
    "### 1. **Teaching Output Format**\n",
    "- **Problem:** Need consistent JSON structure, specific field names\n",
    "- **Solution:** Fine-tune on examples of perfect formatting\n",
    "- **Example:** Extract invoice data ‚Üí always output same JSON schema\n",
    "\n",
    "### 2. **Establishing Brand Voice/Style**\n",
    "- **Problem:** Company has specific tone (formal, casual, technical)\n",
    "- **Solution:** Fine-tune on company's approved responses\n",
    "- **Example:** Customer service chatbot matching brand personality\n",
    "\n",
    "### 3. **Following Internal Guidelines**\n",
    "- **Problem:** Company has specific policies, templates, procedures\n",
    "- **Solution:** Fine-tune on examples following these rules\n",
    "- **Example:** Medical advice bot following clinical protocols\n",
    "\n",
    "### 4. **Consistent Edge Case Handling**\n",
    "- **Problem:** Model should refuse certain requests in specific ways\n",
    "- **Solution:** Fine-tune on examples of proper refusals\n",
    "- **Example:** Financial advisor bot declining legal advice politely\n",
    "\n",
    "### 5. **Reducing Latency + Cost (Post-Distillation)**\n",
    "- **Problem:** GPT-4 is expensive and slow\n",
    "- **Solution:** Fine-tune smaller model (gpt-5-nano) on GPT-4 outputs\n",
    "- **Example:** Customer service with 10x lower costs, 5x faster\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå What Fine-Tuning IS NOT Good For\n",
    "\n",
    "### 1. **Teaching New Knowledge/Facts**\n",
    "- **Why:** Modern LLMs already know most information\n",
    "- **Better approach:** Use RAG (Retrieval Augmented Generation)\n",
    "- **Example:** Instead of fine-tuning on company docs, use RAG to retrieve relevant sections\n",
    "\n",
    "**Why RAG beats fine-tuning for knowledge:**\n",
    "- ‚úÖ Updates in real-time (no retraining needed)\n",
    "- ‚úÖ Cheaper (no training costs)\n",
    "- ‚úÖ Explainable (shows sources)\n",
    "- ‚úÖ Handles changing information better\n",
    "\n",
    "### 2. **Making Model \"Smarter\"**\n",
    "- **Why:** You can't fine-tune a small model to match GPT-4's reasoning\n",
    "- **Reality:** Fine-tuning teaches patterns, not intelligence\n",
    "- **Example:** Can't make gpt-3.5 reason like GPT-4 through fine-tuning\n",
    "\n",
    "### 3. **Fixing Fundamental Model Limitations**\n",
    "- **Why:** Fine-tuning doesn't change core capabilities\n",
    "- **Better approach:** Use a better base model\n",
    "- **Example:** If model can't do math, fine-tuning won't help ‚Üí use tool calling instead\n",
    "\n",
    "### 4. **Reducing Hallucinations Significantly**\n",
    "- **Why:** Fine-tuning can actually increase hallucinations\n",
    "- **Reality:** Fine-tuning teaches confidence, which can worsen false claims\n",
    "- **Better approach:** Use RAG, citations, temperature tuning\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ The Golden Rule of Modern Fine-Tuning\n",
    "\n",
    "**Ask yourself:**\n",
    "\n",
    "> *\"Could I solve this with better prompts, RAG, or tool calling?\"*\n",
    "\n",
    "**If YES ‚Üí Don't fine-tune yet!**\n",
    "\n",
    "**If NO ‚Üí Fine-tuning might be worth it**\n",
    "\n",
    "### Decision Hierarchy (Try in Order):\n",
    "\n",
    "1. **Prompt Engineering** (minutes, free)\n",
    "   - Costs: $0\n",
    "   - Time: Minutes\n",
    "   - Example: Clear instructions, few-shot examples\n",
    "\n",
    "2. **RAG for Knowledge** (hours, low cost)\n",
    "   - Costs: $50-500 setup\n",
    "   - Time: Hours to days\n",
    "   - Example: Vector database + retrieval\n",
    "\n",
    "3. **Tool Calling for Accuracy** (days, medium cost)\n",
    "   - Costs: $100-1000 setup\n",
    "   - Time: Days to weeks\n",
    "   - Example: Calculator, search, database queries\n",
    "\n",
    "4. **Fine-Tuning for Behavior** (weeks, high cost)\n",
    "   - Costs: $500-10,000+\n",
    "   - Time: Weeks to months\n",
    "   - Example: Brand voice, output format, style\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Real-World Success Example\n",
    "\n",
    "**Company:** E-commerce customer support\n",
    "\n",
    "**Initial idea:** \"Let's fine-tune on all our product docs!\"\n",
    "\n",
    "**What they actually did:**\n",
    "1. **Prompt engineering** ‚Üí Got 60% success rate (1 day)\n",
    "2. **Added RAG** ‚Üí 85% success rate (1 week, $200 cost)\n",
    "3. **Added tool calling** ‚Üí 92% success rate (2 weeks, $500 cost)\n",
    "4. **Fine-tuned for tone** ‚Üí 95% success rate (4 weeks, $2000 cost)\n",
    "\n",
    "**Lesson:** Fine-tuning was the **final 3% improvement**, not the first step!\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ The Three Modern Fine-Tuning Approaches\n",
    "\n",
    "Now that you understand **when** to fine-tune, let's learn **how**.\n",
    "\n",
    "### 1. Supervised Fine-Tuning (SFT)\n",
    "- **Teaching:** \"Here are perfect examples, copy this pattern\"\n",
    "- **Data:** Input-output pairs showing desired behavior\n",
    "- **Use case:** Consistent formatting, style, structure\n",
    "- **Complexity:** ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (Easiest)\n",
    "\n",
    "### 2. Preference-Based Fine-Tuning\n",
    "- **Teaching:** \"Response A is better than Response B\"\n",
    "- **Data:** Pairs of outputs with quality rankings\n",
    "- **Use case:** Subjective quality, tone, helpfulness\n",
    "- **Complexity:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (Medium)\n",
    "\n",
    "### 3. RLHF (Reinforcement Learning from Human Feedback)\n",
    "- **Teaching:** \"Here's a reward score across multiple dimensions\"\n",
    "- **Data:** Outputs with multi-dimensional quality scores\n",
    "- **Use case:** Complex quality with multiple criteria\n",
    "- **Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Advanced)\n",
    "\n",
    "---\n",
    "\n",
    "Let's explore each approach in depth! üìñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Understanding Costs\n",
    "\n",
    "Before diving into techniques, let's understand the **economic reality** of fine-tuning.\n",
    "\n",
    "## üí∞ Two Types of Costs\n",
    "\n",
    "### 1. Training Cost (One-Time)\n",
    "- Pay per token during training\n",
    "- Depends on: dataset size, number of epochs, model size\n",
    "- **This is visible and obvious**\n",
    "\n",
    "### 2. Inference Cost (Ongoing)\n",
    "- Fine-tuned models cost MORE per token than base models\n",
    "- For high-volume applications, this adds up quickly\n",
    "- **This is hidden and often forgotten!**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä OpenAI Pricing (gpt-5-nano)\n",
    "\n",
    "### Training Costs:\n",
    "- **Input tokens:** $0.10 per 1M tokens\n",
    "- **Output tokens:** $0.80 per 1M tokens\n",
    "- *Note: You're charged for BOTH user prompts AND assistant responses in your training data*\n",
    "\n",
    "### Inference Costs:\n",
    "- **Base gpt-5-nano:**\n",
    "  - Input: $0.05 / 1M tokens\n",
    "  - Output: $0.40 / 1M tokens\n",
    "  \n",
    "- **Fine-tuned gpt-5-nano:**\n",
    "  - Input: $0.15 / 1M tokens (3x more!)\n",
    "  - Output: $1.20 / 1M tokens (3x more!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Calculator Function\n",
    "\n",
    "def calculate_finetuning_costs(\n",
    "    num_examples: int,\n",
    "    avg_tokens_per_example: int,\n",
    "    epochs: int = 3,\n",
    "    model: str = \"gpt-5-nano\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the costs of fine-tuning a model on OpenAI's platform.\n",
    "    \n",
    "    Args:\n",
    "        num_examples: Number of training examples\n",
    "        avg_tokens_per_example: Average tokens per example (input + output combined)\n",
    "        epochs: Number of training epochs (default: 3)\n",
    "        model: Model to fine-tune (only gpt-5-nano supported in this example)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with cost breakdown\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pricing for gpt-5-nano (as of 2025)\n",
    "    if model == \"gpt-5-nano\":\n",
    "        # Training costs (per 1M tokens)\n",
    "        training_cost_per_1m = 0.10  # Simplified: average of input (0.10) and output (0.80)\n",
    "        \n",
    "        # Inference costs (per 1M tokens)\n",
    "        base_inference_cost = 0.225  # Average of input (0.05) and output (0.40)\n",
    "        finetuned_inference_cost = 0.675  # Average of input (0.15) and output (1.20)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model} not supported in this example\")\n",
    "    \n",
    "    # Calculate training costs\n",
    "    total_training_tokens = num_examples * avg_tokens_per_example * epochs\n",
    "    training_cost = (total_training_tokens / 1_000_000) * training_cost_per_1m\n",
    "    \n",
    "    # Calculate inference cost difference (for 1 million requests)\n",
    "    # Assuming each inference uses similar token count\n",
    "    inference_requests = 1_000_000  # 1 million requests for comparison\n",
    "    total_inference_tokens = inference_requests * avg_tokens_per_example\n",
    "    \n",
    "    base_inference_total = (total_inference_tokens / 1_000_000) * base_inference_cost\n",
    "    finetuned_inference_total = (total_inference_tokens / 1_000_000) * finetuned_inference_cost\n",
    "    inference_cost_increase = finetuned_inference_total - base_inference_total\n",
    "    \n",
    "    # Calculate break-even point\n",
    "    # How many requests until inference costs exceed training savings?\n",
    "    cost_per_request_increase = (finetuned_inference_cost - base_inference_cost) * (avg_tokens_per_example / 1_000_000)\n",
    "    break_even_requests = training_cost / cost_per_request_increase if cost_per_request_increase > 0 else float('inf')\n",
    "    \n",
    "    return {\n",
    "        \"training_cost\": round(training_cost, 2),\n",
    "        \"total_training_tokens\": total_training_tokens,\n",
    "        \"base_inference_cost_per_1m_requests\": round(base_inference_total, 2),\n",
    "        \"finetuned_inference_cost_per_1m_requests\": round(finetuned_inference_total, 2),\n",
    "        \"inference_cost_increase_per_1m_requests\": round(inference_cost_increase, 2),\n",
    "        \"break_even_requests\": int(break_even_requests) if break_even_requests != float('inf') else \"N/A\",\n",
    "        \"cost_per_example\": round(training_cost / num_examples, 4)\n",
    "    }\n",
    "\n",
    "def print_cost_analysis(results: dict, num_examples: int):\n",
    "    \"\"\"\n",
    "    Pretty print cost analysis results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üí∞ COST ANALYSIS: {num_examples:,} Training Examples\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    print(f\"üîß TRAINING COSTS (One-Time)\")\n",
    "    print(f\"   Total cost: ${results['training_cost']:,.2f}\")\n",
    "    print(f\"   Cost per example: ${results['cost_per_example']:.4f}\")\n",
    "    print(f\"   Total tokens processed: {results['total_training_tokens']:,}\\n\")\n",
    "    \n",
    "    print(f\"üìä INFERENCE COSTS (Per 1M Requests)\")\n",
    "    print(f\"   Base model: ${results['base_inference_cost_per_1m_requests']:,.2f}\")\n",
    "    print(f\"   Fine-tuned model: ${results['finetuned_inference_cost_per_1m_requests']:,.2f}\")\n",
    "    print(f\"   Additional cost: ${results['inference_cost_increase_per_1m_requests']:,.2f} (‚¨ÜÔ∏è {((results['finetuned_inference_cost_per_1m_requests'] / results['base_inference_cost_per_1m_requests']) - 1) * 100:.0f}%)\\n\")\n",
    "    \n",
    "    print(f\"‚öñÔ∏è BREAK-EVEN ANALYSIS\")\n",
    "    if results['break_even_requests'] != \"N/A\":\n",
    "        print(f\"   Break-even at: {results['break_even_requests']:,} requests\")\n",
    "        print(f\"   After this point, inference costs exceed training costs!\\n\")\n",
    "    else:\n",
    "        print(f\"   Break-even: Not applicable\\n\")\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "print(\"‚úÖ Cost calculator functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Let's Calculate Real Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Small fine-tuning project (100 examples)\n",
    "print(\"\\nüìù Scenario 1: Small Project (Quick Experiment)\")\n",
    "print(\"   Use case: Testing if fine-tuning helps with your use case\")\n",
    "print(\"   Dataset: 100 examples, ~500 tokens each\")\n",
    "\n",
    "results_small = calculate_finetuning_costs(\n",
    "    num_examples=100,\n",
    "    avg_tokens_per_example=500,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_small, 100)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚úÖ Low training cost - good for experimentation\")\n",
    "print(\"   ‚ö†Ô∏è May not be enough data for significant improvement\")\n",
    "print(\"   ‚úÖ Quick to iterate if results aren't good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Medium fine-tuning project (500 examples)\n",
    "print(\"\\nüìù Scenario 2: Medium Project (Standard Production)\")\n",
    "print(\"   Use case: Customer service chatbot with brand voice\")\n",
    "print(\"   Dataset: 500 examples, ~400 tokens each\")\n",
    "\n",
    "results_medium = calculate_finetuning_costs(\n",
    "    num_examples=500,\n",
    "    avg_tokens_per_example=400,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_medium, 500)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚úÖ Balanced cost-benefit ratio\")\n",
    "print(\"   ‚úÖ Usually sufficient for style/format learning\")\n",
    "print(\"   ‚ö†Ô∏è Inference costs start adding up at scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Large fine-tuning project (1000 examples)\n",
    "print(\"\\nüìù Scenario 3: Large Project (Comprehensive)\")\n",
    "print(\"   Use case: Multi-domain chatbot with complex behaviors\")\n",
    "print(\"   Dataset: 1000 examples, ~600 tokens each\")\n",
    "\n",
    "results_large = calculate_finetuning_costs(\n",
    "    num_examples=1000,\n",
    "    avg_tokens_per_example=600,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_large, 1000)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚ö†Ô∏è Significant upfront investment\")\n",
    "print(\"   ‚úÖ High-quality results expected\")\n",
    "print(\"   ‚ö†Ô∏è Inference costs become major factor at scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 4: Enterprise fine-tuning (5000 examples)\n",
    "print(\"\\nüìù Scenario 4: Enterprise Project (Maximum Quality)\")\n",
    "print(\"   Use case: Mission-critical application with strict requirements\")\n",
    "print(\"   Dataset: 5000 examples, ~500 tokens each\")\n",
    "\n",
    "results_enterprise = calculate_finetuning_costs(\n",
    "    num_examples=5000,\n",
    "    avg_tokens_per_example=500,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_enterprise, 5000)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚ö†Ô∏è Very expensive - ensure this is necessary!\")\n",
    "print(\"   ‚ö†Ô∏è Consider if prompt engineering + RAG could work instead\")\n",
    "print(\"   ‚ö†Ô∏è Inference costs will be substantial - budget accordingly\")\n",
    "print(\"   ‚úÖ Only justified for high-value, high-volume applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Cost Insights\n",
    "\n",
    "### 1. **Training costs scale linearly**\n",
    "- 2x examples = 2x cost\n",
    "- BUT: Diminishing returns on quality!\n",
    "- Sweet spot: Usually 500-1500 examples\n",
    "\n",
    "### 2. **Inference costs are ongoing**\n",
    "- Fine-tuned models cost 3x more per request\n",
    "- At high volume, this exceeds training costs\n",
    "- **Critical consideration:** Calculate your expected volume!\n",
    "\n",
    "### 3. **Quality vs. Quantity trade-off**\n",
    "- 100 high-quality examples > 1000 mediocre examples\n",
    "- Focus on data quality, not just quantity\n",
    "- Manual curation is worth the effort\n",
    "\n",
    "### 4. **The Total Cost of Ownership**\n",
    "\n",
    "**Example:** Customer service chatbot\n",
    "- Training: $18 (one-time)\n",
    "- Inference (1M requests/month): $270/month extra cost\n",
    "- Annual cost: $18 + ($270 √ó 12) = $3,258\n",
    "\n",
    "**Question to ask:** *Is the improved performance worth $3,258/year?*\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Cost Optimization Strategies\n",
    "\n",
    "### Strategy 1: Start Small\n",
    "```\n",
    "100 examples ‚Üí Test ‚Üí Works? ‚Üí Add 400 more ‚Üí Evaluate\n",
    "```\n",
    "\n",
    "### Strategy 2: Distillation Path\n",
    "```\n",
    "1. Use GPT-4 for quality\n",
    "2. Generate many outputs\n",
    "3. Fine-tune gpt-5-nano on GPT-4 outputs\n",
    "4. Get 80% of quality at 10% of cost\n",
    "```\n",
    "\n",
    "### Strategy 3: Hybrid Approach\n",
    "```\n",
    "Fine-tune for format ‚Üí Use base model with RAG for knowledge\n",
    "```\n",
    "\n",
    "### Strategy 4: Batch Processing\n",
    "```\n",
    "Non-urgent requests ‚Üí Process in batches ‚Üí 50% cost reduction\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** The cheapest fine-tuning is the one you don't need to do!\n",
    "\n",
    "Always exhaust prompt engineering and RAG before considering fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Supervised Fine-Tuning (SFT)\n",
    "\n",
    "## üìñ What is Supervised Fine-Tuning?\n",
    "\n",
    "**Supervised Fine-Tuning (SFT)** is the most straightforward fine-tuning approach:\n",
    "\n",
    "**Core Concept:**\n",
    "> \"Here are perfect examples of inputs and their ideal outputs. Learn to copy this pattern.\"\n",
    "\n",
    "**How it works:**\n",
    "1. Provide pairs of (input ‚Üí desired output)\n",
    "2. Model learns to predict outputs given inputs\n",
    "3. Model adjusts weights to minimize difference between its output and your examples\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Technical Deep Dive\n",
    "\n",
    "**Training Process:**\n",
    "```\n",
    "For each example in dataset:\n",
    "    1. Model sees: \"User: How do I reset my password?\"\n",
    "    2. Model generates: \"Click on forgot password...\"\n",
    "    3. Compare to your example: \"Here's how to reset your password: 1) Click...\"\n",
    "    4. Calculate loss (difference)\n",
    "    5. Update model weights to reduce this difference\n",
    "    6. Repeat thousands of times\n",
    "```\n",
    "\n",
    "**What the model learns:**\n",
    "- **Patterns in format:** If all examples use JSON ‚Üí model outputs JSON\n",
    "- **Consistency in style:** If all examples are formal ‚Üí model becomes formal\n",
    "- **Specific phrasings:** If all examples start with \"Here's how\" ‚Üí model copies this\n",
    "- **Edge case handling:** If examples show refusals ‚Üí model learns when to refuse\n",
    "\n",
    "**What the model does NOT learn:**\n",
    "- ‚ùå New facts (use RAG instead)\n",
    "- ‚ùå Better reasoning (use better base model)\n",
    "- ‚ùå External knowledge (use tools/APIs)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ When to Use SFT\n",
    "\n",
    "### Perfect for:\n",
    "1. **Consistent output formatting** (JSON schemas, XML, structured data)\n",
    "2. **Brand voice enforcement** (specific tone, emoji usage, greetings)\n",
    "3. **Template following** (company-specific response structures)\n",
    "4. **Code style compliance** (naming conventions, documentation patterns)\n",
    "5. **Reducing latency** (distilling larger model behavior into smaller model)\n",
    "\n",
    "### Signs SFT is right:\n",
    "- ‚úÖ You have clear \"right answers\" or \"correct formats\"\n",
    "- ‚úÖ Consistency is more important than creativity\n",
    "- ‚úÖ You can describe success objectively\n",
    "- ‚úÖ Prompt engineering gets close but not reliable enough\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå When NOT to Use SFT\n",
    "\n",
    "### Bad for:\n",
    "1. **Teaching new information** ‚Üí Use RAG\n",
    "2. **Subjective quality improvements** ‚Üí Use preference-based tuning\n",
    "3. **Complex multi-objective optimization** ‚Üí Use RLHF\n",
    "4. **Fixing hallucinations** ‚Üí Won't work, may make it worse\n",
    "\n",
    "### Signs SFT is wrong:\n",
    "- ‚ùå You need to update knowledge frequently\n",
    "- ‚ùå \"Better\" is subjective and varies by context\n",
    "- ‚ùå You want model to be \"smarter\"\n",
    "- ‚ùå You don't have clear examples of correct behavior\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Requirements\n",
    "\n",
    "**Minimum viable:** 50-100 examples\n",
    "- Good for: Testing if fine-tuning helps\n",
    "- Quality: May be inconsistent\n",
    "\n",
    "**Recommended:** 500-1000 examples\n",
    "- Good for: Production use\n",
    "- Quality: Reliable and consistent\n",
    "\n",
    "**Maximum useful:** 5000-10,000 examples\n",
    "- Good for: Complex behaviors, multiple patterns\n",
    "- Quality: Diminishing returns above this\n",
    "\n",
    "**Data quality > Data quantity**\n",
    "- 100 perfect examples > 1000 mediocre examples\n",
    "- Consistency is critical\n",
    "- Remove outliers and errors\n",
    "\n",
    "---\n",
    "\n",
    "Let's see SFT in action with three real-world use cases! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíº SFT Use Case #1: Customer Service Brand Voice\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Hip e-commerce startup targeting Gen Z\n",
    "- Problem: Generic AI responses don't match brand personality\n",
    "- Goal: Every response should feel on-brand (casual, emoji-friendly, empathetic)\n",
    "\n",
    "**Why SFT?**\n",
    "- ‚úÖ Clear pattern to copy (brand voice guidelines)\n",
    "- ‚úÖ Consistency is key (all responses should feel similar)\n",
    "- ‚úÖ Prompt engineering gets close but drifts over time\n",
    "\n",
    "**What we're teaching:**\n",
    "- Tone (casual but professional)\n",
    "- Emoji usage (tasteful, not excessive)\n",
    "- Greeting/closing patterns\n",
    "- Empathy expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mock Dataset: Customer Service Brand Voice\n",
    "# This shows the EXACT format OpenAI expects for SFT\n",
    "\n",
    "sft_customer_service_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"My order hasn't arrived yet and it's been 5 days. I'm getting worried.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Oh no, I totally get why you're worried! üòü Let me look into this for you right away.\\n\\nI've checked your order #TT-12847 and I can see it's currently with our shipping partner. It looks like there was a small delay at the distribution center, but the good news is it's already on its way to you! üì¶\\n\\nYou should receive it within the next 2 business days. To make up for the wait, I'm adding a 15% discount code to your account (code: SORRY15) for your next purchase.\\n\\nIs there anything else I can help you with today? üíô\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"The hoodie I received is the wrong size. Can I return it?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Ah, sizing issues are the worst! üòÖ Don't worry though, we've got you covered.\\n\\nYes, absolutely! You can return it within 30 days for a full refund or exchange. Here's the super easy process:\\n\\n1Ô∏è‚É£ Go to our website ‚Üí Your Orders ‚Üí Select this hoodie\\n2Ô∏è‚É£ Click \\\"Return or Exchange\\\"\\n3Ô∏è‚É£ Print the prepaid shipping label\\n4Ô∏è‚É£ Drop it off at any post office\\n\\nWe'll send you the correct size as soon as we receive your return! Usually takes about 5-7 days total.\\n\\nNeed any help with the process or have questions about sizing? I'm here! ‚ú®\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Do you have this jacket in blue?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Great question! üíô Let me check that for you.\\n\\nYes! The CloudFlex Jacket is available in Ocean Blue in sizes XS-XL. It's actually one of our most popular colors this season!\\n\\nWould you like me to send you a direct link? Or I can help you add it to your cart right now! üõçÔ∏è\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I got charged twice for the same order! This is unacceptable.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Oh wow, that's definitely not okay! üòü I'm really sorry this happened - let me fix this immediately.\\n\\nI've checked your account and you're right - there was a duplicate charge of $67.99. This was a processing error on our end, and I've already initiated a refund for the duplicate charge. You should see it back in your account within 3-5 business days depending on your bank.\\n\\nAs an apology for this hassle, I'm also crediting your account with $15 store credit (already applied!).\\n\\nI've flagged this issue with our payment team to make sure it doesn't happen again. Is there anything else I can do to make this right? üíô\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Thanks for helping me with my return!\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"You're so welcome! üåü Happy to help anytime!\\n\\nIf you need anything else or have questions when your exchange arrives, just reach out. We're always here for you! üíô\\n\\nHave an awesome day! ‚ú®\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display as a readable format\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíº SFT USE CASE #1: Customer Service Brand Voice\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(sft_customer_service_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "    \n",
    "    messages = example[\"messages\"]\n",
    "    \n",
    "    # Skip system message in display (but it's included in training)\n",
    "    for msg in messages:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            print(f\"üë§ USER:\\n{msg['content']}\\n\")\n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            print(f\"ü§ñ ASSISTANT:\\n{msg['content']}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS FROM THESE EXAMPLES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Tone & Voice:**\n",
    "   - Casual but professional (\\\"Let me check that for you\\\")\n",
    "   - Empathetic acknowledgment (\\\"I totally get why you're worried\\\")\n",
    "   - Positive language (\\\"good news\\\", \\\"Great question!\\\")\n",
    "\n",
    "2. **Emoji Usage:**\n",
    "   - 1-3 emojis per response (not excessive)\n",
    "   - Contextually appropriate (üòü for problems, üíô for warmth)\n",
    "   - Enhances feeling, doesn't replace words\n",
    "\n",
    "3. **Structure:**\n",
    "   - Acknowledge emotion/issue first\n",
    "   - Provide solution or information\n",
    "   - Offer additional help\n",
    "   - Warm closing\n",
    "\n",
    "4. **Problem Handling:**\n",
    "   - Immediate apology when appropriate\n",
    "   - Take ownership (\\\"I've already initiated...\\\")\n",
    "   - Offer compensation for errors\n",
    "   - Follow up question\n",
    "\n",
    "5. **Consistency:**\n",
    "   - Always ends with warmth\n",
    "   - Uses \\\"we/us\\\" for brand\n",
    "   - Balances friendliness with professionalism\n",
    "   - Never dismissive or robotic\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚ö†Ô∏è IMPORTANT: These examples show CONSISTENT patterns!\")\n",
    "print(\"   The model learns from repetition across many examples.\")\n",
    "print(\"   In production, you'd need 500-1000 examples like these.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä SFT Use Case #2: Structured JSON Output\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Invoice processing automation\n",
    "- Problem: Need to extract data from invoices into exact JSON schema\n",
    "- Goal: 100% consistent JSON format, specific field names, proper data types\n",
    "\n",
    "**Why SFT?**\n",
    "- ‚úÖ Exact format requirements (can't vary)\n",
    "- ‚úÖ Prompt engineering gets 80% right, but 20% have format errors\n",
    "- ‚úÖ Even with structured outputs, need specific business field names\n",
    "- ‚úÖ Need consistent handling of edge cases (missing data, unclear amounts)\n",
    "\n",
    "**What we're teaching:**\n",
    "- Exact JSON schema\n",
    "- Field naming conventions\n",
    "- Data type consistency\n",
    "- Null handling for missing data\n",
    "- Edge case patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Dataset: Structured JSON Output for Invoice Extraction\n",
    "\n",
    "sft_json_extraction_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"INVOICE\\n\\nInvoice #: INV-2024-001\\nDate: January 15, 2024\\n\\nFrom:\\nTech Supplies Inc.\\n123 Silicon Valley Rd, San Jose, CA 95110\\n\\nLine Items:\\n- Dell Monitor 27\\\" x 5 @ $299.99 = $1,499.95\\n- USB-C Cable x 10 @ $12.99 = $129.90\\n- Wireless Mouse x 5 @ $34.99 = $174.95\\n\\nSubtotal: $1,804.80\\nTax (8.5%): $153.41\\nTotal: $1,958.21\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"INV-2024-001\\\",\\n  \\\"invoice_date\\\": \\\"2024-01-15\\\",\\n  \\\"vendor_name\\\": \\\"Tech Supplies Inc.\\\",\\n  \\\"vendor_address\\\": \\\"123 Silicon Valley Rd, San Jose, CA 95110\\\",\\n  \\\"total_amount\\\": 1958.21,\\n  \\\"tax_amount\\\": 153.41,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Dell Monitor 27\\\\\\\"\\\",\\n      \\\"quantity\\\": 5,\\n      \\\"unit_price\\\": 299.99,\\n      \\\"total_price\\\": 1499.95\\n    },\\n    {\\n      \\\"description\\\": \\\"USB-C Cable\\\",\\n      \\\"quantity\\\": 10,\\n      \\\"unit_price\\\": 12.99,\\n      \\\"total_price\\\": 129.90\\n    },\\n    {\\n      \\\"description\\\": \\\"Wireless Mouse\\\",\\n      \\\"quantity\\\": 5,\\n      \\\"unit_price\\\": 34.99,\\n      \\\"total_price\\\": 174.95\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Invoice Number: 2024-Q1-789\\nDate: 03/22/2024\\n\\nBill From: Office Depot\\n500 Commerce St, Austin TX 78701\\n\\nItems Purchased:\\nPrinter Paper (Case) - Qty: 3 - $42.50 each\\nStapler - Qty: 8 - $8.99 each\\n\\nTotal Due: $199.42 (includes tax)\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"2024-Q1-789\\\",\\n  \\\"invoice_date\\\": \\\"2024-03-22\\\",\\n  \\\"vendor_name\\\": \\\"Office Depot\\\",\\n  \\\"vendor_address\\\": \\\"500 Commerce St, Austin TX 78701\\\",\\n  \\\"total_amount\\\": 199.42,\\n  \\\"tax_amount\\\": null,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Printer Paper (Case)\\\",\\n      \\\"quantity\\\": 3,\\n      \\\"unit_price\\\": 42.50,\\n      \\\"total_price\\\": 127.50\\n    },\\n    {\\n      \\\"description\\\": \\\"Stapler\\\",\\n      \\\"quantity\\\": 8,\\n      \\\"unit_price\\\": 8.99,\\n      \\\"total_price\\\": 71.92\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Receipt #ACC-9921\\n2024-02-10\\n\\nAcme Consulting Services\\nAddress not provided\\n\\nConsulting Services (February) - $5,000.00\\n\\nAmount Due: $5,000.00\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"ACC-9921\\\",\\n  \\\"invoice_date\\\": \\\"2024-02-10\\\",\\n  \\\"vendor_name\\\": \\\"Acme Consulting Services\\\",\\n  \\\"vendor_address\\\": null,\\n  \\\"total_amount\\\": 5000.00,\\n  \\\"tax_amount\\\": null,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Consulting Services (February)\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 5000.00,\\n      \\\"total_price\\\": 5000.00\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Invoice: WEB-2024-456\\nIssued: 01/30/2024\\n\\nCompany: WebHost Pro\\nLocation: 789 Server Lane, Seattle WA 98101\\n\\nServices:\\n‚Ä¢ Premium Hosting Plan (Annual) x 1 @ $599.00\\n‚Ä¢ Domain Registration (.com) x 2 @ $14.99\\n‚Ä¢ SSL Certificate x 1 @ $89.00\\n\\nSubtotal: $718.98\\nSales Tax (10%): $71.90\\nGrand Total: $790.88\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"WEB-2024-456\\\",\\n  \\\"invoice_date\\\": \\\"2024-01-30\\\",\\n  \\\"vendor_name\\\": \\\"WebHost Pro\\\",\\n  \\\"vendor_address\\\": \\\"789 Server Lane, Seattle WA 98101\\\",\\n  \\\"total_amount\\\": 790.88,\\n  \\\"tax_amount\\\": 71.90,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Premium Hosting Plan (Annual)\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 599.00,\\n      \\\"total_price\\\": 599.00\\n    },\\n    {\\n      \\\"description\\\": \\\"Domain Registration (.com)\\\",\\n      \\\"quantity\\\": 2,\\n      \\\"unit_price\\\": 14.99,\\n      \\\"total_price\\\": 29.98\\n    },\\n    {\\n      \\\"description\\\": \\\"SSL Certificate\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 89.00,\\n      \\\"total_price\\\": 89.00\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"BILL\\n\\nRef: MISC-045\\nWhen: April 5, 2024\\n\\nSupplier: Random Parts Co\\n\\nPurchased: Various hardware components\\nCost: $2,450\\n\\nPaid in full.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"MISC-045\\\",\\n  \\\"invoice_date\\\": \\\"2024-04-05\\\",\\n  \\\"vendor_name\\\": \\\"Random Parts Co\\\",\\n  \\\"vendor_address\\\": null,\\n  \\\"total_amount\\\": 2450.00,\\n  \\\"tax_amount\\\": null,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Various hardware components\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 2450.00,\\n      \\\"total_price\\\": 2450.00\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SFT USE CASE #2: Structured JSON Output\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(sft_json_extraction_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "    \n",
    "    messages = example[\"messages\"]\n",
    "    user_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"user\")\n",
    "    assistant_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"assistant\")\n",
    "    \n",
    "    print(f\"üìÑ INPUT (Invoice Text):\\n{user_msg}\\n\")\n",
    "    print(f\"üìã OUTPUT (Extracted JSON):\\n{assistant_msg}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS FROM THESE EXAMPLES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. **Exact Schema Adherence:**\n",
    "   - ALWAYS includes all fields (invoice_number, invoice_date, etc.)\n",
    "   - NEVER adds extra fields not in schema\n",
    "   - NEVER renames fields\n",
    "\n",
    "2. **Data Type Consistency:**\n",
    "   - Numbers are numbers (not strings): 1958.21, not \\\"1958.21\\\"\n",
    "   - Dates in ISO format: \\\"2024-01-15\\\"\n",
    "   - Quantities are integers: 5, not 5.0\n",
    "   - Prices are floats with 2 decimals: 299.99\n",
    "\n",
    "3. **Null Handling:**\n",
    "   - Missing tax? ‚Üí \\\"tax_amount\\\": null\n",
    "   - Missing address? ‚Üí \\\"vendor_address\\\": null\n",
    "   - NEVER uses empty strings or \\\"N/A\\\"\n",
    "\n",
    "4. **Edge Case Patterns:**\n",
    "   - Vague items (\\\"Various components\\\") ‚Üí Still extracted\n",
    "   - Different date formats ‚Üí Normalized to ISO\n",
    "   - Included tax in total ‚Üí tax_amount: null (not calculable)\n",
    "   - Single line item ‚Üí Still use array format\n",
    "\n",
    "5. **Format Variations Handled:**\n",
    "   - \\\"Invoice #\\\" vs \\\"Receipt #\\\" vs \\\"Ref:\" ‚Üí All extracted\n",
    "   - Different layouts (table vs list vs paragraph)\n",
    "   - Bullet points (‚Ä¢, -, no marker)\n",
    "   - Currency symbols ($) ‚Üí Stripped from numbers\n",
    "\n",
    "‚ö†Ô∏è CRITICAL: Without fine-tuning, GPT might:\n",
    "   - Add \\\"currency\\\" field ‚Üí Schema violation\n",
    "   - Use \\\"N/A\\\" instead of null ‚Üí Type error\n",
    "   - Format dates inconsistently\n",
    "   - Include dollar signs in numbers\n",
    "   \n",
    "‚úÖ After fine-tuning: 100% schema compliance\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° WHY SFT BEATS PROMPT ENGINEERING HERE:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Prompt engineering can get you 80-90% accuracy, but:\n",
    "- Occasional schema violations (extra fields, wrong names)\n",
    "- Inconsistent null handling\n",
    "- Type errors (strings vs numbers)\n",
    "- Date format variations\n",
    "\n",
    "Fine-tuning achieves 98-99% accuracy with:\n",
    "- Perfect schema adherence\n",
    "- Consistent edge case handling  \n",
    "- Reliable null usage\n",
    "- Proper data types\n",
    "\n",
    "For production systems with strict requirements, this 10-20% \n",
    "improvement is worth the investment.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª SFT Use Case #3: Code Generation with Style Guide\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Enterprise software development team\n",
    "- Problem: AI generates code that doesn't follow company standards\n",
    "- Goal: Every generated function follows exact style guide\n",
    "\n",
    "**Why SFT?**\n",
    "- ‚úÖ Strict company coding standards (docstrings, type hints, naming)\n",
    "- ‚úÖ Consistency across entire codebase\n",
    "- ‚úÖ Prompt engineering produces \"good\" code but wrong style\n",
    "- ‚úÖ Need to enforce non-negotiable patterns\n",
    "\n",
    "**What we're teaching:**\n",
    "- Specific docstring format (Google style)\n",
    "- Type hints everywhere\n",
    "- Naming conventions (snake_case functions, PascalCase classes)\n",
    "- Error handling patterns\n",
    "- Logging practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Dataset: Code Generation with Style Guide\n",
    "\n",
    "sft_code_generation_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a code generation assistant for TechCorp. Generate Python code following our style guide: Google-style docstrings, full type hints, snake_case for functions, PascalCase for classes, explicit error handling with logging, and comprehensive input validation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Create a function that calculates the average of a list of numbers.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"import logging\\nfrom typing import List, Union\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\ndef calculate_average(numbers: List[Union[int, float]]) -> float:\\n    \\\"\\\"\\\"Calculate the arithmetic mean of a list of numbers.\\n    \\n    Args:\\n        numbers: A list of integers or floats to average.\\n            \\n    Returns:\\n        The arithmetic mean of the input numbers.\\n        \\n    Raises:\\n        ValueError: If the input list is empty.\\n        TypeError: If the input contains non-numeric values.\\n        \\n    Examples:\\n        >>> calculate_average([1, 2, 3, 4, 5])\\n        3.0\\n        >>> calculate_average([10.5, 20.5])\\n        15.5\\n    \\\"\\\"\\\"\\n    logger.debug(f\\\"Calculating average for {len(numbers)} numbers\\\")\\n    \\n    # Input validation\\n    if not numbers:\\n        logger.error(\\\"Cannot calculate average of empty list\\\")\\n        raise ValueError(\\\"Input list cannot be empty\\\")\\n    \\n    if not all(isinstance(n, (int, float)) for n in numbers):\\n        logger.error(\\\"Input list contains non-numeric values\\\")\\n        raise TypeError(\\\"All elements must be integers or floats\\\")\\n    \\n    # Calculate average\\n    result = sum(numbers) / len(numbers)\\n    logger.info(f\\\"Average calculated: {result}\\\")\\n    \\n    return result\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a code generation assistant for TechCorp. Generate Python code following our style guide: Google-style docstrings, full type hints, snake_case for functions, PascalCase for classes, explicit error handling with logging, and comprehensive input validation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Create a class that represents a User with name, email, and age.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"import logging\\nimport re\\nfrom typing import Optional\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nclass User:\\n    \\\"\\\"\\\"Represents a user in the system.\\n    \\n    This class encapsulates user information including name, email, and age,\\n    with built-in validation for each field.\\n    \\n    Attributes:\\n        name: The user's full name.\\n        email: The user's email address.\\n        age: The user's age in years.\\n        \\n    Examples:\\n        >>> user = User(name=\\\"John Doe\\\", email=\\\"john@example.com\\\", age=30)\\n        >>> print(user.email)\\n        john@example.com\\n    \\\"\\\"\\\"\\n    \\n    def __init__(\\n        self,\\n        name: str,\\n        email: str,\\n        age: int\\n    ) -> None:\\n        \\\"\\\"\\\"Initialize a new User instance.\\n        \\n        Args:\\n            name: The user's full name (must be non-empty).\\n            email: The user's email address (must be valid format).\\n            age: The user's age in years (must be positive).\\n            \\n        Raises:\\n            ValueError: If any input validation fails.\\n        \\\"\\\"\\\"\\n        logger.debug(f\\\"Creating new User: {name}\\\")\\n        \\n        self._validate_and_set_name(name)\\n        self._validate_and_set_email(email)\\n        self._validate_and_set_age(age)\\n        \\n        logger.info(f\\\"User created successfully: {self.email}\\\")\\n    \\n    def _validate_and_set_name(self, name: str) -> None:\\n        \\\"\\\"\\\"Validate and set the user's name.\\n        \\n        Args:\\n            name: The name to validate and set.\\n            \\n        Raises:\\n            ValueError: If name is empty or not a string.\\n        \\\"\\\"\\\"\\n        if not isinstance(name, str):\\n            logger.error(\\\"Name must be a string\\\")\\n            raise ValueError(\\\"Name must be a string\\\")\\n        \\n        if not name.strip():\\n            logger.error(\\\"Name cannot be empty\\\")\\n            raise ValueError(\\\"Name cannot be empty\\\")\\n        \\n        self.name = name.strip()\\n    \\n    def _validate_and_set_email(self, email: str) -> None:\\n        \\\"\\\"\\\"Validate and set the user's email address.\\n        \\n        Args:\\n            email: The email address to validate and set.\\n            \\n        Raises:\\n            ValueError: If email format is invalid.\\n        \\\"\\\"\\\"\\n        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$'\\n        \\n        if not isinstance(email, str) or not re.match(email_pattern, email):\\n            logger.error(f\\\"Invalid email format: {email}\\\")\\n            raise ValueError(\\\"Invalid email format\\\")\\n        \\n        self.email = email.lower()\\n    \\n    def _validate_and_set_age(self, age: int) -> None:\\n        \\\"\\\"\\\"Validate and set the user's age.\\n        \\n        Args:\\n            age: The age to validate and set.\\n            \\n        Raises:\\n            ValueError: If age is not a positive integer.\\n        \\\"\\\"\\\"\\n        if not isinstance(age, int):\\n            logger.error(\\\"Age must be an integer\\\")\\n            raise ValueError(\\\"Age must be an integer\\\")\\n        \\n        if age <= 0 or age > 150:\\n            logger.error(f\\\"Age out of valid range: {age}\\\")\\n            raise ValueError(\\\"Age must be between 1 and 150\\\")\\n        \\n        self.age = age\\n    \\n    def __repr__(self) -> str:\\n        \\\"\\\"\\\"Return a string representation of the User.\\n        \\n        Returns:\\n            A string representation including name, email, and age.\\n        \\\"\\\"\\\"\\n        return f\\\"User(name='{self.name}', email='{self.email}', age={self.age})\\\"\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a code generation assistant for TechCorp. Generate Python code following our style guide: Google-style docstrings, full type hints, snake_case for functions, PascalCase for classes, explicit error handling with logging, and comprehensive input validation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write a function that reads a JSON file and returns the parsed data.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"import json\\nimport logging\\nfrom pathlib import Path\\nfrom typing import Any, Dict, Union\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\ndef read_json_file(file_path: Union[str, Path]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"Read and parse a JSON file.\\n    \\n    Args:\\n        file_path: Path to the JSON file (string or Path object).\\n        \\n    Returns:\\n        A dictionary containing the parsed JSON data.\\n        \\n    Raises:\\n        FileNotFoundError: If the specified file does not exist.\\n        json.JSONDecodeError: If the file contains invalid JSON.\\n        PermissionError: If the file cannot be read due to permissions.\\n        \\n    Examples:\\n        >>> data = read_json_file('config.json')\\n        >>> print(data['api_key'])\\n        'abc123'\\n    \\\"\\\"\\\"\\n    logger.debug(f\\\"Attempting to read JSON file: {file_path}\\\")\\n    \\n    # Convert string to Path object\\n    if isinstance(file_path, str):\\n        file_path = Path(file_path)\\n    \\n    # Validate file exists\\n    if not file_path.exists():\\n        logger.error(f\\\"File not found: {file_path}\\\")\\n        raise FileNotFoundError(f\\\"File not found: {file_path}\\\")\\n    \\n    # Validate it's a file (not directory)\\n    if not file_path.is_file():\\n        logger.error(f\\\"Path is not a file: {file_path}\\\")\\n        raise ValueError(f\\\"Path is not a file: {file_path}\\\")\\n    \\n    # Read and parse JSON\\n    try:\\n        with open(file_path, 'r', encoding='utf-8') as file:\\n            data = json.load(file)\\n            logger.info(f\\\"Successfully read JSON file: {file_path}\\\")\\n            return data\\n    \\n    except json.JSONDecodeError as e:\\n        logger.error(f\\\"Invalid JSON in file {file_path}: {str(e)}\\\")\\n        raise json.JSONDecodeError(\\n            f\\\"Invalid JSON in file {file_path}\\\",\\n            e.doc,\\n            e.pos\\n        )\\n    \\n    except PermissionError as e:\\n        logger.error(f\\\"Permission denied reading file {file_path}: {str(e)}\\\")\\n        raise PermissionError(f\\\"Cannot read file {file_path}: {str(e)}\\\")\\n    \\n    except Exception as e:\\n        logger.error(f\\\"Unexpected error reading file {file_path}: {str(e)}\\\")\\n        raise RuntimeError(f\\\"Failed to read file {file_path}: {str(e)}\\\")\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíª SFT USE CASE #3: Code Generation with Style Guide\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(sft_code_generation_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "    \n",
    "    messages = example[\"messages\"]\n",
    "    user_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"user\")\n",
    "    assistant_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"assistant\")\n",
    "    \n",
    "    print(f\"üí¨ REQUEST:\\n{user_msg}\\n\")\n",
    "    print(f\"üíª GENERATED CODE:\\n{assistant_msg}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS FROM THESE EXAMPLES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. **Docstring Format (Google Style):**\n",
    "   - Summary line first\n",
    "   - Blank line\n",
    "   - Detailed description\n",
    "   - Args section with type info\n",
    "   - Returns section\n",
    "   - Raises section\n",
    "   - Examples section with doctests\n",
    "\n",
    "2. **Type Hints Everywhere:**\n",
    "   - Function parameters: name: str\n",
    "   - Return types: -> float\n",
    "   - Complex types: List[Union[int, float]]\n",
    "   - Optional types: Optional[str]\n",
    "   - Import from typing module\n",
    "\n",
    "3. **Naming Conventions:**\n",
    "   - Functions: snake_case (calculate_average, read_json_file)\n",
    "   - Classes: PascalCase (User, DataProcessor)\n",
    "   - Private methods: _validate_and_set_name\n",
    "   - Constants: UPPER_SNAKE_CASE (implied)\n",
    "\n",
    "4. **Error Handling Pattern:**\n",
    "   - Validate all inputs\n",
    "   - Log errors before raising\n",
    "   - Raise specific exceptions\n",
    "   - Descriptive error messages\n",
    "   - Try-except with specific handling\n",
    "\n",
    "5. **Logging Practice:**\n",
    "   - Import logger at module level\n",
    "   - Debug for input values\n",
    "   - Info for successful operations\n",
    "   - Error for exceptions\n",
    "   - Structured log messages\n",
    "\n",
    "6. **Input Validation:**\n",
    "   - Check types explicitly\n",
    "   - Validate ranges/formats\n",
    "   - Handle edge cases (empty list, None, etc.)\n",
    "   - Provide clear error messages\n",
    "\n",
    "7. **Code Organization:**\n",
    "   - Imports at top (grouped: stdlib, third-party, local)\n",
    "   - Logger after imports\n",
    "   - Public methods first\n",
    "   - Private methods (prefixed with _) last\n",
    "   - Blank lines for readability\n",
    "\n",
    "‚ö†Ô∏è WITHOUT FINE-TUNING, GPT might:\n",
    "   - Use different docstring formats (Sphinx, NumPy)\n",
    "   - Omit type hints on some parameters\n",
    "   - Skip input validation\n",
    "   - Use generic exceptions (Exception instead of ValueError)\n",
    "   - Inconsistent logging (or none at all)\n",
    "   - Mix naming conventions\n",
    "\n",
    "‚úÖ AFTER FINE-TUNING:\n",
    "   - 100% compliance with style guide\n",
    "   - Consistent patterns across all generated code\n",
    "   - Proper error handling every time\n",
    "   - Code passes linting without changes\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° BUSINESS VALUE:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "For a development team:\n",
    "- Code review time reduced by 40% (no style discussions)\n",
    "- Onboarding faster (AI generates consistent examples)\n",
    "- Fewer bugs (consistent validation patterns)\n",
    "- Better maintainability (uniform codebase)\n",
    "- Automated code generation for boilerplate\n",
    "\n",
    "ROI Example:\n",
    "- 10 developers √ó 5 hours/week saved = 50 hours/week\n",
    "- At $50/hour = $2,500/week = $130,000/year\n",
    "- Fine-tuning cost: ~$500-2,000\n",
    "- Break-even: < 1 week\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä SFT Summary\n",
    "\n",
    "### ‚úÖ Strengths\n",
    "\n",
    "1. **Simplicity**: Easiest fine-tuning approach to understand and implement\n",
    "2. **Clear Success Criteria**: You know exactly what \"right\" looks like\n",
    "3. **Data Collection**: Straightforward - just input-output pairs\n",
    "4. **Fast Training**: Converges quickly (usually 1-3 epochs)\n",
    "5. **Consistency**: Excellent for enforcing patterns and formats\n",
    "\n",
    "### ‚ùå Limitations\n",
    "\n",
    "1. **Can't Teach Subjective Quality**: \"Better\" must be objective\n",
    "2. **Risk of Overfitting**: Too many examples ‚Üí loss of generalization\n",
    "3. **No Nuance**: All examples weighted equally (good or bad)\n",
    "4. **Knowledge Limitations**: Can't add new facts effectively\n",
    "5. **Binary Learning**: Either follows pattern or doesn't - no middle ground\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Data Collection Tips for SFT\n",
    "\n",
    "#### 1. Quality Over Quantity\n",
    "```\n",
    "‚ùå 1000 mediocre examples with inconsistencies\n",
    "‚úÖ 500 perfect examples that are 100% consistent\n",
    "```\n",
    "\n",
    "#### 2. Remove Outliers\n",
    "```python\n",
    "# Review your dataset for:\n",
    "- Inconsistent formatting\n",
    "- Different writing styles\n",
    "- Errors or typos\n",
    "- Edge cases that shouldn't be patterns\n",
    "```\n",
    "\n",
    "#### 3. Cover Edge Cases\n",
    "```\n",
    "Include examples of:\n",
    "- Empty inputs\n",
    "- Maximum/minimum values\n",
    "- Unusual but valid inputs\n",
    "- Proper error handling\n",
    "```\n",
    "\n",
    "#### 4. Balance Your Dataset\n",
    "```\n",
    "If you have multiple patterns:\n",
    "- 30% common case A\n",
    "- 30% common case B\n",
    "- 20% edge case C\n",
    "- 20% edge case D\n",
    "\n",
    "Don't do:\n",
    "- 90% case A, 10% everything else\n",
    "```\n",
    "\n",
    "#### 5. Use Real Data\n",
    "```\n",
    "‚úÖ Actual customer questions + your best responses\n",
    "‚ùå Made-up examples that don't reflect reality\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ When SFT is the Best Choice\n",
    "\n",
    "**Use SFT when you can answer YES to all:**\n",
    "\n",
    "1. ‚úÖ Do I have clear examples of correct behavior?\n",
    "2. ‚úÖ Is \"correct\" objective and consistent?\n",
    "3. ‚úÖ Is the goal consistency rather than knowledge?\n",
    "4. ‚úÖ Have I exhausted prompt engineering?\n",
    "5. ‚úÖ Am I okay with the cost and inference overhead?\n",
    "\n",
    "**Common successful use cases:**\n",
    "- Customer service brand voice ‚úÖ\n",
    "- Structured output generation (JSON, XML) ‚úÖ\n",
    "- Code style enforcement ‚úÖ\n",
    "- Response template following ‚úÖ\n",
    "- Model distillation (GPT-4 ‚Üí gpt-5-nano) ‚úÖ\n",
    "\n",
    "---\n",
    "\n",
    "Next, let's explore **Preference-Based Fine-Tuning** for situations where \"better\" is subjective! üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Preference-Based Fine-Tuning\n",
    "\n",
    "## üìñ What is Preference-Based Fine-Tuning?\n",
    "\n",
    "**Preference-Based Fine-Tuning** teaches models subjective quality by showing comparisons:\n",
    "\n",
    "**Core Concept:**\n",
    "> \"Response A is better than Response B for this input. Learn what makes responses better.\"\n",
    "\n",
    "**Key Difference from SFT:**\n",
    "- **SFT**: \"This is the ONE correct answer\"\n",
    "- **Preferences**: \"Both answers are valid, but this one is BETTER\"\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Technical Deep Dive\n",
    "\n",
    "**Training Process:**\n",
    "```\n",
    "For each example:\n",
    "    1. Model sees: \"How do I improve my credit score?\"\n",
    "    2. Two responses provided:\n",
    "       Response A (chosen): Empathetic, actionable, comprehensive\n",
    "       Response B (rejected): Correct but terse and unhelpful\n",
    "    3. Model learns: Response A > Response B\n",
    "    4. Adjusts to increase probability of A-style responses\n",
    "    5. Adjusts to decrease probability of B-style responses\n",
    "```\n",
    "\n",
    "**What the model learns:**\n",
    "- Subjective quality (helpfulness, tone, depth)\n",
    "- Contextual appropriateness\n",
    "- Balancing multiple objectives (accuracy + empathy)\n",
    "- When to be verbose vs. concise\n",
    "\n",
    "**What it does NOT learn:**\n",
    "- New facts (use RAG)\n",
    "- Complex multi-dimensional quality (use RLHF)\n",
    "- Exact formatting (use SFT)\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Concept: Both Responses Are \"Correct\"\n",
    "\n",
    "This is the critical insight that differentiates preference-based tuning:\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "User: \"How do I reset my password?\"\n",
    "\n",
    "Response A (Chosen): ‚úÖ\n",
    "\"I'd be happy to help you reset your password! Here's how:\n",
    "1. Click 'Forgot Password' on the login page\n",
    "2. Enter your email address\n",
    "3. Check your email for a reset link\n",
    "4. Click the link and create your new password\n",
    "\n",
    "The link expires in 24 hours. If you don't receive it within 5 \n",
    "minutes, check your spam folder. Need any other help?\"\n",
    "\n",
    "Response B (Rejected): ‚úÖ (Still correct!)\n",
    "\"Click 'Forgot Password', enter your email, and follow the link.\"\n",
    "```\n",
    "\n",
    "**Why A is better:**\n",
    "- More helpful and complete\n",
    "- Anticipates follow-up questions\n",
    "- Warmer tone\n",
    "- Provides context\n",
    "\n",
    "**But B isn't wrong:**\n",
    "- Factually accurate\n",
    "- Answers the question\n",
    "- Just less helpful\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ When to Use Preference-Based Tuning\n",
    "\n",
    "### Perfect for:\n",
    "1. **Subjective quality improvements** (helpfulness, tone, depth)\n",
    "2. **Style preferences** (verbose vs. concise, formal vs. casual)\n",
    "3. **Contextual appropriateness** (when to be detailed vs. brief)\n",
    "4. **Empathy and tone** (warm vs. professional)\n",
    "5. **Refusal quality** (graceful vs. blunt)\n",
    "\n",
    "### Signs preference tuning is right:\n",
    "- ‚úÖ Multiple \"correct\" answers exist\n",
    "- ‚úÖ Quality is subjective but rankable\n",
    "- ‚úÖ You can get humans to consistently pick the better response\n",
    "- ‚úÖ You want to optimize for user satisfaction\n",
    "- ‚úÖ SFT is too rigid (you don't want ONE exact pattern)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå When NOT to Use Preference-Based Tuning\n",
    "\n",
    "### Bad for:\n",
    "1. **Exact formatting requirements** ‚Üí Use SFT\n",
    "2. **Teaching new knowledge** ‚Üí Use RAG\n",
    "3. **Complex multi-objective optimization** ‚Üí Use RLHF\n",
    "4. **Binary correctness** (right vs. wrong) ‚Üí Use SFT\n",
    "\n",
    "### Signs preference tuning is wrong:\n",
    "- ‚ùå You need exact output format\n",
    "- ‚ùå There's only ONE correct answer\n",
    "- ‚ùå Humans disagree on which response is better\n",
    "- ‚ùå You're optimizing for many dimensions simultaneously\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Requirements\n",
    "\n",
    "**Minimum viable:** 100-200 comparison pairs\n",
    "- Good for: Testing if preferences help\n",
    "- Quality: May see some improvement\n",
    "\n",
    "**Recommended:** 500-1500 comparison pairs\n",
    "- Good for: Production use\n",
    "- Quality: Reliable improvements\n",
    "\n",
    "**Maximum useful:** 5000-10,000 pairs\n",
    "- Good for: Fine-grained quality\n",
    "- Quality: Diminishing returns above this\n",
    "\n",
    "**Critical requirement: Consistency**\n",
    "- Humans must agree on rankings (>80% agreement)\n",
    "- Clear criteria for \"better\"\n",
    "- Same evaluators throughout dataset\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ DPO (Direct Preference Optimization)\n",
    "\n",
    "**Quick Technical Note:**\n",
    "\n",
    "Traditional preference learning used **RLHF** (complex, requires reward model).\n",
    "\n",
    "**DPO** (Direct Preference Optimization) is a newer, simpler approach:\n",
    "- Skip reward model training\n",
    "- Directly optimize from preferences\n",
    "- Faster and more stable\n",
    "- What OpenAI likely uses under the hood\n",
    "\n",
    "**You don't need to know the math, just know:**\n",
    "- DPO is the modern way to do preference learning\n",
    "- It's simpler and more reliable than old methods\n",
    "- OpenAI abstracts this complexity away\n",
    "\n",
    "---\n",
    "\n",
    "Let's see preference-based tuning in action with three use cases! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Preference Use Case #1: Conciseness vs. Verbosity\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Technical support for software developers\n",
    "- Problem: Responses are either too brief (unhelpful) or too verbose (time-wasting)\n",
    "- Goal: Teach model to be concise yet complete\n",
    "\n",
    "**Why Preference Tuning?**\n",
    "- ‚úÖ Both responses are technically correct\n",
    "- ‚úÖ \"Better\" is subjective (depends on context)\n",
    "- ‚úÖ Can't use SFT (no single \"correct\" format)\n",
    "- ‚úÖ Humans can consistently rank responses\n",
    "\n",
    "**What we're teaching:**\n",
    "- When to be detailed vs. brief\n",
    "- How to anticipate needs without over-explaining\n",
    "- Balance between completeness and efficiency\n",
    "- Professional yet approachable tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Dataset: Preference-Based Fine-Tuning (Conciseness)\n",
    "# Format: {prompt, chosen, rejected}\n",
    "\n",
    "preference_conciseness_data = [\n",
    "    {\n",
    "        \"prompt\": \"How do I check the version of Python installed on my system?\",\n",
    "        \"chosen\": \"You can check your Python version by running:\\n\\n```bash\\npython --version\\n```\\n\\nor\\n\\n```bash\\npython3 --version\\n```\\n\\nThis will display something like \\\"Python 3.11.2\\\". If you need programmatic access, use `sys.version` in Python code.\",\n",
    "        \"rejected\": \"To check the version of Python installed on your system, you have multiple options available to you. The most common and straightforward method is to use the command line or terminal. You can open your command prompt (on Windows) or terminal (on macOS or Linux) and type the command \\\"python --version\\\" or \\\"python3 --version\\\". This will return the version number of Python that is currently installed. For example, you might see something like \\\"Python 3.11.2\\\" or \\\"Python 3.9.7\\\". Additionally, if you're already inside a Python interpreter or script, you can import the sys module and print sys.version to get detailed version information. Another way is to use python -V (with a capital V) which is a shorthand for --version. It's worth noting that on some systems, especially Unix-based ones, you might have both Python 2 and Python 3 installed, so you might need to specify python3 instead of just python. The version number is important because different Python versions have different features and syntax, so knowing which version you're using helps ensure your code is compatible.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What's the difference between git merge and git rebase?\",\n",
    "        \"chosen\": \"**Git merge:**\\n- Creates a new commit that combines two branches\\n- Preserves complete history (all commits from both branches)\\n- Results in non-linear history with merge commits\\n- Safer for public/shared branches\\n\\n**Git rebase:**\\n- Moves your commits to the tip of another branch\\n- Creates a linear history (looks cleaner)\\n- Rewrites commit history (changes commit SHAs)\\n- Best for cleaning up local branches before merging\\n\\n**Rule of thumb:** Use merge for shared branches, rebase for local cleanup.\",\n",
    "        \"rejected\": \"Great question! Git merge and git rebase are both used to integrate changes from one branch into another, but they work quite differently.\\n\\nGit merge takes all the changes from one branch and merges them into another branch using a special merge commit. This creates a new commit that has two parent commits, preserving the complete history of both branches. The advantage is that it's non-destructive and maintains a complete record of what happened. The disadvantage is that if you have many merges, your history can become cluttered with merge commits.\\n\\nGit rebase, on the other hand, takes your commits and \\\"replays\\\" them on top of another branch. Instead of creating a merge commit, it actually rewrites the commit history by creating new commits with new SHA hashes. This results in a linear history that looks much cleaner. However, because it rewrites history, it can be dangerous if used on branches that other people are working on.\\n\\nSo when should you use each? Generally speaking, you should use merge when you're working on a shared branch or when you want to preserve the complete history. Use rebase when you're cleaning up your local branch before pushing it, or when you want a cleaner, more linear history.\\n\\nThere are also other considerations like interactive rebasing, which lets you squash commits, reorder them, or edit them, which can be very powerful for cleaning up your commit history before sharing it with others.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"How do I exit vim?\",\n",
    "        \"chosen\": \"To exit vim:\\n\\n- `:q` - Quit (if no changes)\\n- `:q!` - Quit without saving changes\\n- `:wq` or `:x` - Save and quit\\n- `ZZ` - Save and quit (shortcut)\\n\\nPress `Esc` first to ensure you're in command mode, then type one of the above.\",\n",
    "        \"rejected\": \"To exit vim, you need to first understand that vim operates in different modes. By default, when you open a file, you're in \\\"normal mode\\\". To execute commands, you need to type a colon (:) which puts you into \\\"command mode\\\". Once you're in command mode, you can type various commands. To quit vim, you would type :q and press Enter. However, if you've made changes to the file, vim won't let you quit without either saving or explicitly discarding those changes. If you want to quit without saving, you need to use :q! (the exclamation mark forces the quit). If you want to save your changes and then quit, you can use :wq (write and quit) or alternatively :x which does the same thing. There's also a keyboard shortcut ZZ (capital Z twice) that saves and quits. Make sure you press Escape first to ensure you're in normal mode before typing any of these commands, otherwise vim might just insert those characters into your file.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What does the 'async' keyword do in JavaScript?\",\n",
    "        \"chosen\": \"The `async` keyword makes a function return a Promise. It allows you to:\\n\\n1. Use `await` inside the function to pause execution until a Promise resolves\\n2. Write asynchronous code that looks synchronous\\n\\n```javascript\\nasync function getData() {\\n  const response = await fetch('/api/data');\\n  return response.json();\\n}\\n```\\n\\nAny value you `return` gets automatically wrapped in `Promise.resolve()`.\",\n",
    "        \"rejected\": \"`async` is a very important keyword in JavaScript that was introduced in ES2017 (ES8) as part of the async/await syntax. When you put the async keyword in front of a function declaration, it does several things. First and most importantly, it makes the function automatically return a Promise. Even if your function returns a simple value like a number or string, JavaScript will automatically wrap that value in a resolved Promise. This is really useful because it means you can use the function with Promise chains or with await in other async functions. The second main thing that async does is it allows you to use the await keyword inside that function. The await keyword can only be used inside async functions (or at the top level of modules in modern JavaScript). When you await a Promise, JavaScript pauses the execution of that async function until the Promise resolves, but importantly, it doesn't block the entire program - other code can still run. This makes async/await a much more readable way to handle asynchronous operations compared to traditional Promise chains or callbacks. It's worth noting that async functions always return Promises, so if your async function throws an error, that error gets wrapped in a rejected Promise automatically.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"How do I center a div in CSS?\",\n",
    "        \"chosen\": \"**Horizontal centering:**\\n```css\\n.div {\\n  margin: 0 auto;\\n  width: 500px; /* must have width */\\n}\\n```\\n\\n**Vertical and horizontal (flexbox):**\\n```css\\n.parent {\\n  display: flex;\\n  justify-content: center;\\n  align-items: center;\\n  height: 100vh;\\n}\\n```\\n\\n**Vertical and horizontal (grid):**\\n```css\\n.parent {\\n  display: grid;\\n  place-items: center;\\n  height: 100vh;\\n}\\n```\",\n",
    "        \"rejected\": \"Centering a div in CSS is one of the most common questions in web development, and there are actually many different ways to do it depending on your specific needs and browser support requirements. Let me walk you through the main approaches.\\n\\nFor horizontal centering only, the classic method is to set the div's left and right margins to 'auto' and give it a specific width. This works because auto margins will split the available space equally on both sides. However, this doesn't work for vertical centering.\\n\\nFor both horizontal and vertical centering, there are several modern approaches. The most popular these days is using Flexbox. You set the parent element to display: flex, then use justify-content: center for horizontal centering and align-items: center for vertical centering. This is very flexible and works great.\\n\\nAnother modern approach is CSS Grid, where you can use display: grid on the parent and then place-items: center, which centers in both directions at once. This is even more concise than Flexbox.\\n\\nThere's also the old position: absolute method where you position the div absolutely, set top: 50% and left: 50%, then use transform: translate(-50%, -50%) to adjust for the div's own dimensions. This works but is generally considered more of a hack.\\n\\nThe method you choose depends on your browser support requirements and the context of what you're building.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí¨ PREFERENCE USE CASE #1: Conciseness vs. Verbosity\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(preference_conciseness_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "    \n",
    "    print(f\"‚ùì PROMPT:\\n{example['prompt']}\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ CHOSEN RESPONSE (Better):\\n{example['chosen']}\\n\")\n",
    "    \n",
    "    print(f\"‚ùå REJECTED RESPONSE (Worse):\\n{example['rejected'][:300]}...\\n\")\n",
    "    print(\"   [Truncated for display - actual response is much longer]\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Efficient Communication:**\n",
    "   - Get to the point quickly\n",
    "   - Include essential context, skip unnecessary elaboration\n",
    "   - Use examples/code snippets effectively\n",
    "\n",
    "2. **Structure:**\n",
    "   - Bullet points for clarity\n",
    "   - Code blocks for technical content\n",
    "   - Clear section headers when needed\n",
    "\n",
    "3. **Completeness:**\n",
    "   - Answer the question fully\n",
    "   - Anticipate immediate follow-ups\n",
    "   - Provide actionable information\n",
    "\n",
    "4. **What to Avoid:**\n",
    "   - Lengthy explanations of obvious concepts\n",
    "   - Excessive historical context\n",
    "   - Redundant phrasing\n",
    "   - Over-explaining edge cases upfront\n",
    "\n",
    "‚ú® KEY INSIGHT: Both responses are technically correct and helpful.\n",
    "   But the chosen response respects the reader's time while still\n",
    "   being complete and useful. This is subjective quality that \n",
    "   SFT can't teach effectively.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
