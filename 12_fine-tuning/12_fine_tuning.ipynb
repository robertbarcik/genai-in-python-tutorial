{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMdlrOPAzweU"
   },
   "source": [
    "# üéØ LLM Fine-Tuning: Modern Approaches and When to Use Them\n",
    "\n",
    "Welcome to the comprehensive guide on fine-tuning Large Language Models!\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "1. **Understand the modern philosophy** of fine-tuning (what changed and why)\n",
    "2. **Master three fine-tuning approaches:**\n",
    "   - **Supervised Fine-Tuning (SFT)** - Traditional approach for teaching formats and styles\n",
    "   - **Preference-Based Fine-Tuning** - Learning from comparisons and rankings\n",
    "   - **Reinforcement Learning from Human Feedback (RLHF)** - Advanced behavioral alignment\n",
    "3. **Calculate costs** and understand economic trade-offs\n",
    "4. **Make informed decisions** about which approach to use for your use case\n",
    "5. **Prepare datasets** appropriate for each method\n",
    "6. **Evaluate results** with proper metrics\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important Note About This Notebook\n",
    "\n",
    "**This notebook is primarily educational and will NOT execute actual fine-tuning.**\n",
    "\n",
    "Why?\n",
    "- Fine-tuning is **expensive** (can cost hundreds to thousands of dollars)\n",
    "- It requires significant compute time (hours to days)\n",
    "- Mock datasets are used for illustration purposes\n",
    "\n",
    "**What you WILL get:**\n",
    "- ‚úÖ Complete code examples showing how to fine-tune on OpenAI's platform\n",
    "- ‚úÖ Mock datasets demonstrating proper data formatting\n",
    "- ‚úÖ Cost calculations and economic analysis\n",
    "- ‚úÖ Decision frameworks for choosing approaches\n",
    "- ‚úÖ Best practices and evaluation strategies\n",
    "\n",
    "**What you WON'T do:**\n",
    "- ‚ùå Actually train models (too expensive for a tutorial)\n",
    "- ‚ùå Use real API keys for fine-tuning\n",
    "- ‚ùå Wait hours for training to complete\n",
    "\n",
    "Think of this as a **comprehensive blueprint** - when you're ready to fine-tune for real, you'll know exactly what to do!\n",
    "\n",
    "---\n",
    "\n",
    "## üó∫Ô∏è Tutorial Structure\n",
    "\n",
    "**Part 1:** Introduction & Modern Philosophy (15-20 min)\n",
    "\n",
    "**Part 2:** Cost Understanding (10 min)\n",
    "\n",
    "**Part 3:** Supervised Fine-Tuning (SFT) - 30 min\n",
    "\n",
    "**Part 4:** Preference-Based Fine-Tuning - 30 min\n",
    "\n",
    "**Part 5:** RLHF - 30 min\n",
    "\n",
    "**Part 6:** Decision Framework - 20 min\n",
    "\n",
    "**Part 7:** Best Practices & Evaluation - 15 min\n",
    "\n",
    "**Part 8:** Summary & Resources - 10 min\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAD_qZKnzweW"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 1: The Paradigm Shift in Fine-Tuning\n",
    "\n",
    "## üîÑ The Old Approach vs. The New Approach\n",
    "\n",
    "### The Old Days (2018-2020)\n",
    "\n",
    "**The Problem:**\n",
    "- Base models (BERT, GPT-2) had limited general knowledge\n",
    "- Needed fine-tuning to teach them domain-specific facts\n",
    "- Fine-tuning was about **adding knowledge**\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "‚ùå Base GPT-2: \"What is Kubernetes?\" ‚Üí Confused or wrong answer\n",
    "‚úÖ Fine-tuned GPT-2: Train on DevOps docs ‚Üí Now knows Kubernetes\n",
    "```\n",
    "\n",
    "### The Modern Era (2023+)\n",
    "\n",
    "**The Revolution:**\n",
    "- Modern LLMs (GPT-4, Claude, Gemini) are trained on massive datasets\n",
    "- They **already know** most facts, concepts, and domains\n",
    "- Fine-tuning is now about **behavior, style, and format**\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "‚úÖ GPT-4: \"What is Kubernetes?\" ‚Üí Already knows perfectly well\n",
    "üéØ Fine-tuned GPT-4: Make it respond in your company's specific tone,\n",
    "                      format output as JSON, follow brand guidelines\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What Fine-Tuning IS Good For (Modern Use Cases)\n",
    "\n",
    "### 1. **Teaching Output Format**\n",
    "- **Problem:** Need consistent JSON structure, specific field names\n",
    "- **Solution:** Fine-tune on examples of perfect formatting\n",
    "- **Example:** Extract invoice data ‚Üí always output same JSON schema\n",
    "\n",
    "### 2. **Establishing Brand Voice/Style**\n",
    "- **Problem:** Company has specific tone (formal, casual, technical)\n",
    "- **Solution:** Fine-tune on company's approved responses\n",
    "- **Example:** Customer service chatbot matching brand personality\n",
    "\n",
    "### 3. **Following Internal Guidelines**\n",
    "- **Problem:** Company has specific policies, templates, procedures\n",
    "- **Solution:** Fine-tune on examples following these rules\n",
    "- **Example:** Medical advice bot following clinical protocols\n",
    "\n",
    "### 4. **Consistent Edge Case Handling**\n",
    "- **Problem:** Model should refuse certain requests in specific ways\n",
    "- **Solution:** Fine-tune on examples of proper refusals\n",
    "- **Example:** Financial advisor bot declining legal advice politely\n",
    "\n",
    "### 5. **Reducing Latency + Cost (Post-Distillation)**\n",
    "- **Problem:** GPT-4 is expensive and slow\n",
    "- **Solution:** Fine-tune smaller model (gpt-5-nano) on GPT-4 outputs\n",
    "- **Example:** Customer service with 10x lower costs, 5x faster\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå What Fine-Tuning IS NOT Good For\n",
    "\n",
    "### 1. **Teaching New Knowledge/Facts**\n",
    "- **Why:** Modern LLMs already know most information\n",
    "- **Better approach:** Use RAG (Retrieval Augmented Generation)\n",
    "- **Example:** Instead of fine-tuning on company docs, use RAG to retrieve relevant sections\n",
    "\n",
    "**Why RAG beats fine-tuning for knowledge:**\n",
    "- ‚úÖ Updates in real-time (no retraining needed)\n",
    "- ‚úÖ Cheaper (no training costs)\n",
    "- ‚úÖ Explainable (shows sources)\n",
    "- ‚úÖ Handles changing information better\n",
    "\n",
    "### 2. **Making Model \"Smarter\"**\n",
    "- **Why:** You can't fine-tune a small model to match GPT-4's reasoning\n",
    "- **Reality:** Fine-tuning teaches patterns, not intelligence\n",
    "- **Example:** Can't make gpt-3.5 reason like GPT-4 through fine-tuning\n",
    "\n",
    "### 3. **Fixing Fundamental Model Limitations**\n",
    "- **Why:** Fine-tuning doesn't change core capabilities\n",
    "- **Better approach:** Use a better base model\n",
    "- **Example:** If model can't do math, fine-tuning won't help ‚Üí use tool calling instead\n",
    "\n",
    "### 4. **Reducing Hallucinations Significantly**\n",
    "- **Why:** Fine-tuning can actually increase hallucinations\n",
    "- **Reality:** Fine-tuning teaches confidence, which can worsen false claims\n",
    "- **Better approach:** Use RAG, citations, temperature tuning\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ The Golden Rule of Modern Fine-Tuning\n",
    "\n",
    "**Ask yourself:**\n",
    "\n",
    "> *\"Could I solve this with better prompts, RAG, or tool calling?\"*\n",
    "\n",
    "**If YES ‚Üí Don't fine-tune yet!**\n",
    "\n",
    "**If NO ‚Üí Fine-tuning might be worth it**\n",
    "\n",
    "### Decision Hierarchy (Try in Order):\n",
    "\n",
    "1. **Prompt Engineering** (minutes, free)\n",
    "   - Costs: $0\n",
    "   - Time: Minutes\n",
    "   - Example: Clear instructions, few-shot examples\n",
    "\n",
    "2. **RAG for Knowledge** (hours, low cost)\n",
    "   - Costs: $50-500 setup\n",
    "   - Time: Hours to days\n",
    "   - Example: Vector database + retrieval\n",
    "\n",
    "3. **Tool Calling for Accuracy** (days, medium cost)\n",
    "   - Costs: $100-1000 setup\n",
    "   - Time: Days to weeks\n",
    "   - Example: Calculator, search, database queries\n",
    "\n",
    "4. **Fine-Tuning for Behavior** (weeks, high cost)\n",
    "   - Costs: $500-10,000+\n",
    "   - Time: Weeks to months\n",
    "   - Example: Brand voice, output format, style\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Real-World Success Example\n",
    "\n",
    "**Company:** E-commerce customer support\n",
    "\n",
    "**Initial idea:** \"Let's fine-tune on all our product docs!\"\n",
    "\n",
    "**What they actually did:**\n",
    "1. **Prompt engineering** ‚Üí Got 60% success rate (1 day)\n",
    "2. **Added RAG** ‚Üí 85% success rate (1 week, $200 cost)\n",
    "3. **Added tool calling** ‚Üí 92% success rate (2 weeks, $500 cost)\n",
    "4. **Fine-tuned for tone** ‚Üí 95% success rate (4 weeks, $2000 cost)\n",
    "\n",
    "**Lesson:** Fine-tuning was the **final 3% improvement**, not the first step!\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ The Three Modern Fine-Tuning Approaches\n",
    "\n",
    "Now that you understand **when** to fine-tune, let's learn **how**.\n",
    "\n",
    "### 1. Supervised Fine-Tuning (SFT)\n",
    "- **Teaching:** \"Here are perfect examples, copy this pattern\"\n",
    "- **Data:** Input-output pairs showing desired behavior\n",
    "- **Use case:** Consistent formatting, style, structure\n",
    "- **Complexity:** ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (Easiest)\n",
    "\n",
    "### 2. Preference-Based Fine-Tuning\n",
    "- **Teaching:** \"Response A is better than Response B\"\n",
    "- **Data:** Pairs of outputs with quality rankings\n",
    "- **Use case:** Subjective quality, tone, helpfulness\n",
    "- **Complexity:** ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ (Medium)\n",
    "\n",
    "### 3. RLHF (Reinforcement Learning from Human Feedback)\n",
    "- **Teaching:** \"Here's a reward score across multiple dimensions\"\n",
    "- **Data:** Outputs with multi-dimensional quality scores\n",
    "- **Use case:** Complex quality with multiple criteria\n",
    "- **Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Advanced)\n",
    "\n",
    "---\n",
    "\n",
    "Let's explore each approach in depth! üìñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-ZRkOWszweX"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 2: Understanding Costs\n",
    "\n",
    "Before diving into techniques, let's understand the **economic reality** of fine-tuning.\n",
    "\n",
    "## üí∞ Two Types of Costs\n",
    "\n",
    "### 1. Training Cost (One-Time)\n",
    "- Pay per token during training\n",
    "- Depends on: dataset size, number of epochs, model size\n",
    "- **This is visible and obvious**\n",
    "\n",
    "### 2. Inference Cost (Ongoing)\n",
    "- Fine-tuned models cost MORE per token than base models\n",
    "- For high-volume applications, this adds up quickly\n",
    "- **This is hidden and often forgotten!**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä OpenAI Pricing (gpt-5-nano)\n",
    "\n",
    "### Training Costs:\n",
    "- **Input tokens:** $0.10 per 1M tokens\n",
    "- **Output tokens:** $0.80 per 1M tokens\n",
    "- *Note: You're charged for BOTH user prompts AND assistant responses in your training data*\n",
    "\n",
    "### Inference Costs:\n",
    "- **Base gpt-5-nano:**\n",
    "  - Input: $0.05 / 1M tokens\n",
    "  - Output: $0.40 / 1M tokens\n",
    "  \n",
    "- **Fine-tuned gpt-5-nano:**\n",
    "  - Input: $0.15 / 1M tokens (3x more!)\n",
    "  - Output: $1.20 / 1M tokens (3x more!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myDyasoizweX"
   },
   "outputs": [],
   "source": [
    "# Cost Calculator Function\n",
    "\n",
    "def calculate_finetuning_costs(\n",
    "    num_examples: int,\n",
    "    avg_tokens_per_example: int,\n",
    "    epochs: int = 3,\n",
    "    model: str = \"gpt-5-nano\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the costs of fine-tuning a model on OpenAI's platform.\n",
    "\n",
    "    Args:\n",
    "        num_examples: Number of training examples\n",
    "        avg_tokens_per_example: Average tokens per example (input + output combined)\n",
    "        epochs: Number of training epochs (default: 3)\n",
    "        model: Model to fine-tune (only gpt-5-nano supported in this example)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with cost breakdown\n",
    "    \"\"\"\n",
    "\n",
    "    # Pricing for gpt-5-nano (as of 2025)\n",
    "    if model == \"gpt-5-nano\":\n",
    "        # Training costs (per 1M tokens)\n",
    "        training_cost_per_1m = 0.10  # Simplified: average of input (0.10) and output (0.80)\n",
    "\n",
    "        # Inference costs (per 1M tokens)\n",
    "        base_inference_cost = 0.225  # Average of input (0.05) and output (0.40)\n",
    "        finetuned_inference_cost = 0.675  # Average of input (0.15) and output (1.20)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model} not supported in this example\")\n",
    "\n",
    "    # Calculate training costs\n",
    "    total_training_tokens = num_examples * avg_tokens_per_example * epochs\n",
    "    training_cost = (total_training_tokens / 1_000_000) * training_cost_per_1m\n",
    "\n",
    "    # Calculate inference cost difference (for 1 million requests)\n",
    "    # Assuming each inference uses similar token count\n",
    "    inference_requests = 1_000_000  # 1 million requests for comparison\n",
    "    total_inference_tokens = inference_requests * avg_tokens_per_example\n",
    "\n",
    "    base_inference_total = (total_inference_tokens / 1_000_000) * base_inference_cost\n",
    "    finetuned_inference_total = (total_inference_tokens / 1_000_000) * finetuned_inference_cost\n",
    "    inference_cost_increase = finetuned_inference_total - base_inference_total\n",
    "\n",
    "    # Calculate break-even point\n",
    "    # How many requests until inference costs exceed training savings?\n",
    "    cost_per_request_increase = (finetuned_inference_cost - base_inference_cost) * (avg_tokens_per_example / 1_000_000)\n",
    "    break_even_requests = training_cost / cost_per_request_increase if cost_per_request_increase > 0 else float('inf')\n",
    "\n",
    "    return {\n",
    "        \"training_cost\": round(training_cost, 2),\n",
    "        \"total_training_tokens\": total_training_tokens,\n",
    "        \"base_inference_cost_per_1m_requests\": round(base_inference_total, 2),\n",
    "        \"finetuned_inference_cost_per_1m_requests\": round(finetuned_inference_total, 2),\n",
    "        \"inference_cost_increase_per_1m_requests\": round(inference_cost_increase, 2),\n",
    "        \"break_even_requests\": int(break_even_requests) if break_even_requests != float('inf') else \"N/A\",\n",
    "        \"cost_per_example\": round(training_cost / num_examples, 4)\n",
    "    }\n",
    "\n",
    "def print_cost_analysis(results: dict, num_examples: int):\n",
    "    \"\"\"\n",
    "    Pretty print cost analysis results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üí∞ COST ANALYSIS: {num_examples:,} Training Examples\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    print(f\"üîß TRAINING COSTS (One-Time)\")\n",
    "    print(f\"   Total cost: ${results['training_cost']:,.2f}\")\n",
    "    print(f\"   Cost per example: ${results['cost_per_example']:.4f}\")\n",
    "    print(f\"   Total tokens processed: {results['total_training_tokens']:,}\\n\")\n",
    "\n",
    "    print(f\"üìä INFERENCE COSTS (Per 1M Requests)\")\n",
    "    print(f\"   Base model: ${results['base_inference_cost_per_1m_requests']:,.2f}\")\n",
    "    print(f\"   Fine-tuned model: ${results['finetuned_inference_cost_per_1m_requests']:,.2f}\")\n",
    "    print(f\"   Additional cost: ${results['inference_cost_increase_per_1m_requests']:,.2f} (‚¨ÜÔ∏è {((results['finetuned_inference_cost_per_1m_requests'] / results['base_inference_cost_per_1m_requests']) - 1) * 100:.0f}%)\\n\")\n",
    "\n",
    "    print(f\"‚öñÔ∏è BREAK-EVEN ANALYSIS\")\n",
    "    if results['break_even_requests'] != \"N/A\":\n",
    "        print(f\"   Break-even at: {results['break_even_requests']:,} requests\")\n",
    "        print(f\"   After this point, inference costs exceed training costs!\\n\")\n",
    "    else:\n",
    "        print(f\"   Break-even: Not applicable\\n\")\n",
    "\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "print(\"‚úÖ Cost calculator functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDfMrJsgzweY"
   },
   "source": [
    "## üí° Let's Calculate Real Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X4_w3xwzweY"
   },
   "outputs": [],
   "source": [
    "# Scenario 1: Small fine-tuning project (100 examples)\n",
    "print(\"\\nüìù Scenario 1: Small Project (Quick Experiment)\")\n",
    "print(\"   Use case: Testing if fine-tuning helps with your use case\")\n",
    "print(\"   Dataset: 100 examples, ~500 tokens each\")\n",
    "\n",
    "results_small = calculate_finetuning_costs(\n",
    "    num_examples=100,\n",
    "    avg_tokens_per_example=500,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_small, 100)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚úÖ Low training cost - good for experimentation\")\n",
    "print(\"   ‚ö†Ô∏è May not be enough data for significant improvement\")\n",
    "print(\"   ‚úÖ Quick to iterate if results aren't good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvXMvG75zweY"
   },
   "outputs": [],
   "source": [
    "# Scenario 2: Medium fine-tuning project (500 examples)\n",
    "print(\"\\nüìù Scenario 2: Medium Project (Standard Production)\")\n",
    "print(\"   Use case: Customer service chatbot with brand voice\")\n",
    "print(\"   Dataset: 500 examples, ~400 tokens each\")\n",
    "\n",
    "results_medium = calculate_finetuning_costs(\n",
    "    num_examples=500,\n",
    "    avg_tokens_per_example=400,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_medium, 500)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚úÖ Balanced cost-benefit ratio\")\n",
    "print(\"   ‚úÖ Usually sufficient for style/format learning\")\n",
    "print(\"   ‚ö†Ô∏è Inference costs start adding up at scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yNZ9XjXzweY"
   },
   "outputs": [],
   "source": [
    "# Scenario 3: Large fine-tuning project (1000 examples)\n",
    "print(\"\\nüìù Scenario 3: Large Project (Comprehensive)\")\n",
    "print(\"   Use case: Multi-domain chatbot with complex behaviors\")\n",
    "print(\"   Dataset: 1000 examples, ~600 tokens each\")\n",
    "\n",
    "results_large = calculate_finetuning_costs(\n",
    "    num_examples=1000,\n",
    "    avg_tokens_per_example=600,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_large, 1000)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚ö†Ô∏è Significant upfront investment\")\n",
    "print(\"   ‚úÖ High-quality results expected\")\n",
    "print(\"   ‚ö†Ô∏è Inference costs become major factor at scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiwGkMNmzweY"
   },
   "outputs": [],
   "source": [
    "# Scenario 4: Enterprise fine-tuning (5000 examples)\n",
    "print(\"\\nüìù Scenario 4: Enterprise Project (Maximum Quality)\")\n",
    "print(\"   Use case: Mission-critical application with strict requirements\")\n",
    "print(\"   Dataset: 5000 examples, ~500 tokens each\")\n",
    "\n",
    "results_enterprise = calculate_finetuning_costs(\n",
    "    num_examples=5000,\n",
    "    avg_tokens_per_example=500,\n",
    "    epochs=3\n",
    ")\n",
    "print_cost_analysis(results_enterprise, 5000)\n",
    "\n",
    "print(\"\\nüí≠ Analysis:\")\n",
    "print(\"   ‚ö†Ô∏è Very expensive - ensure this is necessary!\")\n",
    "print(\"   ‚ö†Ô∏è Consider if prompt engineering + RAG could work instead\")\n",
    "print(\"   ‚ö†Ô∏è Inference costs will be substantial - budget accordingly\")\n",
    "print(\"   ‚úÖ Only justified for high-value, high-volume applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_E0JahTzweZ"
   },
   "source": [
    "## üéØ Key Cost Insights\n",
    "\n",
    "### 1. **Training costs scale linearly**\n",
    "- 2x examples = 2x cost\n",
    "- BUT: Diminishing returns on quality!\n",
    "- Sweet spot: Usually 500-1500 examples\n",
    "\n",
    "### 2. **Inference costs are ongoing**\n",
    "- Fine-tuned models cost 3x more per request\n",
    "- At high volume, this exceeds training costs\n",
    "- **Critical consideration:** Calculate your expected volume!\n",
    "\n",
    "### 3. **Quality vs. Quantity trade-off**\n",
    "- 100 high-quality examples > 1000 mediocre examples\n",
    "- Focus on data quality, not just quantity\n",
    "- Manual curation is worth the effort\n",
    "\n",
    "### 4. **The Total Cost of Ownership**\n",
    "\n",
    "**Example:** Customer service chatbot\n",
    "- Training: $18 (one-time)\n",
    "- Inference (1M requests/month): $270/month extra cost\n",
    "- Annual cost: $18 + ($270 √ó 12) = $3,258\n",
    "\n",
    "**Question to ask:** *Is the improved performance worth $3,258/year?*\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Cost Optimization Strategies\n",
    "\n",
    "### Strategy 1: Start Small\n",
    "```\n",
    "100 examples ‚Üí Test ‚Üí Works? ‚Üí Add 400 more ‚Üí Evaluate\n",
    "```\n",
    "\n",
    "### Strategy 2: Distillation Path\n",
    "```\n",
    "1. Use GPT-4 for quality\n",
    "2. Generate many outputs\n",
    "3. Fine-tune gpt-5-nano on GPT-4 outputs\n",
    "4. Get 80% of quality at 10% of cost\n",
    "```\n",
    "\n",
    "### Strategy 3: Hybrid Approach\n",
    "```\n",
    "Fine-tune for format ‚Üí Use base model with RAG for knowledge\n",
    "```\n",
    "\n",
    "### Strategy 4: Batch Processing\n",
    "```\n",
    "Non-urgent requests ‚Üí Process in batches ‚Üí 50% cost reduction\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** The cheapest fine-tuning is the one you don't need to do!\n",
    "\n",
    "Always exhaust prompt engineering and RAG before considering fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAgx0GBazweZ"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 3: Supervised Fine-Tuning (SFT)\n",
    "\n",
    "## üìñ What is Supervised Fine-Tuning?\n",
    "\n",
    "**Supervised Fine-Tuning (SFT)** is the most straightforward fine-tuning approach:\n",
    "\n",
    "**Core Concept:**\n",
    "> \"Here are perfect examples of inputs and their ideal outputs. Learn to copy this pattern.\"\n",
    "\n",
    "**How it works:**\n",
    "1. Provide pairs of (input ‚Üí desired output)\n",
    "2. Model learns to predict outputs given inputs\n",
    "3. Model adjusts weights to minimize difference between its output and your examples\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Technical Deep Dive\n",
    "\n",
    "**Training Process:**\n",
    "```\n",
    "For each example in dataset:\n",
    "    1. Model sees: \"User: How do I reset my password?\"\n",
    "    2. Model generates: \"Click on forgot password...\"\n",
    "    3. Compare to your example: \"Here's how to reset your password: 1) Click...\"\n",
    "    4. Calculate loss (difference)\n",
    "    5. Update model weights to reduce this difference\n",
    "    6. Repeat thousands of times\n",
    "```\n",
    "\n",
    "**What the model learns:**\n",
    "- **Patterns in format:** If all examples use JSON ‚Üí model outputs JSON\n",
    "- **Consistency in style:** If all examples are formal ‚Üí model becomes formal\n",
    "- **Specific phrasings:** If all examples start with \"Here's how\" ‚Üí model copies this\n",
    "- **Edge case handling:** If examples show refusals ‚Üí model learns when to refuse\n",
    "\n",
    "**What the model does NOT learn:**\n",
    "- ‚ùå New facts (use RAG instead)\n",
    "- ‚ùå Better reasoning (use better base model)\n",
    "- ‚ùå External knowledge (use tools/APIs)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ When to Use SFT\n",
    "\n",
    "### Perfect for:\n",
    "1. **Consistent output formatting** (JSON schemas, XML, structured data)\n",
    "2. **Brand voice enforcement** (specific tone, emoji usage, greetings)\n",
    "3. **Template following** (company-specific response structures)\n",
    "4. **Code style compliance** (naming conventions, documentation patterns)\n",
    "5. **Reducing latency** (distilling larger model behavior into smaller model)\n",
    "\n",
    "### Signs SFT is right:\n",
    "- ‚úÖ You have clear \"right answers\" or \"correct formats\"\n",
    "- ‚úÖ Consistency is more important than creativity\n",
    "- ‚úÖ You can describe success objectively\n",
    "- ‚úÖ Prompt engineering gets close but not reliable enough\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå When NOT to Use SFT\n",
    "\n",
    "### Bad for:\n",
    "1. **Teaching new information** ‚Üí Use RAG\n",
    "2. **Subjective quality improvements** ‚Üí Use preference-based tuning\n",
    "3. **Complex multi-objective optimization** ‚Üí Use RLHF\n",
    "4. **Fixing hallucinations** ‚Üí Won't work, may make it worse\n",
    "\n",
    "### Signs SFT is wrong:\n",
    "- ‚ùå You need to update knowledge frequently\n",
    "- ‚ùå \"Better\" is subjective and varies by context\n",
    "- ‚ùå You want model to be \"smarter\"\n",
    "- ‚ùå You don't have clear examples of correct behavior\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Requirements\n",
    "\n",
    "**Minimum viable:** 50-100 examples\n",
    "- Good for: Testing if fine-tuning helps\n",
    "- Quality: May be inconsistent\n",
    "\n",
    "**Recommended:** 500-1000 examples\n",
    "- Good for: Production use\n",
    "- Quality: Reliable and consistent\n",
    "\n",
    "**Maximum useful:** 5000-10,000 examples\n",
    "- Good for: Complex behaviors, multiple patterns\n",
    "- Quality: Diminishing returns above this\n",
    "\n",
    "**Data quality > Data quantity**\n",
    "- 100 perfect examples > 1000 mediocre examples\n",
    "- Consistency is critical\n",
    "- Remove outliers and errors\n",
    "\n",
    "---\n",
    "\n",
    "Let's see SFT in action with three real-world use cases! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1U4wPJ5zweZ"
   },
   "source": [
    "---\n",
    "\n",
    "## üîß How to Actually Fine-Tune with OpenAI (SFT)\n",
    "\n",
    "**Note:** This code is educational and will NOT be executed in this notebook.\n",
    "\n",
    "Here's the complete process for Supervised Fine-Tuning on OpenAI's platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OHMSAZszweZ"
   },
   "outputs": [],
   "source": [
    "# Step 1: Prepare your data in JSONL format\n",
    "# Each line is a JSON object with 'messages' array\n",
    "\n",
    "import json\n",
    "\n",
    "# Example: Converting our customer service data to JSONL\n",
    "training_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you!\"}\n",
    "        ]\n",
    "    },\n",
    "    # ... more examples\n",
    "]\n",
    "\n",
    "# Save as JSONL file\n",
    "with open('training_data.jsonl', 'w') as f:\n",
    "    for example in training_data:\n",
    "        f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "print(\"‚úÖ Training data prepared: training_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_3SjfIFzwea"
   },
   "outputs": [],
   "source": [
    "# Step 2: Upload the training file to OpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=\"your-api-key-here\")  # Replace with your API key\n",
    "\n",
    "# Upload training file\n",
    "training_file = client.files.create(\n",
    "    file=open(\"training_data.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ File uploaded: {training_file.id}\")\n",
    "print(f\"   Status: {training_file.status}\")\n",
    "print(f\"   Filename: {training_file.filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wR_M2d3wzwea"
   },
   "outputs": [],
   "source": [
    "# Step 3: Create a fine-tuning job\n",
    "\n",
    "# Start fine-tuning\n",
    "fine_tune_job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # or gpt-5-nano, gpt-3.5-turbo\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3,  # Number of training epochs (default: auto)\n",
    "    },\n",
    "    suffix=\"customer-service-v1\"  # Optional: custom name suffix\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Fine-tuning job created: {fine_tune_job.id}\")\n",
    "print(f\"   Status: {fine_tune_job.status}\")\n",
    "print(f\"   Model: {fine_tune_job.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNbwb-UEzwea"
   },
   "outputs": [],
   "source": [
    "# Step 4: Monitor training progress\n",
    "\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    job = client.fine_tuning.jobs.retrieve(fine_tune_job.id)\n",
    "\n",
    "    print(f\"Status: {job.status}\")\n",
    "\n",
    "    if job.status == \"succeeded\":\n",
    "        print(f\"\\n‚úÖ Fine-tuning completed!\")\n",
    "        print(f\"   Fine-tuned model: {job.fine_tuned_model}\")\n",
    "        break\n",
    "    elif job.status == \"failed\":\n",
    "        print(f\"\\n‚ùå Fine-tuning failed: {job.error}\")\n",
    "        break\n",
    "\n",
    "    # Wait before checking again\n",
    "    time.sleep(60)  # Check every minute\n",
    "\n",
    "# Optional: View training events\n",
    "events = client.fine_tuning.jobs.list_events(fine_tune_job.id, limit=10)\n",
    "for event in events.data:\n",
    "    print(f\"{event.created_at}: {event.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhBmctzOzwea"
   },
   "outputs": [],
   "source": [
    "# Step 5: Use your fine-tuned model\n",
    "\n",
    "fine_tuned_model_id = job.fine_tuned_model\n",
    "\n",
    "# Make a request to your fine-tuned model\n",
    "response = client.chat.completions.create(\n",
    "    model=fine_tuned_model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a customer service agent.\"},\n",
    "        {\"role\": \"user\", \"content\": \"My order hasn't arrived yet.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"\\nü§ñ Fine-tuned model response:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Compare with base model\n",
    "base_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Base model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a customer service agent.\"},\n",
    "        {\"role\": \"user\", \"content\": \"My order hasn't arrived yet.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Base model response:\")\n",
    "print(base_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wmzqG44zwea"
   },
   "source": [
    "### üí∞ Cost Estimation for This Job\n",
    "\n",
    "```python\n",
    "# Calculate costs\n",
    "num_examples = 500\n",
    "avg_tokens_per_example = 400\n",
    "epochs = 3\n",
    "\n",
    "total_tokens = num_examples * avg_tokens_per_example * epochs\n",
    "training_cost = (total_tokens / 1_000_000) * 0.10  # $0.10 per 1M tokens\n",
    "\n",
    "print(f\"Estimated training cost: ${training_cost:.2f}\")\n",
    "```\n",
    "\n",
    "**Remember:**\n",
    "- Fine-tuned models cost 3x more per request for inference\n",
    "- Budget for both training AND ongoing usage\n",
    "- Start small (100-200 examples) to test effectiveness\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iINvS0Tfzweb"
   },
   "source": [
    "## üíº SFT Use Case #1: Customer Service Brand Voice\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Hip e-commerce startup targeting Gen Z\n",
    "- Problem: Generic AI responses don't match brand personality\n",
    "- Goal: Every response should feel on-brand (casual, emoji-friendly, empathetic)\n",
    "\n",
    "**Why SFT?**\n",
    "- ‚úÖ Clear pattern to copy (brand voice guidelines)\n",
    "- ‚úÖ Consistency is key (all responses should feel similar)\n",
    "- ‚úÖ Prompt engineering gets close but drifts over time\n",
    "\n",
    "**What we're teaching:**\n",
    "- Tone (casual but professional)\n",
    "- Emoji usage (tasteful, not excessive)\n",
    "- Greeting/closing patterns\n",
    "- Empathy expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcxvExu9zweb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mock Dataset: Customer Service Brand Voice\n",
    "# This shows the EXACT format OpenAI expects for SFT\n",
    "\n",
    "sft_customer_service_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"My order hasn't arrived yet and it's been 5 days. I'm getting worried.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Oh no, I totally get why you're worried! üòü Let me look into this for you right away.\\n\\nI've checked your order #TT-12847 and I can see it's currently with our shipping partner. It looks like there was a small delay at the distribution center, but the good news is it's already on its way to you! üì¶\\n\\nYou should receive it within the next 2 business days. To make up for the wait, I'm adding a 15% discount code to your account (code: SORRY15) for your next purchase.\\n\\nIs there anything else I can help you with today? üíô\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"The hoodie I received is the wrong size. Can I return it?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Ah, sizing issues are the worst! üòÖ Don't worry though, we've got you covered.\\n\\nYes, absolutely! You can return it within 30 days for a full refund or exchange. Here's the super easy process:\\n\\n1Ô∏è‚É£ Go to our website ‚Üí Your Orders ‚Üí Select this hoodie\\n2Ô∏è‚É£ Click \\\"Return or Exchange\\\"\\n3Ô∏è‚É£ Print the prepaid shipping label\\n4Ô∏è‚É£ Drop it off at any post office\\n\\nWe'll send you the correct size as soon as we receive your return! Usually takes about 5-7 days total.\\n\\nNeed any help with the process or have questions about sizing? I'm here! ‚ú®\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Do you have this jacket in blue?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Great question! üíô Let me check that for you.\\n\\nYes! The CloudFlex Jacket is available in Ocean Blue in sizes XS-XL. It's actually one of our most popular colors this season!\\n\\nWould you like me to send you a direct link? Or I can help you add it to your cart right now! üõçÔ∏è\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I got charged twice for the same order! This is unacceptable.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Oh wow, that's definitely not okay! üòü I'm really sorry this happened - let me fix this immediately.\\n\\nI've checked your account and you're right - there was a duplicate charge of $67.99. This was a processing error on our end, and I've already initiated a refund for the duplicate charge. You should see it back in your account within 3-5 business days depending on your bank.\\n\\nAs an apology for this hassle, I'm also crediting your account with $15 store credit (already applied!).\\n\\nI've flagged this issue with our payment team to make sure it doesn't happen again. Is there anything else I can do to make this right? üíô\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a customer service agent for TrendyThreads, a Gen Z fashion brand. Be friendly, casual, use appropriate emojis, and show genuine empathy. Keep responses concise but warm.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Thanks for helping me with my return!\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"You're so welcome! üåü Happy to help anytime!\\n\\nIf you need anything else or have questions when your exchange arrives, just reach out. We're always here for you! üíô\\n\\nHave an awesome day! ‚ú®\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display as a readable format\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíº SFT USE CASE #1: Customer Service Brand Voice\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(sft_customer_service_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "\n",
    "    messages = example[\"messages\"]\n",
    "\n",
    "    # Skip system message in display (but it's included in training)\n",
    "    for msg in messages:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            print(f\"üë§ USER:\\n{msg['content']}\\n\")\n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            print(f\"ü§ñ ASSISTANT:\\n{msg['content']}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS FROM THESE EXAMPLES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Tone & Voice:**\n",
    "   - Casual but professional (\\\"Let me check that for you\\\")\n",
    "   - Empathetic acknowledgment (\\\"I totally get why you're worried\\\")\n",
    "   - Positive language (\\\"good news\\\", \\\"Great question!\\\")\n",
    "\n",
    "2. **Emoji Usage:**\n",
    "   - 1-3 emojis per response (not excessive)\n",
    "   - Contextually appropriate (üòü for problems, üíô for warmth)\n",
    "   - Enhances feeling, doesn't replace words\n",
    "\n",
    "3. **Structure:**\n",
    "   - Acknowledge emotion/issue first\n",
    "   - Provide solution or information\n",
    "   - Offer additional help\n",
    "   - Warm closing\n",
    "\n",
    "4. **Problem Handling:**\n",
    "   - Immediate apology when appropriate\n",
    "   - Take ownership (\\\"I've already initiated...\\\")\n",
    "   - Offer compensation for errors\n",
    "   - Follow up question\n",
    "\n",
    "5. **Consistency:**\n",
    "   - Always ends with warmth\n",
    "   - Uses \\\"we/us\\\" for brand\n",
    "   - Balances friendliness with professionalism\n",
    "   - Never dismissive or robotic\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚ö†Ô∏è IMPORTANT: These examples show CONSISTENT patterns!\")\n",
    "print(\"   The model learns from repetition across many examples.\")\n",
    "print(\"   In production, you'd need 500-1000 examples like these.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lnWHGb4zweb"
   },
   "source": [
    "## üìä SFT Use Case #2: Structured JSON Output\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Invoice processing automation\n",
    "- Problem: Need to extract data from invoices into exact JSON schema\n",
    "- Goal: 100% consistent JSON format, specific field names, proper data types\n",
    "\n",
    "**Why SFT?**\n",
    "- ‚úÖ Exact format requirements (can't vary)\n",
    "- ‚úÖ Prompt engineering gets 80% right, but 20% have format errors\n",
    "- ‚úÖ Even with structured outputs, need specific business field names\n",
    "- ‚úÖ Need consistent handling of edge cases (missing data, unclear amounts)\n",
    "\n",
    "**What we're teaching:**\n",
    "- Exact JSON schema\n",
    "- Field naming conventions\n",
    "- Data type consistency\n",
    "- Null handling for missing data\n",
    "- Edge case patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-Hg4L7rzweb"
   },
   "outputs": [],
   "source": [
    "# Mock Dataset: Structured JSON Output for Invoice Extraction\n",
    "\n",
    "sft_json_extraction_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"INVOICE\\n\\nInvoice #: INV-2024-001\\nDate: January 15, 2024\\n\\nFrom:\\nTech Supplies Inc.\\n123 Silicon Valley Rd, San Jose, CA 95110\\n\\nLine Items:\\n- Dell Monitor 27\\\" x 5 @ $299.99 = $1,499.95\\n- USB-C Cable x 10 @ $12.99 = $129.90\\n- Wireless Mouse x 5 @ $34.99 = $174.95\\n\\nSubtotal: $1,804.80\\nTax (8.5%): $153.41\\nTotal: $1,958.21\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"INV-2024-001\\\",\\n  \\\"invoice_date\\\": \\\"2024-01-15\\\",\\n  \\\"vendor_name\\\": \\\"Tech Supplies Inc.\\\",\\n  \\\"vendor_address\\\": \\\"123 Silicon Valley Rd, San Jose, CA 95110\\\",\\n  \\\"total_amount\\\": 1958.21,\\n  \\\"tax_amount\\\": 153.41,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Dell Monitor 27\\\\\\\"\\\",\\n      \\\"quantity\\\": 5,\\n      \\\"unit_price\\\": 299.99,\\n      \\\"total_price\\\": 1499.95\\n    },\\n    {\\n      \\\"description\\\": \\\"USB-C Cable\\\",\\n      \\\"quantity\\\": 10,\\n      \\\"unit_price\\\": 12.99,\\n      \\\"total_price\\\": 129.90\\n    },\\n    {\\n      \\\"description\\\": \\\"Wireless Mouse\\\",\\n      \\\"quantity\\\": 5,\\n      \\\"unit_price\\\": 34.99,\\n      \\\"total_price\\\": 174.95\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Invoice Number: 2024-Q1-789\\nDate: 03/22/2024\\n\\nBill From: Office Depot\\n500 Commerce St, Austin TX 78701\\n\\nItems Purchased:\\nPrinter Paper (Case) - Qty: 3 - $42.50 each\\nStapler - Qty: 8 - $8.99 each\\n\\nTotal Due: $199.42 (includes tax)\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"2024-Q1-789\\\",\\n  \\\"invoice_date\\\": \\\"2024-03-22\\\",\\n  \\\"vendor_name\\\": \\\"Office Depot\\\",\\n  \\\"vendor_address\\\": \\\"500 Commerce St, Austin TX 78701\\\",\\n  \\\"total_amount\\\": 199.42,\\n  \\\"tax_amount\\\": null,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Printer Paper (Case)\\\",\\n      \\\"quantity\\\": 3,\\n      \\\"unit_price\\\": 42.50,\\n      \\\"total_price\\\": 127.50\\n    },\\n    {\\n      \\\"description\\\": \\\"Stapler\\\",\\n      \\\"quantity\\\": 8,\\n      \\\"unit_price\\\": 8.99,\\n      \\\"total_price\\\": 71.92\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Receipt #ACC-9921\\n2024-02-10\\n\\nAcme Consulting Services\\nAddress not provided\\n\\nConsulting Services (February) - $5,000.00\\n\\nAmount Due: $5,000.00\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"ACC-9921\\\",\\n  \\\"invoice_date\\\": \\\"2024-02-10\\\",\\n  \\\"vendor_name\\\": \\\"Acme Consulting Services\\\",\\n  \\\"vendor_address\\\": null,\\n  \\\"total_amount\\\": 5000.00,\\n  \\\"tax_amount\\\": null,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Consulting Services (February)\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 5000.00,\\n      \\\"total_price\\\": 5000.00\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Invoice: WEB-2024-456\\nIssued: 01/30/2024\\n\\nCompany: WebHost Pro\\nLocation: 789 Server Lane, Seattle WA 98101\\n\\nServices:\\n‚Ä¢ Premium Hosting Plan (Annual) x 1 @ $599.00\\n‚Ä¢ Domain Registration (.com) x 2 @ $14.99\\n‚Ä¢ SSL Certificate x 1 @ $89.00\\n\\nSubtotal: $718.98\\nSales Tax (10%): $71.90\\nGrand Total: $790.88\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"WEB-2024-456\\\",\\n  \\\"invoice_date\\\": \\\"2024-01-30\\\",\\n  \\\"vendor_name\\\": \\\"WebHost Pro\\\",\\n  \\\"vendor_address\\\": \\\"789 Server Lane, Seattle WA 98101\\\",\\n  \\\"total_amount\\\": 790.88,\\n  \\\"tax_amount\\\": 71.90,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Premium Hosting Plan (Annual)\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 599.00,\\n      \\\"total_price\\\": 599.00\\n    },\\n    {\\n      \\\"description\\\": \\\"Domain Registration (.com)\\\",\\n      \\\"quantity\\\": 2,\\n      \\\"unit_price\\\": 14.99,\\n      \\\"total_price\\\": 29.98\\n    },\\n    {\\n      \\\"description\\\": \\\"SSL Certificate\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 89.00,\\n      \\\"total_price\\\": 89.00\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an invoice data extraction system. Extract information and output in JSON format with these exact fields: invoice_number, invoice_date, vendor_name, vendor_address, total_amount, tax_amount, line_items (array of objects with: description, quantity, unit_price, total_price). Use null for missing values.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"BILL\\n\\nRef: MISC-045\\nWhen: April 5, 2024\\n\\nSupplier: Random Parts Co\\n\\nPurchased: Various hardware components\\nCost: $2,450\\n\\nPaid in full.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\\n  \\\"invoice_number\\\": \\\"MISC-045\\\",\\n  \\\"invoice_date\\\": \\\"2024-04-05\\\",\\n  \\\"vendor_name\\\": \\\"Random Parts Co\\\",\\n  \\\"vendor_address\\\": null,\\n  \\\"total_amount\\\": 2450.00,\\n  \\\"tax_amount\\\": null,\\n  \\\"line_items\\\": [\\n    {\\n      \\\"description\\\": \\\"Various hardware components\\\",\\n      \\\"quantity\\\": 1,\\n      \\\"unit_price\\\": 2450.00,\\n      \\\"total_price\\\": 2450.00\\n    }\\n  ]\\n}\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SFT USE CASE #2: Structured JSON Output\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(sft_json_extraction_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "\n",
    "    messages = example[\"messages\"]\n",
    "    user_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"user\")\n",
    "    assistant_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"assistant\")\n",
    "\n",
    "    print(f\"üìÑ INPUT (Invoice Text):\\n{user_msg}\\n\")\n",
    "    print(f\"üìã OUTPUT (Extracted JSON):\\n{assistant_msg}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS FROM THESE EXAMPLES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. **Exact Schema Adherence:**\n",
    "   - ALWAYS includes all fields (invoice_number, invoice_date, etc.)\n",
    "   - NEVER adds extra fields not in schema\n",
    "   - NEVER renames fields\n",
    "\n",
    "2. **Data Type Consistency:**\n",
    "   - Numbers are numbers (not strings): 1958.21, not \\\"1958.21\\\"\n",
    "   - Dates in ISO format: \\\"2024-01-15\\\"\n",
    "   - Quantities are integers: 5, not 5.0\n",
    "   - Prices are floats with 2 decimals: 299.99\n",
    "\n",
    "3. **Null Handling:**\n",
    "   - Missing tax? ‚Üí \\\"tax_amount\\\": null\n",
    "   - Missing address? ‚Üí \\\"vendor_address\\\": null\n",
    "   - NEVER uses empty strings or \\\"N/A\\\"\n",
    "\n",
    "4. **Edge Case Patterns:**\n",
    "   - Vague items (\\\"Various components\\\") ‚Üí Still extracted\n",
    "   - Different date formats ‚Üí Normalized to ISO\n",
    "   - Included tax in total ‚Üí tax_amount: null (not calculable)\n",
    "   - Single line item ‚Üí Still use array format\n",
    "\n",
    "5. **Format Variations Handled:**\n",
    "   - \\\"Invoice #\\\" vs \\\"Receipt #\\\" vs \\\"Ref:\" ‚Üí All extracted\n",
    "   - Different layouts (table vs list vs paragraph)\n",
    "   - Bullet points (‚Ä¢, -, no marker)\n",
    "   - Currency symbols ($) ‚Üí Stripped from numbers\n",
    "\n",
    "‚ö†Ô∏è CRITICAL: Without fine-tuning, GPT might:\n",
    "   - Add \\\"currency\\\" field ‚Üí Schema violation\n",
    "   - Use \\\"N/A\\\" instead of null ‚Üí Type error\n",
    "   - Format dates inconsistently\n",
    "   - Include dollar signs in numbers\n",
    "\n",
    "‚úÖ After fine-tuning: 100% schema compliance\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° WHY SFT BEATS PROMPT ENGINEERING HERE:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Prompt engineering can get you 80-90% accuracy, but:\n",
    "- Occasional schema violations (extra fields, wrong names)\n",
    "- Inconsistent null handling\n",
    "- Type errors (strings vs numbers)\n",
    "- Date format variations\n",
    "\n",
    "Fine-tuning achieves 98-99% accuracy with:\n",
    "- Perfect schema adherence\n",
    "- Consistent edge case handling\n",
    "- Reliable null usage\n",
    "- Proper data types\n",
    "\n",
    "For production systems with strict requirements, this 10-20%\n",
    "improvement is worth the investment.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VR_T7aM8zwec"
   },
   "source": [
    "## üíª SFT Use Case #3: Code Generation with Style Guide\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Enterprise software development team\n",
    "- Problem: AI generates code that doesn't follow company standards\n",
    "- Goal: Every generated function follows exact style guide\n",
    "\n",
    "**Why SFT?**\n",
    "- ‚úÖ Strict company coding standards (docstrings, type hints, naming)\n",
    "- ‚úÖ Consistency across entire codebase\n",
    "- ‚úÖ Prompt engineering produces \"good\" code but wrong style\n",
    "- ‚úÖ Need to enforce non-negotiable patterns\n",
    "\n",
    "**What we're teaching:**\n",
    "- Specific docstring format (Google style)\n",
    "- Type hints everywhere\n",
    "- Naming conventions (snake_case functions, PascalCase classes)\n",
    "- Error handling patterns\n",
    "- Logging practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sjQvzSSzwec"
   },
   "outputs": [],
   "source": [
    "# Mock Dataset: Code Generation with Style Guide\n",
    "\n",
    "sft_code_generation_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a code generation assistant for TechCorp. Generate Python code following our style guide: Google-style docstrings, full type hints, snake_case for functions, PascalCase for classes, explicit error handling with logging, and comprehensive input validation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Create a function that calculates the average of a list of numbers.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"import logging\\nfrom typing import List, Union\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\ndef calculate_average(numbers: List[Union[int, float]]) -> float:\\n    \\\"\\\"\\\"Calculate the arithmetic mean of a list of numbers.\\n    \\n    Args:\\n        numbers: A list of integers or floats to average.\\n            \\n    Returns:\\n        The arithmetic mean of the input numbers.\\n        \\n    Raises:\\n        ValueError: If the input list is empty.\\n        TypeError: If the input contains non-numeric values.\\n        \\n    Examples:\\n        >>> calculate_average([1, 2, 3, 4, 5])\\n        3.0\\n        >>> calculate_average([10.5, 20.5])\\n        15.5\\n    \\\"\\\"\\\"\\n    logger.debug(f\\\"Calculating average for {len(numbers)} numbers\\\")\\n    \\n    # Input validation\\n    if not numbers:\\n        logger.error(\\\"Cannot calculate average of empty list\\\")\\n        raise ValueError(\\\"Input list cannot be empty\\\")\\n    \\n    if not all(isinstance(n, (int, float)) for n in numbers):\\n        logger.error(\\\"Input list contains non-numeric values\\\")\\n        raise TypeError(\\\"All elements must be integers or floats\\\")\\n    \\n    # Calculate average\\n    result = sum(numbers) / len(numbers)\\n    logger.info(f\\\"Average calculated: {result}\\\")\\n    \\n    return result\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a code generation assistant for TechCorp. Generate Python code following our style guide: Google-style docstrings, full type hints, snake_case for functions, PascalCase for classes, explicit error handling with logging, and comprehensive input validation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Create a class that represents a User with name, email, and age.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"import logging\\nimport re\\nfrom typing import Optional\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\nclass User:\\n    \\\"\\\"\\\"Represents a user in the system.\\n    \\n    This class encapsulates user information including name, email, and age,\\n    with built-in validation for each field.\\n    \\n    Attributes:\\n        name: The user's full name.\\n        email: The user's email address.\\n        age: The user's age in years.\\n        \\n    Examples:\\n        >>> user = User(name=\\\"John Doe\\\", email=\\\"john@example.com\\\", age=30)\\n        >>> print(user.email)\\n        john@example.com\\n    \\\"\\\"\\\"\\n    \\n    def __init__(\\n        self,\\n        name: str,\\n        email: str,\\n        age: int\\n    ) -> None:\\n        \\\"\\\"\\\"Initialize a new User instance.\\n        \\n        Args:\\n            name: The user's full name (must be non-empty).\\n            email: The user's email address (must be valid format).\\n            age: The user's age in years (must be positive).\\n            \\n        Raises:\\n            ValueError: If any input validation fails.\\n        \\\"\\\"\\\"\\n        logger.debug(f\\\"Creating new User: {name}\\\")\\n        \\n        self._validate_and_set_name(name)\\n        self._validate_and_set_email(email)\\n        self._validate_and_set_age(age)\\n        \\n        logger.info(f\\\"User created successfully: {self.email}\\\")\\n    \\n    def _validate_and_set_name(self, name: str) -> None:\\n        \\\"\\\"\\\"Validate and set the user's name.\\n        \\n        Args:\\n            name: The name to validate and set.\\n            \\n        Raises:\\n            ValueError: If name is empty or not a string.\\n        \\\"\\\"\\\"\\n        if not isinstance(name, str):\\n            logger.error(\\\"Name must be a string\\\")\\n            raise ValueError(\\\"Name must be a string\\\")\\n        \\n        if not name.strip():\\n            logger.error(\\\"Name cannot be empty\\\")\\n            raise ValueError(\\\"Name cannot be empty\\\")\\n        \\n        self.name = name.strip()\\n    \\n    def _validate_and_set_email(self, email: str) -> None:\\n        \\\"\\\"\\\"Validate and set the user's email address.\\n        \\n        Args:\\n            email: The email address to validate and set.\\n            \\n        Raises:\\n            ValueError: If email format is invalid.\\n        \\\"\\\"\\\"\\n        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$'\\n        \\n        if not isinstance(email, str) or not re.match(email_pattern, email):\\n            logger.error(f\\\"Invalid email format: {email}\\\")\\n            raise ValueError(\\\"Invalid email format\\\")\\n        \\n        self.email = email.lower()\\n    \\n    def _validate_and_set_age(self, age: int) -> None:\\n        \\\"\\\"\\\"Validate and set the user's age.\\n        \\n        Args:\\n            age: The age to validate and set.\\n            \\n        Raises:\\n            ValueError: If age is not a positive integer.\\n        \\\"\\\"\\\"\\n        if not isinstance(age, int):\\n            logger.error(\\\"Age must be an integer\\\")\\n            raise ValueError(\\\"Age must be an integer\\\")\\n        \\n        if age <= 0 or age > 150:\\n            logger.error(f\\\"Age out of valid range: {age}\\\")\\n            raise ValueError(\\\"Age must be between 1 and 150\\\")\\n        \\n        self.age = age\\n    \\n    def __repr__(self) -> str:\\n        \\\"\\\"\\\"Return a string representation of the User.\\n        \\n        Returns:\\n            A string representation including name, email, and age.\\n        \\\"\\\"\\\"\\n        return f\\\"User(name='{self.name}', email='{self.email}', age={self.age})\\\"\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a code generation assistant for TechCorp. Generate Python code following our style guide: Google-style docstrings, full type hints, snake_case for functions, PascalCase for classes, explicit error handling with logging, and comprehensive input validation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write a function that reads a JSON file and returns the parsed data.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\"\"import json\\nimport logging\\nfrom pathlib import Path\\nfrom typing import Any, Dict, Union\\n\\nlogger = logging.getLogger(__name__)\\n\\n\\ndef read_json_file(file_path: Union[str, Path]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"Read and parse a JSON file.\\n    \\n    Args:\\n        file_path: Path to the JSON file (string or Path object).\\n        \\n    Returns:\\n        A dictionary containing the parsed JSON data.\\n        \\n    Raises:\\n        FileNotFoundError: If the specified file does not exist.\\n        json.JSONDecodeError: If the file contains invalid JSON.\\n        PermissionError: If the file cannot be read due to permissions.\\n        \\n    Examples:\\n        >>> data = read_json_file('config.json')\\n        >>> print(data['api_key'])\\n        'abc123'\\n    \\\"\\\"\\\"\\n    logger.debug(f\\\"Attempting to read JSON file: {file_path}\\\")\\n    \\n    # Convert string to Path object\\n    if isinstance(file_path, str):\\n        file_path = Path(file_path)\\n    \\n    # Validate file exists\\n    if not file_path.exists():\\n        logger.error(f\\\"File not found: {file_path}\\\")\\n        raise FileNotFoundError(f\\\"File not found: {file_path}\\\")\\n    \\n    # Validate it's a file (not directory)\\n    if not file_path.is_file():\\n        logger.error(f\\\"Path is not a file: {file_path}\\\")\\n        raise ValueError(f\\\"Path is not a file: {file_path}\\\")\\n    \\n    # Read and parse JSON\\n    try:\\n        with open(file_path, 'r', encoding='utf-8') as file:\\n            data = json.load(file)\\n            logger.info(f\\\"Successfully read JSON file: {file_path}\\\")\\n            return data\\n    \\n    except json.JSONDecodeError as e:\\n        logger.error(f\\\"Invalid JSON in file {file_path}: {str(e)}\\\")\\n        raise json.JSONDecodeError(\\n            f\\\"Invalid JSON in file {file_path}\\\",\\n            e.doc,\\n            e.pos\\n        )\\n    \\n    except PermissionError as e:\\n        logger.error(f\\\"Permission denied reading file {file_path}: {str(e)}\\\")\\n        raise PermissionError(f\\\"Cannot read file {file_path}: {str(e)}\\\")\\n    \\n    except Exception as e:\\n        logger.error(f\\\"Unexpected error reading file {file_path}: {str(e)}\\\")\\n        raise RuntimeError(f\\\"Failed to read file {file_path}: {str(e)}\\\")\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíª SFT USE CASE #3: Code Generation with Style Guide\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(sft_code_generation_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "\n",
    "    messages = example[\"messages\"]\n",
    "    user_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"user\")\n",
    "    assistant_msg = next(m[\"content\"] for m in messages if m[\"role\"] == \"assistant\")\n",
    "\n",
    "    print(f\"üí¨ REQUEST:\\n{user_msg}\\n\")\n",
    "    print(f\"üíª GENERATED CODE:\\n{assistant_msg}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS FROM THESE EXAMPLES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. **Docstring Format (Google Style):**\n",
    "   - Summary line first\n",
    "   - Blank line\n",
    "   - Detailed description\n",
    "   - Args section with type info\n",
    "   - Returns section\n",
    "   - Raises section\n",
    "   - Examples section with doctests\n",
    "\n",
    "2. **Type Hints Everywhere:**\n",
    "   - Function parameters: name: str\n",
    "   - Return types: -> float\n",
    "   - Complex types: List[Union[int, float]]\n",
    "   - Optional types: Optional[str]\n",
    "   - Import from typing module\n",
    "\n",
    "3. **Naming Conventions:**\n",
    "   - Functions: snake_case (calculate_average, read_json_file)\n",
    "   - Classes: PascalCase (User, DataProcessor)\n",
    "   - Private methods: _validate_and_set_name\n",
    "   - Constants: UPPER_SNAKE_CASE (implied)\n",
    "\n",
    "4. **Error Handling Pattern:**\n",
    "   - Validate all inputs\n",
    "   - Log errors before raising\n",
    "   - Raise specific exceptions\n",
    "   - Descriptive error messages\n",
    "   - Try-except with specific handling\n",
    "\n",
    "5. **Logging Practice:**\n",
    "   - Import logger at module level\n",
    "   - Debug for input values\n",
    "   - Info for successful operations\n",
    "   - Error for exceptions\n",
    "   - Structured log messages\n",
    "\n",
    "6. **Input Validation:**\n",
    "   - Check types explicitly\n",
    "   - Validate ranges/formats\n",
    "   - Handle edge cases (empty list, None, etc.)\n",
    "   - Provide clear error messages\n",
    "\n",
    "7. **Code Organization:**\n",
    "   - Imports at top (grouped: stdlib, third-party, local)\n",
    "   - Logger after imports\n",
    "   - Public methods first\n",
    "   - Private methods (prefixed with _) last\n",
    "   - Blank lines for readability\n",
    "\n",
    "‚ö†Ô∏è WITHOUT FINE-TUNING, GPT might:\n",
    "   - Use different docstring formats (Sphinx, NumPy)\n",
    "   - Omit type hints on some parameters\n",
    "   - Skip input validation\n",
    "   - Use generic exceptions (Exception instead of ValueError)\n",
    "   - Inconsistent logging (or none at all)\n",
    "   - Mix naming conventions\n",
    "\n",
    "‚úÖ AFTER FINE-TUNING:\n",
    "   - 100% compliance with style guide\n",
    "   - Consistent patterns across all generated code\n",
    "   - Proper error handling every time\n",
    "   - Code passes linting without changes\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° BUSINESS VALUE:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "For a development team:\n",
    "- Code review time reduced by 40% (no style discussions)\n",
    "- Onboarding faster (AI generates consistent examples)\n",
    "- Fewer bugs (consistent validation patterns)\n",
    "- Better maintainability (uniform codebase)\n",
    "- Automated code generation for boilerplate\n",
    "\n",
    "ROI Example:\n",
    "- 10 developers √ó 5 hours/week saved = 50 hours/week\n",
    "- At $50/hour = $2,500/week = $130,000/year\n",
    "- Fine-tuning cost: ~$500-2,000\n",
    "- Break-even: < 1 week\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UqDBms7zwec"
   },
   "source": [
    "## üìä SFT Summary\n",
    "\n",
    "### ‚úÖ Strengths\n",
    "\n",
    "1. **Simplicity**: Easiest fine-tuning approach to understand and implement\n",
    "2. **Clear Success Criteria**: You know exactly what \"right\" looks like\n",
    "3. **Data Collection**: Straightforward - just input-output pairs\n",
    "4. **Fast Training**: Converges quickly (usually 1-3 epochs)\n",
    "5. **Consistency**: Excellent for enforcing patterns and formats\n",
    "\n",
    "### ‚ùå Limitations\n",
    "\n",
    "1. **Can't Teach Subjective Quality**: \"Better\" must be objective\n",
    "2. **Risk of Overfitting**: Too many examples ‚Üí loss of generalization\n",
    "3. **No Nuance**: All examples weighted equally (good or bad)\n",
    "4. **Knowledge Limitations**: Can't add new facts effectively\n",
    "5. **Binary Learning**: Either follows pattern or doesn't - no middle ground\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Data Collection Tips for SFT\n",
    "\n",
    "#### 1. Quality Over Quantity\n",
    "```\n",
    "‚ùå 1000 mediocre examples with inconsistencies\n",
    "‚úÖ 500 perfect examples that are 100% consistent\n",
    "```\n",
    "\n",
    "#### 2. Remove Outliers\n",
    "```python\n",
    "# Review your dataset for:\n",
    "- Inconsistent formatting\n",
    "- Different writing styles\n",
    "- Errors or typos\n",
    "- Edge cases that shouldn't be patterns\n",
    "```\n",
    "\n",
    "#### 3. Cover Edge Cases\n",
    "```\n",
    "Include examples of:\n",
    "- Empty inputs\n",
    "- Maximum/minimum values\n",
    "- Unusual but valid inputs\n",
    "- Proper error handling\n",
    "```\n",
    "\n",
    "#### 4. Balance Your Dataset\n",
    "```\n",
    "If you have multiple patterns:\n",
    "- 30% common case A\n",
    "- 30% common case B\n",
    "- 20% edge case C\n",
    "- 20% edge case D\n",
    "\n",
    "Don't do:\n",
    "- 90% case A, 10% everything else\n",
    "```\n",
    "\n",
    "#### 5. Use Real Data\n",
    "```\n",
    "‚úÖ Actual customer questions + your best responses\n",
    "‚ùå Made-up examples that don't reflect reality\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ When SFT is the Best Choice\n",
    "\n",
    "**Use SFT when you can answer YES to all:**\n",
    "\n",
    "1. ‚úÖ Do I have clear examples of correct behavior?\n",
    "2. ‚úÖ Is \"correct\" objective and consistent?\n",
    "3. ‚úÖ Is the goal consistency rather than knowledge?\n",
    "4. ‚úÖ Have I exhausted prompt engineering?\n",
    "5. ‚úÖ Am I okay with the cost and inference overhead?\n",
    "\n",
    "**Common successful use cases:**\n",
    "- Customer service brand voice ‚úÖ\n",
    "- Structured output generation (JSON, XML) ‚úÖ\n",
    "- Code style enforcement ‚úÖ\n",
    "- Response template following ‚úÖ\n",
    "- Model distillation (GPT-4 ‚Üí gpt-5-nano) ‚úÖ\n",
    "\n",
    "---\n",
    "\n",
    "Next, let's explore **Preference-Based Fine-Tuning** for situations where \"better\" is subjective! üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlpDUnFCzwed"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 4: Preference-Based Fine-Tuning\n",
    "\n",
    "## üìñ What is Preference-Based Fine-Tuning?\n",
    "\n",
    "**Preference-Based Fine-Tuning** teaches models subjective quality by showing comparisons:\n",
    "\n",
    "**Core Concept:**\n",
    "> \"Response A is better than Response B for this input. Learn what makes responses better.\"\n",
    "\n",
    "**Key Difference from SFT:**\n",
    "- **SFT**: \"This is the ONE correct answer\"\n",
    "- **Preferences**: \"Both answers are valid, but this one is BETTER\"\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Technical Deep Dive\n",
    "\n",
    "**Training Process:**\n",
    "```\n",
    "For each example:\n",
    "    1. Model sees: \"How do I improve my credit score?\"\n",
    "    2. Two responses provided:\n",
    "       Response A (chosen): Empathetic, actionable, comprehensive\n",
    "       Response B (rejected): Correct but terse and unhelpful\n",
    "    3. Model learns: Response A > Response B\n",
    "    4. Adjusts to increase probability of A-style responses\n",
    "    5. Adjusts to decrease probability of B-style responses\n",
    "```\n",
    "\n",
    "**What the model learns:**\n",
    "- Subjective quality (helpfulness, tone, depth)\n",
    "- Contextual appropriateness\n",
    "- Balancing multiple objectives (accuracy + empathy)\n",
    "- When to be verbose vs. concise\n",
    "\n",
    "**What it does NOT learn:**\n",
    "- New facts (use RAG)\n",
    "- Complex multi-dimensional quality (use RLHF)\n",
    "- Exact formatting (use SFT)\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Concept: Both Responses Are \"Correct\"\n",
    "\n",
    "This is the critical insight that differentiates preference-based tuning:\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "User: \"How do I reset my password?\"\n",
    "\n",
    "Response A (Chosen): ‚úÖ\n",
    "\"I'd be happy to help you reset your password! Here's how:\n",
    "1. Click 'Forgot Password' on the login page\n",
    "2. Enter your email address\n",
    "3. Check your email for a reset link\n",
    "4. Click the link and create your new password\n",
    "\n",
    "The link expires in 24 hours. If you don't receive it within 5\n",
    "minutes, check your spam folder. Need any other help?\"\n",
    "\n",
    "Response B (Rejected): ‚úÖ (Still correct!)\n",
    "\"Click 'Forgot Password', enter your email, and follow the link.\"\n",
    "```\n",
    "\n",
    "**Why A is better:**\n",
    "- More helpful and complete\n",
    "- Anticipates follow-up questions\n",
    "- Warmer tone\n",
    "- Provides context\n",
    "\n",
    "**But B isn't wrong:**\n",
    "- Factually accurate\n",
    "- Answers the question\n",
    "- Just less helpful\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ When to Use Preference-Based Tuning\n",
    "\n",
    "### Perfect for:\n",
    "1. **Subjective quality improvements** (helpfulness, tone, depth)\n",
    "2. **Style preferences** (verbose vs. concise, formal vs. casual)\n",
    "3. **Contextual appropriateness** (when to be detailed vs. brief)\n",
    "4. **Empathy and tone** (warm vs. professional)\n",
    "5. **Refusal quality** (graceful vs. blunt)\n",
    "\n",
    "### Signs preference tuning is right:\n",
    "- ‚úÖ Multiple \"correct\" answers exist\n",
    "- ‚úÖ Quality is subjective but rankable\n",
    "- ‚úÖ You can get humans to consistently pick the better response\n",
    "- ‚úÖ You want to optimize for user satisfaction\n",
    "- ‚úÖ SFT is too rigid (you don't want ONE exact pattern)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå When NOT to Use Preference-Based Tuning\n",
    "\n",
    "### Bad for:\n",
    "1. **Exact formatting requirements** ‚Üí Use SFT\n",
    "2. **Teaching new knowledge** ‚Üí Use RAG\n",
    "3. **Complex multi-objective optimization** ‚Üí Use RLHF\n",
    "4. **Binary correctness** (right vs. wrong) ‚Üí Use SFT\n",
    "\n",
    "### Signs preference tuning is wrong:\n",
    "- ‚ùå You need exact output format\n",
    "- ‚ùå There's only ONE correct answer\n",
    "- ‚ùå Humans disagree on which response is better\n",
    "- ‚ùå You're optimizing for many dimensions simultaneously\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Requirements\n",
    "\n",
    "**Minimum viable:** 100-200 comparison pairs\n",
    "- Good for: Testing if preferences help\n",
    "- Quality: May see some improvement\n",
    "\n",
    "**Recommended:** 500-1500 comparison pairs\n",
    "- Good for: Production use\n",
    "- Quality: Reliable improvements\n",
    "\n",
    "**Maximum useful:** 5000-10,000 pairs\n",
    "- Good for: Fine-grained quality\n",
    "- Quality: Diminishing returns above this\n",
    "\n",
    "**Critical requirement: Consistency**\n",
    "- Humans must agree on rankings (>80% agreement)\n",
    "- Clear criteria for \"better\"\n",
    "- Same evaluators throughout dataset\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ DPO (Direct Preference Optimization)\n",
    "\n",
    "**Quick Technical Note:**\n",
    "\n",
    "Traditional preference learning used **RLHF** (complex, requires reward model).\n",
    "\n",
    "**DPO** (Direct Preference Optimization) is a newer, simpler approach:\n",
    "- Skip reward model training\n",
    "- Directly optimize from preferences\n",
    "- Faster and more stable\n",
    "- What OpenAI likely uses under the hood\n",
    "\n",
    "**You don't need to know the math, just know:**\n",
    "- DPO is the modern way to do preference learning\n",
    "- It's simpler and more reliable than old methods\n",
    "- OpenAI abstracts this complexity away\n",
    "\n",
    "---\n",
    "\n",
    "Let's see preference-based tuning in action with three use cases! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mliTVms3zwed"
   },
   "source": [
    "---\n",
    "\n",
    "## üîß How to Actually Fine-Tune with OpenAI (Preferences)\n",
    "\n",
    "**Note:** OpenAI doesn't directly expose preference-based fine-tuning via API yet.\n",
    "\n",
    "**Current approach:**\n",
    "\n",
    "1. **Option A: Use comparison data in SFT format**\n",
    "   - Include both chosen and rejected responses in training data\n",
    "   - Add explicit feedback in system messages\n",
    "\n",
    "2. **Option B: Use third-party tools**\n",
    "   - Hugging Face TRL library (Transformers Reinforcement Learning)\n",
    "   - Supports DPO (Direct Preference Optimization)\n",
    "   - Requires running your own infrastructure\n",
    "\n",
    "**Expected future API format:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc3DNNAhzwed"
   },
   "outputs": [],
   "source": [
    "# HYPOTHETICAL: How preference-based fine-tuning might work on OpenAI\n",
    "# (Not currently available as of 2025)\n",
    "\n",
    "import json\n",
    "\n",
    "# Prepare preference data in JSONL format\n",
    "preference_data = [\n",
    "    {\n",
    "        \"prompt\": [{\"role\": \"user\", \"content\": \"How do I reset my password?\"}],\n",
    "        \"chosen\": {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I'd be happy to help! Here's how: 1) Click 'Forgot Password'...\"\n",
    "        },\n",
    "        \"rejected\": {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Click forgot password and follow the link.\"\n",
    "        }\n",
    "    },\n",
    "    # ... more pairs\n",
    "]\n",
    "\n",
    "# Save as JSONL\n",
    "with open('preference_data.jsonl', 'w') as f:\n",
    "    for example in preference_data:\n",
    "        f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "print(\"‚úÖ Preference data prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdTA-ulhzwed"
   },
   "outputs": [],
   "source": [
    "# HYPOTHETICAL API usage (not real as of 2025)\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"your-api-key\")\n",
    "\n",
    "# Upload file\n",
    "file = client.files.create(\n",
    "    file=open(\"preference_data.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Create preference-based fine-tuning job\n",
    "# (This is speculative - API doesn't exist yet)\n",
    "fine_tune_job = client.fine_tuning.jobs.create(\n",
    "    training_file=file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    method=\"preference\",  # Hypothetical parameter\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3,\n",
    "        \"learning_rate\": 5e-5\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Job created: {fine_tune_job.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FkZzO5wzwed"
   },
   "source": [
    "### üîß Practical Alternative: Using Hugging Face\n",
    "\n",
    "For actual preference-based fine-tuning today, use Hugging Face's TRL library:\n",
    "\n",
    "```python\n",
    "from trl import DPOTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Prepare dataset with chosen/rejected pairs\n",
    "# ... dataset preparation ...\n",
    "\n",
    "# Train with DPO\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    beta=0.1,  # KL penalty coefficient\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "**Trade-offs:**\n",
    "- ‚úÖ Full control over preference training\n",
    "- ‚úÖ Use any base model\n",
    "- ‚ùå Requires your own infrastructure\n",
    "- ‚ùå More complex than OpenAI API\n",
    "- ‚ùå Need ML engineering expertise\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwZRnlOZzwed"
   },
   "source": [
    "## üí¨ Preference Use Case #1: Conciseness vs. Verbosity\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Technical support for software developers\n",
    "- Problem: Responses are either too brief (unhelpful) or too verbose (time-wasting)\n",
    "- Goal: Teach model to be concise yet complete\n",
    "\n",
    "**Why Preference Tuning?**\n",
    "- ‚úÖ Both responses are technically correct\n",
    "- ‚úÖ \"Better\" is subjective (depends on context)\n",
    "- ‚úÖ Can't use SFT (no single \"correct\" format)\n",
    "- ‚úÖ Humans can consistently rank responses\n",
    "\n",
    "**What we're teaching:**\n",
    "- When to be detailed vs. brief\n",
    "- How to anticipate needs without over-explaining\n",
    "- Balance between completeness and efficiency\n",
    "- Professional yet approachable tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLqNTBgzzwed"
   },
   "outputs": [],
   "source": [
    "# Mock Dataset: Preference-Based Fine-Tuning (Conciseness)\n",
    "# Format: {prompt, chosen, rejected}\n",
    "\n",
    "preference_conciseness_data = [\n",
    "    {\n",
    "        \"prompt\": \"How do I check the version of Python installed on my system?\",\n",
    "        \"chosen\": \"You can check your Python version by running:\\n\\n```bash\\npython --version\\n```\\n\\nor\\n\\n```bash\\npython3 --version\\n```\\n\\nThis will display something like \\\"Python 3.11.2\\\". If you need programmatic access, use `sys.version` in Python code.\",\n",
    "        \"rejected\": \"To check the version of Python installed on your system, you have multiple options available to you. The most common and straightforward method is to use the command line or terminal. You can open your command prompt (on Windows) or terminal (on macOS or Linux) and type the command \\\"python --version\\\" or \\\"python3 --version\\\". This will return the version number of Python that is currently installed. For example, you might see something like \\\"Python 3.11.2\\\" or \\\"Python 3.9.7\\\". Additionally, if you're already inside a Python interpreter or script, you can import the sys module and print sys.version to get detailed version information. Another way is to use python -V (with a capital V) which is a shorthand for --version. It's worth noting that on some systems, especially Unix-based ones, you might have both Python 2 and Python 3 installed, so you might need to specify python3 instead of just python. The version number is important because different Python versions have different features and syntax, so knowing which version you're using helps ensure your code is compatible.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What's the difference between git merge and git rebase?\",\n",
    "        \"chosen\": \"**Git merge:**\\n- Creates a new commit that combines two branches\\n- Preserves complete history (all commits from both branches)\\n- Results in non-linear history with merge commits\\n- Safer for public/shared branches\\n\\n**Git rebase:**\\n- Moves your commits to the tip of another branch\\n- Creates a linear history (looks cleaner)\\n- Rewrites commit history (changes commit SHAs)\\n- Best for cleaning up local branches before merging\\n\\n**Rule of thumb:** Use merge for shared branches, rebase for local cleanup.\",\n",
    "        \"rejected\": \"Great question! Git merge and git rebase are both used to integrate changes from one branch into another, but they work quite differently.\\n\\nGit merge takes all the changes from one branch and merges them into another branch using a special merge commit. This creates a new commit that has two parent commits, preserving the complete history of both branches. The advantage is that it's non-destructive and maintains a complete record of what happened. The disadvantage is that if you have many merges, your history can become cluttered with merge commits.\\n\\nGit rebase, on the other hand, takes your commits and \\\"replays\\\" them on top of another branch. Instead of creating a merge commit, it actually rewrites the commit history by creating new commits with new SHA hashes. This results in a linear history that looks much cleaner. However, because it rewrites history, it can be dangerous if used on branches that other people are working on.\\n\\nSo when should you use each? Generally speaking, you should use merge when you're working on a shared branch or when you want to preserve the complete history. Use rebase when you're cleaning up your local branch before pushing it, or when you want a cleaner, more linear history.\\n\\nThere are also other considerations like interactive rebasing, which lets you squash commits, reorder them, or edit them, which can be very powerful for cleaning up your commit history before sharing it with others.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"How do I exit vim?\",\n",
    "        \"chosen\": \"To exit vim:\\n\\n- `:q` - Quit (if no changes)\\n- `:q!` - Quit without saving changes\\n- `:wq` or `:x` - Save and quit\\n- `ZZ` - Save and quit (shortcut)\\n\\nPress `Esc` first to ensure you're in command mode, then type one of the above.\",\n",
    "        \"rejected\": \"To exit vim, you need to first understand that vim operates in different modes. By default, when you open a file, you're in \\\"normal mode\\\". To execute commands, you need to type a colon (:) which puts you into \\\"command mode\\\". Once you're in command mode, you can type various commands. To quit vim, you would type :q and press Enter. However, if you've made changes to the file, vim won't let you quit without either saving or explicitly discarding those changes. If you want to quit without saving, you need to use :q! (the exclamation mark forces the quit). If you want to save your changes and then quit, you can use :wq (write and quit) or alternatively :x which does the same thing. There's also a keyboard shortcut ZZ (capital Z twice) that saves and quits. Make sure you press Escape first to ensure you're in normal mode before typing any of these commands, otherwise vim might just insert those characters into your file.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What does the 'async' keyword do in JavaScript?\",\n",
    "        \"chosen\": \"The `async` keyword makes a function return a Promise. It allows you to:\\n\\n1. Use `await` inside the function to pause execution until a Promise resolves\\n2. Write asynchronous code that looks synchronous\\n\\n```javascript\\nasync function getData() {\\n  const response = await fetch('/api/data');\\n  return response.json();\\n}\\n```\\n\\nAny value you `return` gets automatically wrapped in `Promise.resolve()`.\",\n",
    "        \"rejected\": \"`async` is a very important keyword in JavaScript that was introduced in ES2017 (ES8) as part of the async/await syntax. When you put the async keyword in front of a function declaration, it does several things. First and most importantly, it makes the function automatically return a Promise. Even if your function returns a simple value like a number or string, JavaScript will automatically wrap that value in a resolved Promise. This is really useful because it means you can use the function with Promise chains or with await in other async functions. The second main thing that async does is it allows you to use the await keyword inside that function. The await keyword can only be used inside async functions (or at the top level of modules in modern JavaScript). When you await a Promise, JavaScript pauses the execution of that async function until the Promise resolves, but importantly, it doesn't block the entire program - other code can still run. This makes async/await a much more readable way to handle asynchronous operations compared to traditional Promise chains or callbacks. It's worth noting that async functions always return Promises, so if your async function throws an error, that error gets wrapped in a rejected Promise automatically.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"How do I center a div in CSS?\",\n",
    "        \"chosen\": \"**Horizontal centering:**\\n```css\\n.div {\\n  margin: 0 auto;\\n  width: 500px; /* must have width */\\n}\\n```\\n\\n**Vertical and horizontal (flexbox):**\\n```css\\n.parent {\\n  display: flex;\\n  justify-content: center;\\n  align-items: center;\\n  height: 100vh;\\n}\\n```\\n\\n**Vertical and horizontal (grid):**\\n```css\\n.parent {\\n  display: grid;\\n  place-items: center;\\n  height: 100vh;\\n}\\n```\",\n",
    "        \"rejected\": \"Centering a div in CSS is one of the most common questions in web development, and there are actually many different ways to do it depending on your specific needs and browser support requirements. Let me walk you through the main approaches.\\n\\nFor horizontal centering only, the classic method is to set the div's left and right margins to 'auto' and give it a specific width. This works because auto margins will split the available space equally on both sides. However, this doesn't work for vertical centering.\\n\\nFor both horizontal and vertical centering, there are several modern approaches. The most popular these days is using Flexbox. You set the parent element to display: flex, then use justify-content: center for horizontal centering and align-items: center for vertical centering. This is very flexible and works great.\\n\\nAnother modern approach is CSS Grid, where you can use display: grid on the parent and then place-items: center, which centers in both directions at once. This is even more concise than Flexbox.\\n\\nThere's also the old position: absolute method where you position the div absolutely, set top: 50% and left: 50%, then use transform: translate(-50%, -50%) to adjust for the div's own dimensions. This works but is generally considered more of a hack.\\n\\nThe method you choose depends on your browser support requirements and the context of what you're building.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí¨ PREFERENCE USE CASE #1: Conciseness vs. Verbosity\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(preference_conciseness_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "\n",
    "    print(f\"‚ùì PROMPT:\\n{example['prompt']}\\n\")\n",
    "\n",
    "    print(f\"‚úÖ CHOSEN RESPONSE (Better):\\n{example['chosen']}\\n\")\n",
    "\n",
    "    print(f\"‚ùå REJECTED RESPONSE (Worse):\\n{example['rejected'][:300]}...\\n\")\n",
    "    print(\"   [Truncated for display - actual response is much longer]\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Efficient Communication:**\n",
    "   - Get to the point quickly\n",
    "   - Include essential context, skip unnecessary elaboration\n",
    "   - Use examples/code snippets effectively\n",
    "\n",
    "2. **Structure:**\n",
    "   - Bullet points for clarity\n",
    "   - Code blocks for technical content\n",
    "   - Clear section headers when needed\n",
    "\n",
    "3. **Completeness:**\n",
    "   - Answer the question fully\n",
    "   - Anticipate immediate follow-ups\n",
    "   - Provide actionable information\n",
    "\n",
    "4. **What to Avoid:**\n",
    "   - Lengthy explanations of obvious concepts\n",
    "   - Excessive historical context\n",
    "   - Redundant phrasing\n",
    "   - Over-explaining edge cases upfront\n",
    "\n",
    "‚ú® KEY INSIGHT: Both responses are technically correct and helpful.\n",
    "   But the chosen response respects the reader's time while still\n",
    "   being complete and useful. This is subjective quality that\n",
    "   SFT can't teach effectively.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSVw34cQzwee"
   },
   "source": [
    "## ü§ù Preference Use Case #2: Helpfulness & Empathy\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Mental health support chatbot\n",
    "- Problem: Responses are either too clinical (cold) or too casual (unprofessional)\n",
    "- Goal: Balance empathy with professionalism\n",
    "\n",
    "**Why Preference Tuning?**\n",
    "- ‚úÖ Both responses can be factually correct\n",
    "- ‚úÖ \"Better\" depends on emotional intelligence\n",
    "- ‚úÖ Humans can judge which feels more supportive\n",
    "- ‚úÖ Can't reduce to a template (needs flexibility)\n",
    "\n",
    "**What we're teaching:**\n",
    "- Empathetic acknowledgment\n",
    "- Professional boundaries\n",
    "- When to be warm vs. when to be directive\n",
    "- Avoiding dismissiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKanzrIvzwee"
   },
   "outputs": [],
   "source": [
    "# Mock Dataset: Preference-Based Fine-Tuning (Helpfulness & Empathy)\n",
    "\n",
    "preference_empathy_data = [\n",
    "    {\n",
    "        \"prompt\": \"I'm feeling really overwhelmed with work lately and I don't know what to do.\",\n",
    "        \"chosen\": \"I'm sorry to hear you're feeling overwhelmed - that's a really difficult place to be. It's important to recognize that this feeling is valid and that you're not alone in experiencing it.\\n\\nHere are some steps that might help:\\n\\n1. **Prioritize**: Make a list of tasks and identify what's truly urgent vs. what can wait\\n2. **Break it down**: Large projects feel less daunting when broken into smaller steps\\n3. **Set boundaries**: It's okay to say no or to ask for help\\n4. **Take breaks**: Even 5-10 minutes away from work can help reset your mind\\n\\nIf these feelings persist or worsen, please consider reaching out to a mental health professional who can provide personalized support. Would you like to talk more about any specific challenges you're facing?\",\n",
    "        \"rejected\": \"Feeling overwhelmed with work is common. You should make a to-do list and prioritize your tasks. Break large projects into smaller tasks. Take regular breaks. Consider talking to your manager about workload. If stress continues, see a therapist.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I'm having trouble sleeping because I keep thinking about my mistakes at work.\",\n",
    "        \"chosen\": \"It sounds like you're experiencing a lot of worry about work, and that's affecting your sleep - that must be exhausting. It's actually very common to replay difficult moments, even though it doesn't feel good.\\n\\nA few things that might help:\\n\\n**For immediate relief:**\\n- Try the 4-7-8 breathing technique before bed (inhale 4 seconds, hold 7, exhale 8)\\n- Keep a notepad by your bed - if worries come up, write them down to address tomorrow\\n- Consider a brief \\\"worry period\\\" earlier in the evening to process these thoughts\\n\\n**Longer-term perspective:**\\n- Remember that everyone makes mistakes - they're opportunities to learn\\n- Ask yourself: \\\"Will this matter in 5 years?\\\" for perspective\\n- If specific mistakes are fixable, make a plan to address them tomorrow\\n\\nIf sleep problems continue for more than a few weeks, it might be worth discussing with a doctor. You deserve rest. Is there a particular mistake that's weighing on you?\",\n",
    "        \"rejected\": \"Stop thinking about work mistakes before bed. Use breathing exercises. Write down your worries. Remember everyone makes mistakes. See a doctor if sleep problems persist.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"I don't think therapy is working for me. Should I quit?\",\n",
    "        \"chosen\": \"Thank you for sharing that - it takes courage to acknowledge when something isn't feeling right. Before making a decision, let's think through this together.\\n\\n**Questions to consider:**\\n\\n1. **How long have you been in therapy?** Sometimes it takes 4-6 sessions to build rapport and see progress\\n2. **Have you discussed this with your therapist?** They may have insights or be willing to adjust their approach\\n3. **Is it the therapist or the process?** Sometimes the fit isn't right, and that's okay - finding another therapist might help\\n4. **What were you hoping to achieve?** Comparing expectations to reality can clarify if progress is happening\\n\\n**It's completely valid to:**\\n- Switch therapists if the connection isn't there\\n- Take a break and return later\\n- Try a different therapy approach (CBT, DBT, EMDR, etc.)\\n\\nTherapy should feel like it's helping more than it's frustrating. What specifically feels like it's not working?\",\n",
    "        \"rejected\": \"Therapy takes time to work. You should talk to your therapist about your concerns. If you still want to quit after discussing it, you can try a different therapist or take a break. Don't give up entirely though.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ü§ù PREFERENCE USE CASE #2: Helpfulness & Empathy\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(preference_empathy_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "    print(f\"‚ùì PROMPT:\\n{example['prompt']}\\n\")\n",
    "    print(f\"‚úÖ CHOSEN (Better - Empathetic & Complete):\\n{example['chosen']}\\n\")\n",
    "    print(f\"‚ùå REJECTED (Worse - Terse & Clinical):\\n{example['rejected']}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Empathetic Acknowledgment:**\n",
    "   - Validate feelings first\n",
    "   - Use phrases like \\\"I'm sorry to hear\\\" and \\\"that must be difficult\\\"\n",
    "   - Show understanding before problem-solving\n",
    "\n",
    "2. **Structured Support:**\n",
    "   - Provide actionable steps\n",
    "   - Organize information clearly\n",
    "   - Balance immediate help with long-term perspective\n",
    "\n",
    "3. **Professional Boundaries:**\n",
    "   - Suggest professional help when appropriate\n",
    "   - Don't diagnose or prescribe\n",
    "   - Empower user to make their own decisions\n",
    "\n",
    "4. **Follow-up Engagement:**\n",
    "   - Ask open-ended questions\n",
    "   - Show genuine interest\n",
    "   - Create space for further discussion\n",
    "\n",
    "‚ú® KEY INSIGHT: The rejected responses aren't wrong - they provide correct\n",
    "   information. But they lack warmth and fail to make the user feel heard.\n",
    "   This is subjective quality that requires preference-based learning.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ_-R2Bvzwee"
   },
   "source": [
    "## üö´ Preference Use Case #3: Refusal Quality\n",
    "\n",
    "**Scenario:**\n",
    "- Company: AI assistant for financial advice\n",
    "- Problem: Model sometimes refuses correctly but rudely/unhelpfully\n",
    "- Goal: Teach graceful, helpful refusals\n",
    "\n",
    "**Why Preference Tuning?**\n",
    "- ‚úÖ Both responses correctly refuse\n",
    "- ‚úÖ Quality is about tone and helpfulness\n",
    "- ‚úÖ SFT would enforce one exact refusal format (too rigid)\n",
    "- ‚úÖ Context determines best refusal style\n",
    "\n",
    "**What we're teaching:**\n",
    "- Polite but firm boundaries\n",
    "- Offering alternatives\n",
    "- Explaining why (when appropriate)\n",
    "- Maintaining positive relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6ZCRjv9zwee"
   },
   "outputs": [],
   "source": [
    "# Mock Dataset: Preference-Based Fine-Tuning (Refusal Quality)\n",
    "\n",
    "preference_refusal_data = [\n",
    "    {\n",
    "        \"prompt\": \"Can you review my specific stock portfolio and tell me what to buy/sell?\",\n",
    "        \"chosen\": \"I appreciate you thinking of me for this, but I'm not able to provide personalized investment advice or specific buy/sell recommendations. Here's why:\\n\\n**What I can't do:**\\n- Analyze your specific portfolio\\n- Recommend individual stocks to buy or sell\\n- Provide financial advice tailored to your situation\\n\\n**What I can help with:**\\n- Explain general investment concepts (diversification, risk tolerance, etc.)\\n- Provide educational information about different investment types\\n- Help you understand financial terms and strategies\\n- Suggest questions to ask a financial advisor\\n\\n**Better alternative:**\\nConsider consulting with a licensed financial advisor who can review your complete financial picture, understand your goals, and provide personalized recommendations. Would you like help understanding any general investment concepts instead?\",\n",
    "        \"rejected\": \"I cannot provide personalized investment advice or recommend specific stocks to buy or sell. You should consult with a licensed financial advisor for that.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Can you write me a college essay and make it sound like I wrote it?\",\n",
    "        \"chosen\": \"I can't write your college essay for you, but I'd love to help you write a great one yourself! Here's why and how I can assist:\\n\\n**Why I can't write it for you:**\\n- It would be academic dishonesty\\n- Admissions officers want to hear YOUR voice\\n- You'd miss the valuable reflection process\\n\\n**How I CAN help:**\\n- Brainstorm ideas and experiences to write about\\n- Review your draft and suggest improvements\\n- Help with structure and organization\\n- Explain effective writing techniques\\n- Provide examples of strong essay elements\\n\\n**Want to get started?**\\n- Tell me about an experience that shaped you\\n- Share what makes you unique\\n- Discuss what you want colleges to know about you\\n\\nI can help you find and express your authentic story. What topics are you considering?\",\n",
    "        \"rejected\": \"I cannot write your college essay for you as that would be cheating. You need to write it yourself. I can help you brainstorm or review a draft.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Help me craft a message to get back together with my ex who blocked me.\",\n",
    "        \"chosen\": \"I understand this must be a painful situation, and I want to help in a way that's truly in your best interest. However, I need to respectfully decline helping you contact someone who has blocked you. Here's why:\\n\\n**Why reaching out might not be helpful:**\\n- Blocking is a clear boundary they've set\\n- Attempting contact could be perceived as harassment\\n- It's unlikely to achieve the outcome you want\\n- It could cause legal issues or restraining orders\\n\\n**What might help instead:**\\n- Give them (and yourself) space and time\\n- Focus on your own healing and growth\\n- Talk to a therapist about processing these feelings\\n- Reconnect with friends and hobbies\\n- If they want to reconnect later, they'll reach out\\n\\n**I can help with:**\\n- Coping strategies for breakups\\n- Understanding healthy relationships\\n- Building self-esteem after a relationship ends\\n\\nI know this isn't the answer you wanted, but respecting boundaries - even when it hurts - is crucial. Would you like to talk about healing instead?\",\n",
    "        \"rejected\": \"I cannot help you contact someone who has blocked you. That would not be respecting their boundaries. You should move on and respect their decision.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üö´ PREFERENCE USE CASE #3: Refusal Quality\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for idx, example in enumerate(preference_refusal_data, 1):\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"üìù Example {idx}\")\n",
    "    print(f\"{'‚îÄ'*80}\\n\")\n",
    "    print(f\"‚ùì PROMPT:\\n{example['prompt']}\\n\")\n",
    "    print(f\"‚úÖ CHOSEN (Better - Graceful & Helpful):\\n{example['chosen']}\\n\")\n",
    "    print(f\"‚ùå REJECTED (Worse - Blunt & Unhelpful):\\n{example['rejected']}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Graceful Refusal Pattern:**\n",
    "   - Acknowledge the request positively\n",
    "   - Clearly state what you CAN'T do\n",
    "   - Explain WHY (builds trust)\n",
    "   - Offer what you CAN do\n",
    "   - Maintain warm, helpful tone\n",
    "\n",
    "2. **Structure:**\n",
    "   - \\\"I understand... but I can't because...\\\"\n",
    "   - Bullet points for clarity\n",
    "   - Alternative offerings\n",
    "   - Re-engagement question\n",
    "\n",
    "3. **Tone Balance:**\n",
    "   - Firm boundaries (not apologetic or wishy-washy)\n",
    "   - Empathetic (acknowledge disappointment)\n",
    "   - Constructive (redirect to helpful alternatives)\n",
    "   - Professional (not preachy)\n",
    "\n",
    "4. **Context-Appropriate:**\n",
    "   - Academic dishonesty: Focus on learning value\n",
    "   - Boundary violations: Focus on respect\n",
    "   - Regulated advice: Focus on safety/legality\n",
    "\n",
    "‚ú® KEY INSIGHT: Both responses correctly refuse the request. But the\n",
    "   chosen response turns a \\\"no\\\" into a \\\"yes, but differently,\\\" maintaining\n",
    "   the relationship and providing value. This nuanced quality judgment is\n",
    "   what preference-based tuning excels at.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8kju_J0zwee"
   },
   "source": [
    "## üìä Preference-Based Tuning Summary\n",
    "\n",
    "### ‚úÖ Strengths\n",
    "\n",
    "1. **Handles Subjectivity**: Perfect for \\\"better\\\" rather than \\\"correct\\\"\n",
    "2. **More Natural**: Doesn't enforce rigid patterns\n",
    "3. **User Satisfaction**: Directly optimizes for what humans prefer\n",
    "4. **Flexible**: Model adapts appropriately to context\n",
    "5. **Less Brittle**: More robust than SFT to variations\n",
    "\n",
    "### ‚ùå Limitations\n",
    "\n",
    "1. **Needs Consistency**: Humans must agree on rankings\n",
    "2. **More Data**: Requires 2x examples (chosen + rejected for each)\n",
    "3. **Harder to Collect**: Ranking is more cognitively demanding than writing\n",
    "4. **Single Dimension**: Optimizes one quality axis at a time\n",
    "5. **Can't Handle Multi-Objective**: If \\\"better\\\" means \\\"more A AND more B,\\\" use RLHF\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Data Collection Tips\n",
    "\n",
    "#### 1. Ensure Inter-Rater Agreement\n",
    "```\n",
    "‚úÖ 3+ people rank the same pairs\n",
    "‚úÖ Track agreement rate (should be >80%)\n",
    "‚ùå If agreement <70%, criteria aren't clear enough\n",
    "```\n",
    "\n",
    "#### 2. Generate Rejection Candidates\n",
    "```\n",
    "Approach A: Take real model outputs, rank them\n",
    "Approach B: Deliberately create \\\"worse\\\" versions\n",
    "Approach C: Use different models (GPT-4 = chosen, GPT-3.5 = rejected)\n",
    "```\n",
    "\n",
    "#### 3. Clear Ranking Criteria\n",
    "```\n",
    "Document exactly what makes a response \\\"better\\\":\n",
    "- More concise?\n",
    "- More empathetic?\n",
    "- Better structured?\n",
    "- More actionable?\n",
    "\n",
    "Raters need these guidelines!\n",
    "```\n",
    "\n",
    "#### 4. Avoid Close Calls\n",
    "```\n",
    "‚ùå When responses are similarly good, preferences are noise\n",
    "‚úÖ Choose pairs with clear quality differences\n",
    "```\n",
    "\n",
    "#### 5. Representative Distribution\n",
    "```\n",
    "Include:\n",
    "- Different prompt types\n",
    "- Various difficulty levels\n",
    "- Edge cases\n",
    "- Common scenarios\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ When to Use Preference-Based Tuning\n",
    "\n",
    "**Use when you answer YES to:**\n",
    "\n",
    "1. ‚úÖ Are multiple correct answers possible?\n",
    "2. ‚úÖ Is quality subjective but rankable by humans?\n",
    "3. ‚úÖ Do you want flexibility, not rigid formatting?\n",
    "4. ‚úÖ Can humans consistently agree on which is better?\n",
    "5. ‚úÖ Is it one-dimensional quality (helpfulness OR conciseness, not both simultaneously)?\n",
    "\n",
    "**Perfect use cases:**\n",
    "- Chatbot helpfulness ‚úÖ\n",
    "- Response tone/empathy ‚úÖ\n",
    "- Conciseness vs. completeness ‚úÖ\n",
    "- Refusal quality ‚úÖ\n",
    "- Writing style preferences ‚úÖ\n",
    "\n",
    "---\n",
    "\n",
    "Next: **RLHF** for when you need to optimize multiple quality dimensions simultaneously! üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qt5kEF4-zwee"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 5: RLHF (Reinforcement Learning from Human Feedback)\n",
    "\n",
    "## üìñ What is RLHF?\n",
    "\n",
    "**RLHF** is the most sophisticated fine-tuning approach, used to train models like ChatGPT and Claude.\n",
    "\n",
    "**Core Concept:**\n",
    "> \\\"Optimize for multiple quality dimensions simultaneously using scored feedback.\\\"\n",
    "\n",
    "**Key Differences:**\n",
    "- **SFT**: \\\"Here's the correct answer\\\"\n",
    "- **Preferences**: \\\"Response A is better than Response B\\\"\n",
    "- **RLHF**: \\\"Response gets 8/10 on helpfulness, 6/10 on safety, 9/10 on accuracy\\\"\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Technical Overview\n",
    "\n",
    "**Traditional RLHF has 3 stages:**\n",
    "\n",
    "### Stage 1: Supervised Fine-Tuning (SFT)\n",
    "- Start with base model\n",
    "- Fine-tune on high-quality demonstrations\n",
    "- Creates the \\\"initial policy\\\"\n",
    "\n",
    "### Stage 2: Reward Model Training\n",
    "- Collect human rankings of outputs\n",
    "- Train a separate \\\"reward model\\\" to predict human preferences\n",
    "- This model scores outputs (e.g., 0-10)\n",
    "\n",
    "### Stage 3: RL Optimization (PPO)\n",
    "- Use the reward model to guide the main model\n",
    "- Model generates outputs ‚Üí Reward model scores them ‚Üí Model learns\n",
    "- Uses PPO (Proximal Policy Optimization) algorithm\n",
    "- Balances: maximize reward while staying close to original model\n",
    "\n",
    "**OpenAI's Approach (Simplified):**\n",
    "- You likely won't implement full RLHF yourself\n",
    "- OpenAI may abstract this to: \\\"Provide scores for multiple dimensions\\\"\n",
    "- The complexity is handled behind the scenes\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ When to Use RLHF\n",
    "\n",
    "### Perfect for:\n",
    "1. **Multi-dimensional quality** (accuracy + safety + helpfulness all matter)\n",
    "2. **Complex alignment** (human values, safety, ethical behavior)\n",
    "3. **Nuanced trade-offs** (sometimes verbose is better, sometimes concise)\n",
    "4. **Continuous quality scales** (not just \\\"better/worse\\\" but \\\"how much better?\\\")\n",
    "5. **Flagship products** (ChatGPT, Claude - where quality is critical)\n",
    "\n",
    "### Signs RLHF is right:\n",
    "- ‚úÖ Quality has multiple important dimensions\n",
    "- ‚úÖ Trade-offs between dimensions are contextual\n",
    "- ‚úÖ Simple preferences can't capture the nuance\n",
    "- ‚úÖ You have resources for complex data collection\n",
    "- ‚úÖ You're building a high-value, high-impact product\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå When NOT to Use RLHF\n",
    "\n",
    "### Overkill for:\n",
    "1. **Single quality dimension** ‚Üí Use preference tuning\n",
    "2. **Exact formatting** ‚Üí Use SFT\n",
    "3. **Quick prototypes** ‚Üí Too complex and expensive\n",
    "4. **Simple patterns** ‚Üí Simpler methods work fine\n",
    "\n",
    "### Signs RLHF is wrong:\n",
    "- ‚ùå Your problem is straightforward\n",
    "- ‚ùå You don't have significant resources\n",
    "- ‚ùå Simpler methods haven't been tried yet\n",
    "- ‚ùå You can't collect multi-dimensional scores\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Requirements\n",
    "\n",
    "**Minimum viable:** 500-1000 scored examples\n",
    "- Each example needs scores on 3-5 dimensions\n",
    "- Multiple raters per example for reliability\n",
    "\n",
    "**Recommended:** 5,000-20,000 examples\n",
    "- Production quality alignment\n",
    "- Robust across edge cases\n",
    "\n",
    "**Reality check:**\n",
    "- This is expensive and time-consuming\n",
    "- Typically reserved for flagship products\n",
    "- Most companies should try SFT or preferences first\n",
    "\n",
    "---\n",
    "\n",
    "Let's see RLHF-style data with three complex use cases! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-L4m_40Kzwef"
   },
   "source": [
    "---\n",
    "\n",
    "## üîß How to Actually Fine-Tune with RLHF\n",
    "\n",
    "**Reality Check:** True RLHF is not available via OpenAI's fine-tuning API.\n",
    "\n",
    "**Why?**\n",
    "- RLHF is extremely complex (3-stage process)\n",
    "- Requires significant compute infrastructure\n",
    "- Needs thousands of examples with multi-dimensional scores\n",
    "- Reserved for flagship products (ChatGPT, Claude)\n",
    "\n",
    "**Your Options:**\n",
    "\n",
    "### Option 1: Use OpenAI's Pre-Aligned Models\n",
    "- GPT-4, GPT-4o, GPT-5-nano are already RLHF-tuned\n",
    "- These models already have excellent alignment\n",
    "- For most use cases, prompt engineering + RAG is sufficient\n",
    "\n",
    "### Option 2: Build Your Own RLHF Pipeline\n",
    "If you have significant resources and expertise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dMaroHUzwef"
   },
   "outputs": [],
   "source": [
    "# CONCEPTUAL: RLHF training pipeline (high-level)\n",
    "# This is NOT runnable code - just illustrative\n",
    "\n",
    "# Stage 1: Supervised Fine-Tuning (SFT)\n",
    "base_model = load_model(\"gpt2-large\")\n",
    "sft_model = supervised_fine_tune(\n",
    "    model=base_model,\n",
    "    dataset=high_quality_demonstrations,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# Stage 2: Reward Model Training\n",
    "# Collect human preferences with multi-dimensional scores\n",
    "reward_model = train_reward_model(\n",
    "    preference_data=scored_comparisons,  # Thousands of examples\n",
    "    dimensions=[\"helpfulness\", \"safety\", \"accuracy\"],\n",
    "    model_size=\"large\"\n",
    ")\n",
    "\n",
    "# Stage 3: RL Optimization (PPO)\n",
    "final_model = ppo_training(\n",
    "    policy_model=sft_model,\n",
    "    reward_model=reward_model,\n",
    "    prompts=training_prompts,\n",
    "    iterations=10000,\n",
    "    kl_penalty=0.1  # Stay close to original model\n",
    ")\n",
    "\n",
    "print(\"RLHF training complete (in theory!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D7ENJcOzwef"
   },
   "source": [
    "### üè¢ Enterprise Solutions\n",
    "\n",
    "If you need RLHF-level quality:\n",
    "\n",
    "**1. OpenAI Custom Models Program**\n",
    "- Contact OpenAI for custom model training\n",
    "- They handle RLHF complexity\n",
    "- Minimum budget: $100K+\n",
    "- Turnaround: Months\n",
    "\n",
    "**2. Anthropic Custom Training**\n",
    "- Similar to OpenAI's program\n",
    "- Uses Constitutional AI (their RLHF variant)\n",
    "- Enterprise-scale budgets\n",
    "\n",
    "**3. Build In-House**\n",
    "- Use Hugging Face TRL + Accelerate\n",
    "- Requires: ML team, GPU cluster, months of work\n",
    "- Budget: $50K-500K+\n",
    "\n",
    "### üí° Practical Advice\n",
    "\n",
    "**For 99% of use cases:**\n",
    "```python\n",
    "# Instead of RLHF, do this:\n",
    "\n",
    "# 1. Start with prompt engineering\n",
    "prompt = \"\"\"You are a helpful assistant. Be accurate, safe, and empathetic.\"\"\"\n",
    "\n",
    "# 2. Add RAG for knowledge\n",
    "context = retrieve_relevant_docs(query)\n",
    "\n",
    "# 3. Use tool calling for accuracy\n",
    "result = use_calculator_tool(math_problem)\n",
    "\n",
    "# 4. Fine-tune for format/style (SFT)\n",
    "# Only if the above isn't sufficient\n",
    "```\n",
    "\n",
    "**When you actually need RLHF:**\n",
    "- Building a flagship AI product (ChatGPT competitor)\n",
    "- Safety-critical application (medical diagnosis AI)\n",
    "- Multi-million user base\n",
    "- Budget: $100K+ for training\n",
    "\n",
    "**For everyone else:**\n",
    "- Use GPT-4 (already RLHF-tuned) ‚úÖ\n",
    "- Focus on prompt engineering + RAG ‚úÖ\n",
    "- Consider SFT for format/style ‚úÖ\n",
    "- Save the RLHF complexity for later ‚úÖ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG7D_Nbbzwef"
   },
   "source": [
    "## üè• RLHF Use Case #1: Medical Information (Multi-Dimensional Quality)\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Health information chatbot\n",
    "- Problem: Need to balance accuracy, safety, empathy, and actionability\n",
    "- Goal: Provide helpful health information that's safe and appropriate\n",
    "\n",
    "**Why RLHF?**\n",
    "- ‚úÖ Multiple critical dimensions (can't optimize just one)\n",
    "- ‚úÖ Trade-offs are contextual (sometimes empathy > brevity, sometimes not)\n",
    "- ‚úÖ Safety is paramount but so is helpfulness\n",
    "- ‚úÖ Preferences alone can't capture all dimensions\n",
    "\n",
    "**Quality Dimensions:**\n",
    "1. **Medical Accuracy** (0-10): Factual correctness\n",
    "2. **Safety** (0-10): Appropriate disclaimers, doesn't diagnose\n",
    "3. **Empathy** (0-10): Shows understanding and compassion\n",
    "4. **Actionability** (0-10): Provides clear next steps\n",
    "5. **Appropriateness** (0-10): Recognizes limitations, suggests professional help when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_tks9Qzzwef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mock Dataset: RLHF for Medical Information\n",
    "# Format: {prompt, response, scores_per_dimension}\n",
    "\n",
    "rlhf_medical_data = [\n",
    "    {\n",
    "        \"prompt\": \"I've had a headache for 3 days. What's wrong with me?\",\n",
    "        \"responses\": [\n",
    "            {\n",
    "                \"text\": \"Headaches lasting several days can have many causes. Common ones include tension, dehydration, lack of sleep, or stress. More rarely, they could indicate something more serious.\\n\\nImmediate steps you can try:\\n- Ensure you're well hydrated\\n- Get adequate rest\\n- Try over-the-counter pain relief if appropriate for you\\n- Reduce screen time and stress\\n\\nYou should see a doctor if:\\n- The headache is severe or getting worse\\n- You have fever, stiff neck, confusion, or vision changes\\n- It's different from your usual headaches\\n- It persists beyond a week\\n\\nI can't diagnose what's causing your headache, but I hope these suggestions help. Please don't hesitate to seek medical attention if you're concerned.\",\n",
    "                \"scores\": {\n",
    "                    \"medical_accuracy\": 9,\n",
    "                    \"safety\": 10,\n",
    "                    \"empathy\": 7,\n",
    "                    \"actionability\": 9,\n",
    "                    \"appropriateness\": 10\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"I understand having a persistent headache must be uncomfortable and concerning. Let me try to help.\\n\\nThere are many possible causes for a 3-day headache, ranging from common to more serious. While I can provide general information, I can't diagnose your specific situation.\\n\\nCommon causes include:\\n- Tension or stress\\n- Dehydration\\n- Poor sleep\\n- Eye strain\\n- Caffeine withdrawal\\n\\nWhat you can try now:\\n1. Drink plenty of water\\n2. Rest in a dark, quiet room\\n3. Apply a cold compress to your forehead\\n4. Try gentle neck stretches\\n\\nWarning signs to see a doctor immediately:\\n- Sudden, severe headache (\\\"worst of your life\\\")\\n- Headache with fever, stiff neck, rash, confusion\\n- Headache after a head injury\\n- Progressive worsening\\n- New headache if you're over 50\\n\\nGiven it's been 3 days, I'd recommend scheduling a doctor's appointment soon for proper evaluation. They can rule out underlying issues and provide appropriate treatment.\\n\\nHow are you feeling otherwise? Any other symptoms?\",\n",
    "                \"scores\": {\n",
    "                    \"medical_accuracy\": 9,\n",
    "                    \"safety\": 10,\n",
    "                    \"empathy\": 10,\n",
    "                    \"actionability\": 10,\n",
    "                    \"appropriateness\": 10\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"You probably have a tension headache or migraine. Try taking ibuprofen and resting. If it doesn't go away, see a doctor.\",\n",
    "                \"scores\": {\n",
    "                    \"medical_accuracy\": 6,\n",
    "                    \"safety\": 5,\n",
    "                    \"empathy\": 3,\n",
    "                    \"actionability\": 6,\n",
    "                    \"appropriateness\": 4\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"A 3-day headache could be a sign of many conditions ranging from benign to serious. Possible causes include tension headaches, migraines, cluster headaches, sinus infections, high blood pressure, brain tumor, aneurysm, meningitis, or temporal arteritis. You should see a doctor immediately for proper diagnostic imaging and blood work to rule out serious conditions.\",\n",
    "                \"scores\": {\n",
    "                    \"medical_accuracy\": 7,\n",
    "                    \"safety\": 3,\n",
    "                    \"empathy\": 2,\n",
    "                    \"actionability\": 5,\n",
    "                    \"appropriateness\": 3\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display RLHF data\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üè• RLHF USE CASE #1: Medical Information (Multi-Dimensional Quality)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for example in rlhf_medical_data:\n",
    "    print(f\"‚ùì PROMPT: {example['prompt']}\\n\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for idx, response in enumerate(example['responses'], 1):\n",
    "        print(f\"\\nüìã RESPONSE {idx}:\\n{response['text']}\\n\")\n",
    "\n",
    "        scores = response['scores']\n",
    "        total_score = sum(scores.values())\n",
    "        max_score = len(scores) * 10\n",
    "\n",
    "        print(f\"\\nüìä SCORES:\")\n",
    "        for dimension, score in scores.items():\n",
    "            bar = \"‚ñà\" * score + \"‚ñë\" * (10 - score)\n",
    "            print(f\"  {dimension.replace('_', ' ').title():20s} {bar} {score}/10\")\n",
    "\n",
    "        print(f\"\\n  {'TOTAL':20s} {total_score}/{max_score} ({total_score/max_score*100:.0f}%)\")\n",
    "        print(\"‚îÄ\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Multi-Dimensional Optimization:**\n",
    "   - Can't just maximize one dimension\n",
    "   - Response 2 scores highest overall (50/50)\n",
    "   - Balances ALL dimensions effectively\n",
    "\n",
    "2. **Understanding Trade-offs:**\n",
    "   - Response 1 is good (45/50) but less empathetic\n",
    "   - Response 3 is dangerously brief (lacks safety)\n",
    "   - Response 4 is accurate but causes unnecessary alarm\n",
    "\n",
    "3. **Contextual Appropriateness:**\n",
    "   - When to be detailed vs. concise\n",
    "   - How much medical terminology to use\n",
    "   - When to emphasize seeking professional help\n",
    "\n",
    "4. **Safety Paramount:**\n",
    "   - Never diagnose\n",
    "   - Always include appropriate disclaimers\n",
    "   - Highlight red flags clearly\n",
    "   - Suggest professional consultation\n",
    "\n",
    "‚ú® KEY INSIGHT: This isn't \\\"Response A vs Response B\\\" - it's understanding\n",
    "   that Response 2 achieves the best overall balance across ALL quality\n",
    "   dimensions. RLHF teaches the model to navigate these complex trade-offs.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PCTqH5Qzwef"
   },
   "source": [
    "## ‚úçÔ∏è RLHF Use Case #2: Creative Writing Quality\n",
    "\n",
    "**Scenario:**\n",
    "- Company: AI writing assistant\n",
    "- Problem: Story openings need to balance multiple creative elements\n",
    "- Goal: Generate engaging story openings that score high across all dimensions\n",
    "\n",
    "**Why RLHF?**\n",
    "- ‚úÖ Multiple subjective dimensions (atmosphere, originality, prose, hook)\n",
    "- ‚úÖ Trade-offs are contextual and complex\n",
    "- ‚úÖ Can't reduce to simple preferences\n",
    "- ‚úÖ Need continuous quality scores, not just rankings\n",
    "\n",
    "**Quality Dimensions:**\n",
    "1. **Atmosphere** (0-10): Establishes mood and setting effectively\n",
    "2. **Originality** (0-10): Fresh ideas, avoids clich√©s\n",
    "3. **Hook** (0-10): Compels reader to continue\n",
    "4. **Prose Quality** (0-10): Writing style, word choice, flow\n",
    "5. **Character** (0-10): Interesting character introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54hxoTj-zweg"
   },
   "outputs": [],
   "source": [
    "# Mock Dataset: RLHF for Creative Writing\n",
    "\n",
    "rlhf_writing_data = [\n",
    "    {\n",
    "        \"prompt\": \"Write an opening paragraph for a sci-fi story about a lone astronaut.\",\n",
    "        \"responses\": [\n",
    "            {\n",
    "                \"text\": \"The silence was different here. Commander Sarah Chen had spent eighteen months on the International Space Station, but this‚Äîthis was the silence of true isolation. Through the porthole of her one-person craft, Earth hung like a blue marble against the infinite black, shrinking with each passing hour. Her only companion was the steady hum of life support systems and the ghost of a voice that should have been on the comms channel but wasn't.\",\n",
    "                \"scores\": {\n",
    "                    \"atmosphere\": 9,\n",
    "                    \"originality\": 7,\n",
    "                    \"hook\": 9,\n",
    "                    \"prose_quality\": 9,\n",
    "                    \"character\": 8\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"The astronaut floated alone in space. She looked out the window at Earth. It was far away now. She wondered if she would ever go back. The spaceship was quiet except for the sounds of the machines. She had been traveling for a long time and felt lonely.\",\n",
    "                \"scores\": {\n",
    "                    \"atmosphere\": 4,\n",
    "                    \"originality\": 3,\n",
    "                    \"hook\": 3,\n",
    "                    \"prose_quality\": 3,\n",
    "                    \"character\": 2\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Maya's fingers trembled as she powered down the distress beacon. Three days of silence from Mission Control. Three days of telling herself there was a reasonable explanation. But deep in the lizard part of her brain‚Äîthe part that had kept her ancestors alive on the savanna‚Äîshe knew the truth: she was the last human being with a heartbeat.\",\n",
    "                \"scores\": {\n",
    "                    \"atmosphere\": 10,\n",
    "                    \"originality\": 9,\n",
    "                    \"hook\": 10,\n",
    "                    \"prose_quality\": 9,\n",
    "                    \"character\": 9\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"The astronaut was alone in the vast emptiness of space, floating through the cosmic void, surrounded by infinite darkness and twinkling stars, feeling the profound loneliness of being the only human for millions of miles in any direction, contemplating the meaning of existence and humanity's place in the universe.\",\n",
    "                \"scores\": {\n",
    "                    \"atmosphere\": 6,\n",
    "                    \"originality\": 4,\n",
    "                    \"hook\": 5,\n",
    "                    \"prose_quality\": 5,\n",
    "                    \"character\": 1\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úçÔ∏è RLHF USE CASE #2: Creative Writing Quality\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for example in rlhf_writing_data:\n",
    "    print(f\"‚ùì PROMPT: {example['prompt']}\\n\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for idx, response in enumerate(example['responses'], 1):\n",
    "        print(f\"\\nüìã RESPONSE {idx}:\\n{response['text']}\\n\")\n",
    "\n",
    "        scores = response['scores']\n",
    "        total_score = sum(scores.values())\n",
    "        max_score = len(scores) * 10\n",
    "\n",
    "        print(f\"\\nüìä SCORES:\")\n",
    "        for dimension, score in scores.items():\n",
    "            bar = \"‚ñà\" * score + \"‚ñë\" * (10 - score)\n",
    "            print(f\"  {dimension.replace('_', ' ').title():20s} {bar} {score}/10\")\n",
    "\n",
    "        print(f\"\\n  {'TOTAL':20s} {total_score}/{max_score} ({total_score/max_score*100:.0f}%)\")\n",
    "        print(\"‚îÄ\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Balancing Multiple Creative Elements:**\n",
    "   - Response 3 scores highest (47/50 = 94%)\n",
    "   - Excellent atmosphere AND hook AND character\n",
    "   - Can't just optimize one dimension\n",
    "\n",
    "2. **Avoiding Common Pitfalls:**\n",
    "   - Response 2: Too simple, tells instead of shows\n",
    "   - Response 4: Purple prose, run-on sentence, no character\n",
    "   - Response 1: Good but slightly conventional\n",
    "\n",
    "3. **Show Don't Tell:**\n",
    "   - \\\"trembled,\\\" \\\"lizard part of her brain\\\" > \\\"felt lonely\\\"\n",
    "   - Specific details > Generic descriptions\n",
    "   - Action and thought > Exposition\n",
    "\n",
    "4. **Creating Hooks:**\n",
    "   - Mystery: \\\"should have been on comms but wasn't\\\"\n",
    "   - High stakes: \\\"last human being with a heartbeat\\\"\n",
    "   - Immediate tension: \\\"powered down the distress beacon\\\"\n",
    "\n",
    "‚ú® KEY INSIGHT: Creative quality can't be reduced to \\\"better/worse.\\\"\n",
    "   RLHF teaches the model to understand that Response 3 achieves the\n",
    "   best balance across all creative dimensions simultaneously.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4eTYC-pzweg"
   },
   "source": [
    "## üë®‚Äçüíª RLHF Use Case #3: Code Review Quality\n",
    "\n",
    "**Scenario:**\n",
    "- Company: Developer tools platform\n",
    "- Problem: Code reviews need to balance correctness, tone, specificity, and teaching\n",
    "- Goal: Provide helpful code reviews that improve code AND developer skills\n",
    "\n",
    "**Why RLHF?**\n",
    "- ‚úÖ Multiple competing dimensions (thorough vs. not overwhelming)\n",
    "- ‚úÖ Context determines balance (junior devs need more explanation)\n",
    "- ‚úÖ Trade-offs are subtle and complex\n",
    "- ‚úÖ Quality is continuous, not binary\n",
    "\n",
    "**Quality Dimensions:**\n",
    "1. **Technical Correctness** (0-10): Identifies real issues accurately\n",
    "2. **Tone** (0-10): Professional, encouraging, not dismissive\n",
    "3. **Specificity** (0-10): Concrete suggestions, not vague\n",
    "4. **Educational Value** (0-10): Explains why, teaches concepts\n",
    "5. **Prioritization** (0-10): Distinguishes critical from nice-to-have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnQeuOC0zweg"
   },
   "outputs": [],
   "source": [
    "# Mock Dataset: RLHF for Code Review\n",
    "\n",
    "rlhf_code_review_data = [\n",
    "    {\n",
    "        \"prompt\": \"Review this Python function:\\n\\n```python\\ndef calculate_discount(price, discount_percent):\\n    discount = price * discount_percent\\n    final_price = price - discount\\n    return final_price\\n```\",\n",
    "        \"responses\": [\n",
    "            {\n",
    "                \"text\": \"The function has a bug. You're not dividing discount_percent by 100, so if someone passes 10 for 10%, you'll calculate 10x the price instead of 10% of the price. This needs to be fixed.\",\n",
    "                \"scores\": {\n",
    "                    \"technical_correctness\": 10,\n",
    "                    \"tone\": 5,\n",
    "                    \"specificity\": 7,\n",
    "                    \"educational_value\": 4,\n",
    "                    \"prioritization\": 8\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Good start! I found one issue that would cause incorrect calculations:\\n\\n**Issue: Percentage calculation**\\n- Line 2: `discount = price * discount_percent`\\n- Problem: If discount_percent is 10 (meaning 10%), this calculates price √ó 10 instead of price √ó 0.10\\n- Fix: `discount = price * (discount_percent / 100)`\\n\\n**Suggestions:**\\n1. Add input validation (negative prices/percentages)\\n2. Add a docstring explaining expected inputs\\n3. Consider adding type hints\\n\\n**Example fix:**\\n```python\\ndef calculate_discount(price: float, discount_percent: float) -> float:\\n    \\\"\\\"\\\"Calculate final price after discount.\\n    \\n    Args:\\n        price: Original price (must be positive)\\n        discount_percent: Discount as percentage (e.g., 10 for 10%)\\n    \\\"\\\"\\\"\\n    if price < 0 or discount_percent < 0:\\n        raise ValueError(\\\"Price and discount must be positive\\\")\\n    \\n    discount = price * (discount_percent / 100)\\n    return price - discount\\n```\\n\\nThis makes the function more robust and self-documenting. Nice work overall!\",\n",
    "                \"scores\": {\n",
    "                    \"technical_correctness\": 10,\n",
    "                    \"tone\": 10,\n",
    "                    \"specificity\": 10,\n",
    "                    \"educational_value\": 10,\n",
    "                    \"prioritization\": 9\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"This code could be improved in several ways. First, the calculation logic isn't quite right. Also, you should add error handling. The function needs better documentation. Variable names could be more descriptive. You might want to consider using type hints. Also think about edge cases. Overall this needs work before it's production-ready.\",\n",
    "                \"scores\": {\n",
    "                    \"technical_correctness\": 6,\n",
    "                    \"tone\": 4,\n",
    "                    \"specificity\": 2,\n",
    "                    \"educational_value\": 2,\n",
    "                    \"prioritization\": 3\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Great function! Just one tiny thing - you might want to divide discount_percent by 100. Otherwise looks perfect! üëç\",\n",
    "                \"scores\": {\n",
    "                    \"technical_correctness\": 9,\n",
    "                    \"tone\": 9,\n",
    "                    \"specificity\": 5,\n",
    "                    \"educational_value\": 3,\n",
    "                    \"prioritization\": 7\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üë®‚Äçüíª RLHF USE CASE #3: Code Review Quality\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for example in rlhf_code_review_data:\n",
    "    print(f\"‚ùì PROMPT: {example['prompt']}\\n\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for idx, response in enumerate(example['responses'], 1):\n",
    "        print(f\"\\nüìã RESPONSE {idx}:\\n{response['text']}\\n\")\n",
    "\n",
    "        scores = response['scores']\n",
    "        total_score = sum(scores.values())\n",
    "        max_score = len(scores) * 10\n",
    "\n",
    "        print(f\"\\nüìä SCORES:\")\n",
    "        for dimension, score in scores.items():\n",
    "            bar = \"‚ñà\" * score + \"‚ñë\" * (10 - score)\n",
    "            print(f\"  {dimension.replace('_', ' ').title():20s} {bar} {score}/10\")\n",
    "\n",
    "        print(f\"\\n  {'TOTAL':20s} {total_score}/{max_score} ({total_score/max_score*100:.0f}%)\")\n",
    "        print(\"‚îÄ\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ WHAT THE MODEL LEARNS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\\n\n",
    "1. **Optimal Balance Across All Dimensions:**\n",
    "   - Response 2 scores highest (49/50 = 98%)\n",
    "   - Technical accuracy + encouraging tone + specific fixes + teaching\n",
    "   - Can't sacrifice any dimension\n",
    "\n",
    "2. **Understanding Trade-offs:**\n",
    "   - Response 1: Accurate but abrasive (could discourage developer)\n",
    "   - Response 3: Vague critique without actionable guidance\n",
    "   - Response 4: Too nice, misses educational opportunity\n",
    "\n",
    "3. **Effective Code Review Elements:**\n",
    "   - Point out issue clearly\n",
    "   - Explain WHY it's wrong\n",
    "   - Show exactly HOW to fix it\n",
    "   - Suggest improvements beyond the bug\n",
    "   - Maintain encouraging, professional tone\n",
    "\n",
    "4. **Prioritization:**\n",
    "   - Critical: The bug (must fix)\n",
    "   - Important: Input validation (should fix)\n",
    "   - Nice-to-have: Docstrings, type hints (good to add)\n",
    "\n",
    "‚ú® KEY INSIGHT: Code reviews require balancing being thorough without\n",
    "   being overwhelming, direct without being harsh, and educational without\n",
    "   being condescending. RLHF teaches this nuanced, multi-dimensional quality.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfrW3Gf7zweg"
   },
   "source": [
    "## üìä RLHF Summary\n",
    "\n",
    "### ‚úÖ Strengths\n",
    "\n",
    "1. **Multi-Dimensional Optimization**: Simultaneously optimizes across multiple quality axes\n",
    "2. **Handles Complex Trade-offs**: Understands contextual balance between competing goals\n",
    "3. **Continuous Quality**: Not just \"better/worse\" but \"how much better?\"\n",
    "4. **Most Sophisticated**: State-of-the-art alignment technique\n",
    "5. **Proven at Scale**: Powers ChatGPT, Claude, and other flagship products\n",
    "\n",
    "### ‚ùå Limitations\n",
    "\n",
    "1. **Extreme Complexity**: Multi-stage process, requires ML expertise\n",
    "2. **Very Expensive**: 5-10x cost of preference tuning\n",
    "3. **Data Intensive**: Needs thousands of multi-dimensionally scored examples\n",
    "4. **Slow to Iterate**: Changes require full retraining\n",
    "5. **Overkill for Most**: Simpler methods work for 90% of use cases\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Data Collection for RLHF\n",
    "\n",
    "#### 1. Define Clear Dimensions\n",
    "```\n",
    "‚úÖ Specific, measurable qualities\n",
    "‚úÖ 3-5 dimensions (not too many)\n",
    "‚úÖ Each dimension has clear 0-10 scale\n",
    "‚ùå Vague dimensions like \"quality\"\n",
    "```\n",
    "\n",
    "#### 2. Multiple Raters per Example\n",
    "```\n",
    "Ideal: 3-5 raters score each response\n",
    "Average their scores\n",
    "Track inter-rater agreement\n",
    "```\n",
    "\n",
    "#### 3. Calibration Sessions\n",
    "```\n",
    "Before data collection:\n",
    "- Train raters together\n",
    "- Score practice examples\n",
    "- Discuss disagreements\n",
    "- Establish shared understanding\n",
    "```\n",
    "\n",
    "#### 4. Diverse Response Quality\n",
    "```\n",
    "Include:\n",
    "- Excellent examples (8-10 across dimensions)\n",
    "- Good examples (6-8)\n",
    "- Poor examples (2-5)\n",
    "- Terrible examples (0-2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ When to Use RLHF\n",
    "\n",
    "**Use RLHF when ALL are true:**\n",
    "\n",
    "1. ‚úÖ Quality has 3+ critical dimensions\n",
    "2. ‚úÖ Dimensions sometimes conflict/trade-off\n",
    "3. ‚úÖ Simpler methods have been tried and aren't sufficient\n",
    "4. ‚úÖ You have substantial resources ($10K-100K+ budget)\n",
    "5. ‚úÖ This is a flagship product where quality is paramount\n",
    "\n",
    "**Perfect use cases:**\n",
    "- Conversational AI assistants (ChatGPT-like) ‚úÖ\n",
    "- Safety-critical applications (medical, legal) ‚úÖ\n",
    "- Creative tools with subjective quality ‚úÖ\n",
    "- Complex content moderation ‚úÖ\n",
    "- Code generation with multiple quality criteria ‚úÖ\n",
    "\n",
    "**Not worth it for:**\n",
    "- Simple formatting tasks ‚ùå\n",
    "- Single quality dimension ‚ùå\n",
    "- Prototypes or MVPs ‚ùå\n",
    "- Limited budget (<$5K) ‚ùå\n",
    "- Internal tools with small user base ‚ùå\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
