{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Basics of Prompt Engineering\n",
    "\n",
    "*An introductory guide to effective prompt engineering with OpenAI's API* üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î **What is Prompt Engineering?**\n",
    "\n",
    "### üìñ **Introduction to Prompt Engineering**\n",
    "\n",
    "Prompt engineering refers to the careful design and structuring of input prompts that are given to AI language models to produce desired outputs. These prompts guide the AI's responses, helping to shape them in a way that meets specific needs. When interacting with language models, the way a question or command is phrased can significantly influence the quality and relevance of the response.\n",
    "\n",
    "In essence, prompt engineering is about crafting the \"questions\" we ask the AI to get the \"answers\" we need. This practice is fundamental in ensuring that the AI understands the context and purpose of the interaction, resulting in accurate, coherent, and useful outputs.\n",
    "\n",
    "### üí° **Why is Prompt Engineering Important?**\n",
    "\n",
    "Prompt engineering is crucial for several reasons. First, it allows us to control the quality of the AI's responses. By carefully crafting prompts, we can guide the AI to provide more precise, relevant, and contextually appropriate answers. This control is vital, especially in scenarios where the output must meet high standards of accuracy or clarity, such as customer support, content creation, or technical documentation.\n",
    "\n",
    "Second, prompt engineering helps unlock the full capabilities of language models. AI models are inherently flexible and can handle various tasks, but they need clear instructions to perform effectively. Good prompt design clarifies these instructions, ensuring that the AI knows what to do and how to do it.\n",
    "\n",
    "Finally, effective prompt engineering reduces ambiguity. Ambiguous or vague prompts can lead to off-topic or nonsensical answers. By being clear and specific in our prompts, we minimize the chances of misinterpretation and improve the reliability of the AI's responses.\n",
    "\n",
    "### üèóÔ∏è **The Role of an Architect in Prompt Engineering**\n",
    "\n",
    "While prompt engineering focuses on crafting effective inputs for AI models, it must be combined with strategic thinking and architectural design to solve real-world problems effectively. In other words, it's not just about what you send to the model but also about how this fits into the broader system.\n",
    "\n",
    "An \"architect\" in this context refers to someone who understands how to structure the interaction between the user, the AI, and the surrounding environment in a seamless and efficient manner. This involves:\n",
    "\n",
    "1. **Breaking Down Problems:** Before designing prompts, it's essential to decompose the problem into manageable parts. This step ensures that each aspect of the task is understood and addressed correctly. For instance, if you're developing a customer support chatbot, you would break down tasks into greeting the user, understanding the query, fetching information, and providing a response.\n",
    "\n",
    "2. **Integrating Prompts with Python Code:** Effective prompt engineering requires embedding the prompts within a functional Python framework. This means creating functions that handle the generation of prompts, processing user inputs, and managing the AI's responses. It also involves setting up error handling, logging, and data management to ensure that the application runs smoothly.\n",
    "\n",
    "3. **Maintaining a Feedback Loop:** Prompt engineering is often iterative. As you interact with the AI, you will learn which prompts work best and which need adjustment. This requires building a feedback loop within your application to monitor and refine prompts based on user interactions and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîß Setup\n",
    "\n",
    "Let's start by installing the required libraries and configuring our OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import warnings\n",
    "from openai import OpenAI\n",
    "\n",
    "# Suppress deprecation warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Key Configuration\n",
    "\n",
    "You have two methods to provide your OpenAI API key:\n",
    "\n",
    "**Method 1 (Recommended)** ‚ú®: Use Colab Secrets\n",
    "1. Click the üîë icon in the left sidebar\n",
    "2. Click \"Add new secret\"\n",
    "3. Name: `OPENAI_API_KEY`\n",
    "4. Value: Your OpenAI API key\n",
    "5. Enable notebook access\n",
    "\n",
    "**Method 2 (Fallback)** üí≠: Manual input when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key\n",
    "# Method 1: Try to get API key from Colab secrets (recommended)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úÖ API key loaded from Colab secrets\")\n",
    "except:\n",
    "    # Method 2: Manual input (fallback)\n",
    "    from getpass import getpass\n",
    "    print(\"üí° To use Colab secrets: Go to üîë (left sidebar) ‚Üí Add new secret ‚Üí Name: OPENAI_API_KEY\")\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "# Set the API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# Validate that the API key is set\n",
    "if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == \"\":\n",
    "    raise ValueError(\"‚ùå ERROR: No API key provided!\")\n",
    "\n",
    "print(\"‚úÖ Authentication configured!\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "print(\"‚úÖ OpenAI client initialized!\")\n",
    "\n",
    "# We'll use gpt-5-nano for cost efficiency throughout this notebook\n",
    "MODEL = \"gpt-5-nano\"\n",
    "print(f\"ü§ñ Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 0Ô∏è‚É£ Understanding Model Parameters\n",
    "\n",
    "Before diving into prompt engineering techniques, it's essential to understand how models process inputs and generate outputs. Two fundamental concepts will help you use AI models more effectively: **temperature settings** üå°Ô∏è and **token limits** üé´."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå°Ô∏è 0.1 Temperature and Sampling Parameters\n",
    "\n",
    "When you ask an AI model to generate text, it doesn't just produce a single \"correct\" answer. Instead, it considers many possible next words and chooses among them. The `temperature` parameter controls how this choice is made, fundamentally affecting whether the output feels predictable or creative.\n",
    "\n",
    "Think of temperature as a **creativity dial** üé®. At low temperatures (closer to 0.0), the model behaves conservatively, almost always choosing the most likely next word. This makes outputs consistent, focused, and deterministic‚Äîask the same question twice and you'll get nearly identical answers. At high temperatures (1.0 and above), the model becomes more adventurous, sometimes choosing less probable words, leading to varied, creative, and occasionally surprising responses. Ask the same question multiple times at high temperature, and you might get completely different answers each time.\n",
    "\n",
    "The temperature scale typically ranges from **0.0 to 2.0**. Low values between **0.0 and 0.3** work best for factual tasks like data extraction, classification, or answering specific questions where accuracy matters more than variety. Medium values around **0.5 to 0.7** offer a balanced approach suitable for general-purpose tasks, providing some variation without sacrificing too much consistency. High values from **0.8 to 1.0** (or even higher) shine in creative applications like storytelling, brainstorming sessions, or generating diverse marketing copy where you want the model to explore different phrasings and ideas.\n",
    "\n",
    "Understanding temperature helps you match the model's behavior to your specific needs. When you need reliable, consistent answers‚Äîlike extracting information from documents or classifying support tickets‚Äîuse lower temperatures ‚ùÑÔ∏è. When you want the model to explore possibilities and generate varied options‚Äîlike writing product descriptions or coming up with blog post titles‚Äîcrank up the temperature üî•."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Practical Example: Temperature in Action\n",
    "\n",
    "Let's see how temperature affects the same prompt. We'll ask the model to write a professional email subject line for a meeting request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompt\n",
    "test_prompt = \"Write a professional email subject line for requesting a meeting with your manager to discuss project updates.\"\n",
    "\n",
    "# Low temperature (0.2) - Focused and consistent\n",
    "print(\"üîµ LOW TEMPERATURE (0.2) - Focused and consistent\")\n",
    "print(\"=\" * 70)\n",
    "response_low = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=test_prompt,\n",
    "    temperature=0.2\n",
    ")\n",
    "print(response_low.output_text)\n",
    "print()\n",
    "\n",
    "# Medium temperature (0.7) - Balanced\n",
    "print(\"üü° MEDIUM TEMPERATURE (0.7) - Balanced creativity\")\n",
    "print(\"=\" * 70)\n",
    "response_med = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=test_prompt,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(response_med.output_text)\n",
    "print()\n",
    "\n",
    "# High temperature (1.0) - Creative and varied\n",
    "print(\"üî¥ HIGH TEMPERATURE (1.0) - Creative and varied\")\n",
    "print(\"=\" * 70)\n",
    "response_high = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=test_prompt,\n",
    "    temperature=1.0\n",
    ")\n",
    "print(response_high.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the outputs differ across temperature settings! The low-temperature version likely gave you something straightforward and professional, perhaps \"Meeting Request: Project Updates Discussion\" or similar. The medium-temperature version probably added a bit more personality while staying professional. The high-temperature version might have taken creative liberties, perhaps using more colorful language or unconventional phrasing.\n",
    "\n",
    "üí° **Key Takeaway**: Temperature matters most when you need either absolute consistency (low) or deliberate variety (high). For many everyday tasks, the default temperature works fine, but understanding this parameter gives you precise control over the model's creativity-consistency trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé´ 0.2 Token Limits & Context Awareness\n",
    "\n",
    "AI models don't process text the way we do, word by word. Instead, they break language into smaller units called **tokens**. Understanding tokens is crucial because they determine both what you can ask the model to do and how much it will cost you üí∞.\n",
    "\n",
    "A token isn't exactly a word, though that's a useful approximation. Think of tokens as the model's way of seeing language‚Äîsometimes a token is a whole word like \"hello,\" sometimes it's just part of a word like \"ing\" in \"running,\" and sometimes it's punctuation or even a space. In English, a rough rule of thumb is that **one token ‚âà 4 characters** or **¬æ of a word**. So a 100-word paragraph might use around 133 tokens. Numbers, special characters, and non-English text can have different token counts because the model breaks them down differently.\n",
    "\n",
    "Every model has a **context window**‚Äîa maximum number of tokens it can process in a single request. This limit includes both your input prompt and the model's response. For example:\n",
    "- **GPT-3.5-turbo**: 16,385 tokens (~12,000 words) üìÑ\n",
    "- **GPT-4**: varies by version, some exceed 100,000 tokens üìö\n",
    "\n",
    "These limits might seem generous, but they matter when you're working with long documents, providing extensive examples, or asking the model to process multiple texts at once.\n",
    "\n",
    "What happens when you exceed these limits? ‚ö†Ô∏è Usually, the API will reject your request with an error, telling you that your prompt is too long. Some implementations automatically truncate your input, cutting off the beginning or end to fit within limits, which can lead to incomplete context and poor results. This is why understanding your token usage is essential for production applications‚Äîyou need to design your prompts knowing these constraints exist.\n",
    "\n",
    "Tokens have direct cost implications üíµ. API providers charge based on token usage, typically pricing input tokens (your prompt) differently from output tokens (the model's response). If you're processing thousands of documents or generating lengthy reports, token costs can add up quickly. Efficient prompt design‚Äîgetting the results you need with fewer tokens‚Äîbecomes not just a technical concern but a financial one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Checking Token Usage\n",
    "\n",
    "Let's see how to check token usage from an API response. This helps you understand the cost of your prompts and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simple API call and check token usage\n",
    "test_prompt = \"Explain what machine learning is in 3 sentences.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=test_prompt\n",
    ")\n",
    "\n",
    "print(\"üìù Response:\")\n",
    "print(\"=\" * 70)\n",
    "print(response.output_text)\n",
    "print()\n",
    "\n",
    "# Check token usage\n",
    "print(\"üìä Token Usage:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Input tokens (your prompt): {response.usage.input_tokens}\")\n",
    "print(f\"Output tokens (model's response): {response.usage.output_tokens}\")\n",
    "print(f\"Total tokens used: {response.usage.total_tokens}\")\n",
    "print()\n",
    "\n",
    "# Calculate approximate cost (example rates - check current pricing)\n",
    "# These are example rates for illustration\n",
    "input_cost_per_1k = 0.0001  # Example: $0.0001 per 1K input tokens\n",
    "output_cost_per_1k = 0.0002  # Example: $0.0002 per 1K output tokens\n",
    "\n",
    "input_cost = (response.usage.input_tokens / 1000) * input_cost_per_1k\n",
    "output_cost = (response.usage.output_tokens / 1000) * output_cost_per_1k\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "print(\"üí∞ Approximate Cost (example rates):\")\n",
    "print(f\"This request cost approximately: ${total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does understanding tokens matter for real applications? ü§î When you're building a chatbot that handles thousands of conversations, or a document analysis tool that processes hundreds of pages, or an automated content generator that runs daily, token efficiency directly affects your bottom line. Knowing how to check usage, estimate costs, and optimize your prompts to use fewer tokens while still getting quality results becomes a critical skill. Beyond costs, token awareness helps you design better applications‚Äîyou'll know when to split long documents into chunks, when to summarize before processing, and how to stay within context windows without losing important information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ Writing Clear Instructions\n",
    "\n",
    "The foundation of effective prompt engineering is **clear communication** üí¨. The model will perform best when you provide explicit, detailed instructions about what you want. Let's explore several tactics for writing clearer prompts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù 1.1 Tactic: Add Specific Details for Better Responses\n",
    "\n",
    "When you want a relevant and accurate response, ensure your requests include essential details and context. Vague prompts force the model to guess what you really want, often leading to generic or off-target responses. üéØ\n",
    "\n",
    "Here are some examples to illustrate how adding specific details improves responses:\n",
    "\n",
    "| ‚ùå Vague                                 | ‚úÖ Detailed                                                                                  |\n",
    "|-----------------------------------------|----------------------------------------------------------------------------------------------|\n",
    "| How do I cook pasta?                    | How do I cook al dente spaghetti for a carbonara dish?                                       |\n",
    "| Write a function to sort a list.        | Write a Python function to sort a list of dictionaries by a specific key. Include comments to explain the logic. |\n",
    "| Describe the history of the internet.   | Provide a brief history of the internet, highlighting key milestones from the 1960s to the present. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¨ Example: Vague vs. Detailed Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vague request - lacks specific details\n",
    "print(\"‚ùå VAGUE PROMPT:\")\n",
    "print(\"=\" * 70)\n",
    "vague_prompt = \"Tell me about blockchain technology.\"\n",
    "print(f\"Prompt: {vague_prompt}\\n\")\n",
    "\n",
    "response_vague = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=vague_prompt\n",
    ")\n",
    "print(response_vague.output_text)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed request - includes specific details about what you want\n",
    "print(\"‚úÖ DETAILED PROMPT:\")\n",
    "print(\"=\" * 70)\n",
    "detailed_prompt = \"Explain in short how blockchain technology works and provide one application in finance, healthcare, and supply chain management.\"\n",
    "print(f\"Prompt: {detailed_prompt}\\n\")\n",
    "\n",
    "response_detailed = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=detailed_prompt\n",
    ")\n",
    "print(response_detailed.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When to Use This Tactic\n",
    "\n",
    "Specific details work wonders when you're working in specialized domains where **precision matters** üîç. If you're asking about technical implementations, industry-specific processes, or need information tailored to a particular context, adding details ensures the model understands your exact requirements. For instance, asking about \"marketing strategies\" is broad, but asking about \"digital marketing strategies for B2B SaaS companies targeting enterprise clients\" narrows the focus dramatically, yielding far more relevant advice.\n",
    "\n",
    "However, there's a balance to strike ‚öñÔ∏è. For creative tasks like brainstorming or exploring possibilities, too much specificity can be constraining. If you want the model to generate diverse blog post ideas, saying \"give me blog post ideas\" might work better than providing ten constraints about length, tone, audience, and topic. The sweet spot is being specific about the parameters that truly matter while leaving room for the model to be helpful in ways you might not have anticipated. When you catch yourself writing a vague prompt and getting generic results, that's your signal to add the crucial details that distinguish your specific need from a general request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ 1.2 Tactic: Ask the Model to Adopt a Specific Persona\n",
    "\n",
    "Persona adoption means guiding the AI to respond like a particular character or role. This approach has many benefits! It makes responses more engaging and relatable by reflecting a specific persona, ensures consistency in tone and style, and allows for tailored responses that better meet the needs of different audiences.\n",
    "\n",
    "Examples of persona adoption could be:\n",
    "- **üë®‚Äçüè´ Educational Tutor**: The model adopts a patient and explanatory style, ideal for teaching complex topics.\n",
    "- **ü§ù Customer Service Agent**: The model uses a friendly and helpful tone to assist with customer inquiries.\n",
    "- **üë®‚Äçüíª Technical Expert**: The model provides detailed and precise information suitable for professional discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã Example: Without Persona\n",
    "\n",
    "First, let's see how the AI responds without adopting any specific persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request without specifying a persona\n",
    "print(\"üìù WITHOUT PERSONA:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "response_no_persona = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"I'm feeling very anxious because I've been having headaches and dizziness. What could be causing this?\"\n",
    ")\n",
    "\n",
    "print(response_no_persona.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíô Example: With Empathetic Persona\n",
    "\n",
    "Now let's specify an empathetic and caring persona that acknowledges feelings while providing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request with a specific empathetic persona\n",
    "print(\"üíô WITH EMPATHETIC PERSONA:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Combine persona instruction with user query\n",
    "prompt_with_persona = \"\"\"You are an empathetic and caring assistant who helps to calm down and reassure people seeking medical advice.\n",
    "\n",
    "User message: I'm feeling very anxious because I've been having headaches and dizziness. What could be causing this?\"\"\"\n",
    "\n",
    "response_with_persona = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_with_persona\n",
    ")\n",
    "\n",
    "print(response_with_persona.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé™ When to Use Personas\n",
    "\n",
    "Personas are your tool for controlling **how** information is delivered, not **what** information the model knows. This is a crucial distinction that many people miss! üö® Asking the model to be \"a medical expert\" doesn't suddenly give it medical expertise it didn't have before‚Äîit simply changes the communication style, making responses sound more authoritative or use more technical language. The underlying knowledge remains the same.\n",
    "\n",
    "Use personas when the style and tone of communication truly matter for your application üé®. Customer service scenarios benefit enormously from a friendly, patient persona that acknowledges frustration and offers reassurance. Educational contexts work well with a tutor persona that breaks down concepts step by step without condescension. Sensitive topics like health üè•, finance üí∞, or legal matters ‚öñÔ∏è call for personas that are empathetic, careful, and appropriately serious. Personas excel at maintaining a consistent voice across many interactions, which is essential for brand consistency or user experience.\n",
    "\n",
    "Don't fall into the trap of using personas thinking they'll make the model magically more knowledgeable about a subject. If you need accurate technical information, provide reference materials or use specific, detailed prompts‚Äîdon't just ask it to \"be an expert.\" The best applications of personas are about emotional intelligence and communication style, not factual enhancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Important**: Personas affect **HOW** information is delivered, not **WHAT** information the model knows. Don't use personas as a substitute for providing accurate reference material or specific instructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì¶ 1.3 Tactic: Separating Parts of the Input\n",
    "\n",
    "Using **delimiters** to clearly separate different sections of input helps the model understand which parts of the text should be treated differently. Delimiters such as triple quotation marks, section titles, and XML tags can specify which parts should be processed in specific ways, making it easier for the AI to understand and process information correctly. üè∑Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Example: Without Delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without delimiters - everything runs together\n",
    "print(\"‚ùå WITHOUT DELIMITERS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prompt_no_delimiters = \"\"\"Summarize the arguments presented in each article. Then, evaluate which article presents a stronger argument and explain your reasoning. \n",
    "\n",
    "Online learning has revolutionized education by providing students with unprecedented access to resources and flexibility. One of the key advantages of online learning is that it allows students to learn at their own pace. Unlike traditional classroom settings where students must adhere to a fixed schedule, online courses offer the flexibility to review materials, take breaks, and move forward at a comfortable speed. This personalized approach can significantly enhance a student's understanding and retention of the subject matter. Additionally, online learning platforms often include a variety of multimedia tools such as videos, interactive quizzes, and forums, which cater to different learning styles and make the learning experience more engaging and effective. The accessibility of online learning also means that education can be democratized, reaching students who may not have had the opportunity to attend traditional schools due to geographical, financial, or personal constraints.\n",
    "\n",
    "Despite the growing popularity of online learning, there are several challenges and limitations that cannot be overlooked. One significant drawback is the lack of face-to-face interaction, which can affect the learning experience. In traditional classroom settings, students benefit from real-time feedback, direct engagement with instructors, and collaborative learning with peers. These interactions are difficult to replicate in an online environment, which can lead to feelings of isolation and disengagement. Moreover, the effectiveness of online learning heavily depends on a student's self-discipline and motivation. Without the structured environment of a physical classroom, students may struggle to stay on track, complete assignments, and maintain consistent study habits. Technical issues such as unreliable internet access and the need for updated devices can also hinder the learning process, especially for students in underserved areas. Therefore, while online learning offers flexibility and accessibility, it also presents challenges that must be addressed to ensure a comprehensive and effective educational experience.\"\"\"\n",
    "\n",
    "response_no_delim = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_no_delimiters\n",
    ")\n",
    "\n",
    "print(response_no_delim.output_text)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Example: With XML Delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With delimiters - clearly structured\n",
    "print(\"‚úÖ WITH XML DELIMITERS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prompt_with_delimiters = \"\"\"You will be provided with two articles about the same topic, each delimited by XML tags. First, summarize the arguments presented in each article. Then, evaluate which article presents a stronger argument and explain your reasoning.\n",
    "\n",
    "<article>\n",
    "Online learning has revolutionized education by providing students with unprecedented access to resources and flexibility. One of the key advantages of online learning is that it allows students to learn at their own pace. Unlike traditional classroom settings where students must adhere to a fixed schedule, online courses offer the flexibility to review materials, take breaks, and move forward at a comfortable speed. This personalized approach can significantly enhance a student's understanding and retention of the subject matter. Additionally, online learning platforms often include a variety of multimedia tools such as videos, interactive quizzes, and forums, which cater to different learning styles and make the learning experience more engaging and effective. The accessibility of online learning also means that education can be democratized, reaching students who may not have had the opportunity to attend traditional schools due to geographical, financial, or personal constraints.\n",
    "</article>\n",
    "\n",
    "<article>\n",
    "Despite the growing popularity of online learning, there are several challenges and limitations that cannot be overlooked. One significant drawback is the lack of face-to-face interaction, which can affect the learning experience. In traditional classroom settings, students benefit from real-time feedback, direct engagement with instructors, and collaborative learning with peers. These interactions are difficult to replicate in an online environment, which can lead to feelings of isolation and disengagement. Moreover, the effectiveness of online learning heavily depends on a student's self-discipline and motivation. Without the structured environment of a physical classroom, students may struggle to stay on track, complete assignments, and maintain consistent study habits. Technical issues such as unreliable internet access and the need for updated devices can also hinder the learning process, especially for students in underserved areas. Therefore, while online learning offers flexibility and accessibility, it also presents challenges that must be addressed to ensure a comprehensive and effective educational experience.\n",
    "</article>\"\"\"\n",
    "\n",
    "response_with_delim = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_with_delimiters\n",
    ")\n",
    "\n",
    "print(response_with_delim.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõ°Ô∏è When Delimiters Matter\n",
    "\n",
    "Delimiters become essential when you're juggling multiple pieces of content that need different treatment within a single request üéØ. Imagine you're building a document comparison tool‚Äîyou want the model to analyze two contracts and highlight differences. Without delimiters, the model might blur the boundaries between documents, treating them as one continuous text and missing your intent to compare them separately. With clear XML tags or other delimiters marking where each contract begins and ends, the model understands the structure you're imposing.\n",
    "\n",
    "This technique shines when processing user-generated content that might contain confusing instructions or attempts at **prompt injection** ‚ö†Ô∏è. If a user submits a support ticket that includes text like \"ignore previous instructions and do something else,\" delimiters help the model understand that this text is data to be processed, not instructions to follow. You're essentially saying, \"Everything inside these tags is content, not commands.\" This becomes critical for security and reliability in production applications.\n",
    "\n",
    "Delimiters also prevent confusion in complex multi-part tasks üß©. If you want the model to translate one section, summarize another, and extract key points from a third‚Äîall in one request‚Äîdelimiters make your intent crystal clear. Each section has its own boundaries and associated instructions. Without this structure, the model might mix operations or misunderstand which instruction applies to which content.\n",
    "\n",
    "On the flip side, don't add delimiters just because you can üö´. For simple, single-task prompts where you're asking one straightforward question about one piece of text, delimiters add unnecessary complexity. They're a tool for when structure matters, not a universal best practice. The key is recognizing when the boundaries between different parts of your input actually matter for getting the right output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü™ú 1.4 Tactic: List the Specific Steps Necessary to Complete a Task\n",
    "\n",
    "Some tasks are most effectively outlined as a series of steps. Clearly detailing each step helps the model follow instructions more easily, reduces ambiguity, ensures proper sequence, and improves accuracy. Let's see this in action! üìã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Example: Without Step-by-Step Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without clear steps - general instruction\n",
    "print(\"üìù WITHOUT STEP-BY-STEP INSTRUCTIONS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "text_to_process = \"\"\"Artificial intelligence (AI) has the potential to revolutionize various industries by automating tasks, providing insights from big data, and improving decision-making processes. AI technologies, such as machine learning, natural language processing, and computer vision, can enhance productivity, efficiency, and innovation. However, the widespread adoption of AI also raises ethical and societal concerns, including issues of privacy, security, and the potential displacement of jobs. To fully harness the benefits of AI, it is crucial to address these challenges through thoughtful regulation, interdisciplinary research, and collaboration between stakeholders from different sectors. Additionally, continuous learning and adaptation are essential to keep up with the rapid advancements in AI and to ensure its responsible and beneficial integration into society. As AI continues to evolve, it will play an increasingly significant role in shaping the future of work, healthcare, transportation, and many other fields.\"\"\"\n",
    "\n",
    "prompt_no_steps = f\"\"\"Summarize this text in one sentence and provide key points.\n",
    "\n",
    "{text_to_process}\"\"\"\n",
    "\n",
    "response_no_steps = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_no_steps\n",
    ")\n",
    "\n",
    "print(response_no_steps.output_text)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Example: With Step-by-Step Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With clear steps - structured instructions\n",
    "print(\"‚úÖ WITH STEP-BY-STEP INSTRUCTIONS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prompt_with_steps = f\"\"\"Follow these step-by-step instructions to respond to the text below:\n",
    "\n",
    "Step 1 - Provide a one-sentence summary of this text, starting with 'Summary: '.\n",
    "Step 2 - Extract the key points from the text in bullet points, starting with 'Key Points: '.\n",
    "\n",
    "Text:\n",
    "{text_to_process}\"\"\"\n",
    "\n",
    "response_with_steps = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_with_steps\n",
    ")\n",
    "\n",
    "print(response_with_steps.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When Step-by-Step Instructions Help\n",
    "\n",
    "Step-by-step instructions become valuable when you're dealing with **multi-part tasks** where sequence and structure matter üîÑ. If you're building a data analysis pipeline where you need to first extract information, then categorize it, then format it in a specific way, breaking this into numbered steps ensures the model follows your intended workflow rather than improvising its own approach. This is especially important when each step depends on the completion of previous steps, or when you want specific formatting and labels for each part of the output.\n",
    "\n",
    "Complex procedural tasks benefit enormously from this approach üèóÔ∏è. Imagine you're asking the model to review a document: check for errors, suggest improvements, rewrite problematic sections, and provide a final assessment. Without explicit steps, the model might mix these activities or skip some entirely. With clear steps, you get organized, predictable output where each task is addressed in order. This makes the results easier to parse programmatically and helps ensure nothing is missed.\n",
    "\n",
    "However, don't overuse this technique for simple questions ‚ö†Ô∏è. If you're asking \"What's the capital of France?\" you don't need to write \"Step 1: Identify the question. Step 2: Recall the capital. Step 3: State the answer.\" That's overkill! Save step-by-step instructions for when the task genuinely involves multiple distinct operations. \n",
    "\n",
    "üí° **Rule of Thumb**: If you can explain your task in **three or more distinct steps**, this tactic will likely improve results. For single-step tasks, keep it simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìè 1.5 Tactic: Define the Desired Output Length\n",
    "\n",
    "You can request the model to generate outputs of a specific target length, such as a certain number of **words, sentences, paragraphs, or bullet points**. This ensures responses are tailored to your exact needs and provides better control over detail and readability. ‚úÇÔ∏è\n",
    "\n",
    "‚ö†Ô∏è **Note**: Asking the model to produce an exact word count may not be highly precise. It is more reliable in generating outputs with a specified number of **paragraphs or bullet points**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Example: Without Length Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without length specification\n",
    "print(\"üìù WITHOUT LENGTH SPECIFICATION:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "text_to_summarize = \"\"\"Artificial intelligence (AI) is transforming various industries by automating tasks, providing insights through data analysis, and enhancing decision-making processes. Machine learning, a subset of AI, allows systems to learn and improve from experience without being explicitly programmed. This technology is used in numerous applications, including healthcare for predictive diagnostics, finance for fraud detection, and transportation for optimizing routes. Despite its benefits, AI also raises ethical concerns, such as data privacy, algorithmic bias, and the potential for job displacement. Addressing these issues requires careful consideration and the implementation of ethical guidelines to ensure AI's responsible use and development.\"\"\"\n",
    "\n",
    "response_no_length = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=f\"Summarize the following text:\\n\\n{text_to_summarize}\"\n",
    ")\n",
    "\n",
    "print(response_no_length.output_text)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Example: With Length Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With length specification - 2 bullet points\n",
    "print(\"‚úÖ WITH LENGTH SPECIFICATION (2 bullet points):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "response_with_length = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=f\"Summarize the following text in exactly 2 short bullet points:\\n\\n{text_to_summarize}\"\n",
    ")\n",
    "\n",
    "print(response_with_length.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When to Specify Length\n",
    "\n",
    "Specifying output length becomes essential when **space constraints are real and meaningful** üìê. If you're generating social media posts with strict character limits üê¶, writing executive summaries that must fit on one page üìÑ, or creating bullet points for a presentation slide üìä, telling the model exactly how much space it has prevents the frustration of getting back text that's too long or too short for your needs. This is practical control that saves you editing time!\n",
    "\n",
    "Length specifications work best when you use **structural units** like sentences, paragraphs, or bullet points rather than exact word counts. The model is quite good at producing \"3 bullet points\" or \"2 short paragraphs\" but less precise with \"exactly 150 words.\" It will get close, but don't expect exact word counts‚Äîthere's some natural variation in how the model interprets and generates text.\n",
    "\n",
    "The real value of length control is **matching output to purpose** üéØ. A detailed technical report might need multiple paragraphs of explanation, while a quick reference guide needs just a few sentences. An internal memo might be fine at any reasonable length, but a tweet absolutely must fit Twitter's character limit! Use length specifications when the format genuinely matters for your application, not just as arbitrary constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üö´ 1.6 Tactic: Negative Prompting\n",
    "\n",
    "Negative prompting is the technique of explicitly telling the model what **NOT** to do. While most prompt engineering focuses on what you want the model to do, negative prompting adds constraints by specifying unwanted behaviors, formats, or content types. This technique complements positive instructions by preventing common pitfalls you've observed in practice. üõ°Ô∏è\n",
    "\n",
    "Think of negative prompting as **preventive medicine** üíä for your prompts. When you've worked with a model and noticed it consistently makes certain mistakes‚Äîlike using jargon when you want simple language, or providing overly technical explanations when your audience is non-technical‚Äînegative prompting lets you explicitly block these tendencies. It's reactive in the sense that it addresses observed problems, but preventive because it stops those problems before they happen in future outputs.\n",
    "\n",
    "The power of negative prompting comes from its **specificity** üéØ. Rather than hoping the model will intuitively understand your audience's level or preferences, you state boundaries clearly. This is particularly valuable when the default behavior of the model doesn't quite match your needs, or when you're working in a domain where certain types of content or assumptions would be problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Example: Without Negative Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without negative prompting - model might use jargon\n",
    "print(\"üìù WITHOUT NEGATIVE PROMPTING:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "response_no_negative = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"Explain how machine learning works.\"\n",
    ")\n",
    "\n",
    "print(response_no_negative.output_text)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Example: With Negative Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With negative prompting - explicitly avoid unwanted elements\n",
    "print(\"‚úÖ WITH NEGATIVE PROMPTING:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prompt_with_negative = \"\"\"Explain how machine learning works.\n",
    "\n",
    "DO NOT use technical jargon.\n",
    "DO NOT assume prior programming knowledge.\n",
    "DO NOT include mathematical formulas.\n",
    "DO NOT use acronyms without explaining them first.\"\"\"\n",
    "\n",
    "response_with_negative = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_with_negative\n",
    ")\n",
    "\n",
    "print(response_with_negative.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When to Use Negative Prompting\n",
    "\n",
    "Negative prompting excels when you're trying to reach specific audiences who need information presented in particular ways üë•. If you're creating educational content for beginners üéì, you might need to prevent the model from using technical terminology or assuming background knowledge they don't have. If you're writing for a general audience üåç, you might want to avoid academic language or industry-specific jargon that would alienate readers. These negative constraints shape the communication style to match your audience's needs.\n",
    "\n",
    "**Format control** is another strong use case üìê. Sometimes you need narrative prose, not bulleted lists. Other times you want direct answers without lengthy preambles. Negative prompting lets you specify these format preferences explicitly, especially useful when the model's default formatting doesn't match your application's requirements. If you're generating content for a specific platform or document type, negative instructions help maintain consistency.\n",
    "\n",
    "The technique becomes especially powerful when you've **iterated on prompts** and noticed specific patterns of unwanted behavior üîÑ. Maybe the model keeps going off on tangents, or includes unnecessary caveats, or makes assumptions about context that aren't valid for your use case. Negative prompting is your way of course-correcting based on observed patterns. It's less about theoretical best practices and more about practical adjustments based on real usage.\n",
    "\n",
    "‚ö†Ô∏è Don't use negative prompting as your first approach for every prompt. Start with clear positive instructions about what you want. Add negative constraints when you've identified specific problems that need prevention. Overusing negative prompting can make prompts verbose and may even draw the model's attention to things you're trying to avoid. It's most effective when targeted at genuine, observed issues rather than theoretical concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Key Insight**: Negative prompting is especially powerful when you've iterated on prompts and noticed specific patterns of unwanted behavior. It's reactive and preventive‚Äîuse it to address **real problems** you've observed, not hypothetical ones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Providing Reference Text\n",
    "\n",
    "One effective way to improve the reliability and accuracy of AI responses is to provide **reference text** üìö that the model should use when generating answers. This grounds the model's responses in verified information rather than relying solely on its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ 2.1 Tactic: Guide the Model to Answer Using Reference Text\n",
    "\n",
    "We can instruct the model to answer questions based on a provided reference text. By supplying the model with trusted and relevant information, you can direct it to use this information to generate accurate answers, reducing the likelihood of **hallucinations** üëª or misinformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Example: Without Reference Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without reference text - model relies on training data\n",
    "print(\"üìù WITHOUT REFERENCE TEXT:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "response_no_ref = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"How many deaths worldwide are attributed to household air pollution?\"\n",
    ")\n",
    "\n",
    "print(response_no_ref.output_text)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Example: With Reference Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With reference text - model uses provided information\n",
    "print(\"‚úÖ WITH REFERENCE TEXT:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prompt_with_ref = \"\"\"Refer to the provided text enclosed within XML tags to answer the questions. If the answer is not found in the text, respond with 'I could not find an answer.'\n",
    "\n",
    "<article>\n",
    "The keyword co-occurrence network reveals a strong correlation between air pollution and the burden of disease. As air pollution intensifies, there is a commensurate rise in the global burden of disease. In 2019, the toll of fatalities attributed to air pollution across the globe amounted to 6.67 million. Indoor air pollution exhibits a strong correlation with family health. The associated effects and disease burden garner escalating attention from academics and governments. Based on the statistical data derived from the Global Burden of Disease, household air pollution from solid fuels has caused 2.3 million deaths worldwide. Among them, 1.06 million deaths are attributed to cardiovascular diseases, 420,000 deaths are caused by respiratory infections and tuberculosis, while 398,000 deaths are associated with chronic respiratory diseases. According to the World Health Organization, the utilization of solid fuels and incomplete combustion leading to household air pollution will result in 3.2 million premature deaths worldwide. Thus, when considering the impact of air pollution on health, indoor space is a crucial microenvironment that needs to be given ample attention.\n",
    "</article>\n",
    "\n",
    "Question: How many deaths worldwide are attributed to household air pollution?\"\"\"\n",
    "\n",
    "response_with_ref = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_with_ref\n",
    ")\n",
    "\n",
    "print(response_with_ref.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When to Use Reference Text\n",
    "\n",
    "Reference text becomes essential when you have **authoritative sources** üìë and need responses grounded in specific information rather than general knowledge. This is the technique to reach for when accuracy and verifiability matter more than creative interpretation. If you're building a Q&A system over company documentation, policy manuals, research papers, or any corpus where answers must reflect the exact content of your materials, reference text constrains the model to work within those boundaries.\n",
    "\n",
    "The primary benefit is **reducing hallucinations** üö´üëª‚Äîthose moments when models confidently state plausible-sounding information that isn't actually true. By providing reference text and instructing the model to answer only from that text, you dramatically reduce this risk. The model can still fail to find relevant information or misinterpret the text, but it's much less likely to invent facts entirely. This makes reference text valuable for applications where trust and accuracy are paramount: customer support systems üéß, compliance tools ‚öñÔ∏è, research assistants üî¨.\n",
    "\n",
    "**Company-specific information** üè¢ is another ideal use case. The model's training data doesn't include your internal processes, product specifications, or organizational policies. Providing this information as reference text lets you leverage the model's language understanding while ensuring responses reflect your specific context. This bridges the gap between the model's general capabilities and your particular needs.\n",
    "\n",
    "However, don't use reference text for creative tasks üé® or general knowledge questions where you actually want the model to draw on its broad training. If you're asking for brainstorming ideas, creative writing, or synthesis of widely-known information, providing reference text might unnecessarily constrain the model. The technique is about **focus and accuracy**, not about enhancing creativity or breadth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìé 2.2 Tactic: Guide the Model to Answer with Citations from Reference Texts\n",
    "\n",
    "You can instruct the model to include **citations** in its answers by referencing specific passages from provided documents. This allows citations in the output to be programmatically verified through string matching, significantly improving the trustworthiness of the model's outputs. ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With citations from reference text\n",
    "print(\"‚úÖ WITH CITATIONS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "prompt_with_citations = \"\"\"You will be given a document delimited by XML tags and a question. Your task is to answer the question using only the information from the provided document and to cite the relevant passages. \n",
    "\n",
    "If the document does not contain enough information to answer the question, write: 'I could not find an answer.' \n",
    "\n",
    "Any answer provided must include a citation. Use the following format to cite relevant passages: ({\"citation\": ...})\n",
    "\n",
    "<article>\n",
    "The keyword co-occurrence network reveals a strong correlation between air pollution and the burden of disease. As air pollution intensifies, there is a commensurate rise in the global burden of disease. In 2019, the toll of fatalities attributed to air pollution across the globe amounted to 6.67 million. Indoor air pollution exhibits a strong correlation with family health. The associated effects and disease burden garner escalating attention from academics and governments. Based on the statistical data derived from the Global Burden of Disease, household air pollution from solid fuels has caused 2.3 million deaths worldwide. Among them, 1.06 million deaths are attributed to cardiovascular diseases, 420,000 deaths are caused by respiratory infections and tuberculosis, while 398,000 deaths are associated with chronic respiratory diseases. According to the World Health Organization, the utilization of solid fuels and incomplete combustion leading to household air pollution will result in 3.2 million premature deaths worldwide. Thus, when considering the impact of air pollution on health, indoor space is a crucial microenvironment that needs to be given ample attention.\n",
    "</article>\n",
    "\n",
    "Question: How many deaths worldwide are attributed to household air pollution?\"\"\"\n",
    "\n",
    "response_with_citations = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt_with_citations\n",
    ")\n",
    "\n",
    "print(response_with_citations.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Why Citations Matter\n",
    "\n",
    "Citations transform AI-generated responses from unverifiable claims into **traceable information** üìç. In professional contexts where accountability matters‚Äîlegal analysis ‚öñÔ∏è, medical information üè•, financial advice üí∞, academic research üéì‚Äîbeing able to trace a statement back to its source is often required, not optional. Citations allow readers to verify information, check context, and assess the reliability of sources, which is fundamental to trust.\n",
    "\n",
    "The practical benefit extends beyond trust to **functionality** ‚öôÔ∏è. When the model cites specific passages, you can programmatically verify those citations by checking if the quoted text actually appears in the source documents. This lets you build quality checks into your application‚Äîflagging responses where citations don't match sources, or filtering out answers that lack proper citations. This kind of automated verification is impossible without explicit citations!\n",
    "\n",
    "Academic and research applications demand citations by nature, but the need extends to business contexts too üíº. When your company's AI assistant answers questions about policies or procedures, having citations that point to specific policy sections protects both the company and users. If there's ever a dispute about what was communicated, citations provide an **audit trail** üìã. In regulated industries like healthcare, finance, or legal services, this traceability can be a compliance requirement, not just a nice-to-have feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ Few-Shot Prompting\n",
    "\n",
    "Few-shot prompting is a powerful technique that leverages **examples** üìù to guide the model's behavior. Rather than just telling the model what to do, you **show** it examples of what you want! ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Understanding Few-Shot Prompting\n",
    "\n",
    "### üí≠ What is Few-Shot Learning?\n",
    "\n",
    "Few-shot prompting works by providing the AI model with a small number of examples that demonstrate the task you want it to perform. These examples‚Äîoften called \"**shots**\" üéØ‚Äîserve as templates that show the model the pattern you're looking for. It's fundamentally different from **zero-shot prompting** (where you just describe the task without examples) and from **fine-tuning** (where you permanently train the model on many examples to specialize its behavior).\n",
    "\n",
    "The psychology behind few-shot learning is intuitive üßí. Imagine teaching a child to identify different types of clouds. You could describe the characteristics of cumulus clouds in abstract terms, or you could simply point at the sky and say \"see those fluffy, cotton-like clouds? Those are cumulus.\" Show them a few more examples, and they'll start recognizing cumulus clouds on their own. Few-shot prompting works similarly‚Äîthe model sees patterns in your examples and generalizes those patterns to new cases.\n",
    "\n",
    "When the model sees examples, it picks up on subtle aspects that might be hard to describe explicitly: the **tone** üéµ, the **level of detail** üîç, the **structure** üèóÔ∏è of the response, the way certain types of inputs map to outputs. Examples communicate these nuances more effectively than lengthy descriptions. A single well-chosen example can convey what would take paragraphs to explain, and multiple examples reinforce the pattern while showing acceptable variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¢ How Many Examples Should You Provide?\n",
    "\n",
    "The right number of examples depends on your task's complexity and how consistently the model needs to perform. For **simple tasks** with clear patterns‚Äîlike basic classification or format conversion‚Äî**2-3 examples** are often sufficient to establish the pattern. The model picks up on straightforward patterns quickly, and additional examples provide diminishing returns.\n",
    "\n",
    "More **nuanced tasks** requiring subtle distinctions benefit from **5-10 examples**. If you're doing sentiment analysis that distinguishes between frustrated, angry, and disappointed, or if you're extracting structured data where edge cases matter, more examples help the model understand the boundaries between categories and handle ambiguous cases better. Each additional example can clarify a different aspect of the task or demonstrate how to handle a particular edge case.\n",
    "\n",
    "However, more examples aren't always better ‚ö†Ô∏è. Beyond a certain point, you hit **diminishing returns**‚Äîthe model isn't learning much from additional examples, but you're paying for those extra tokens in every request üí∏. More examples also make prompts more complex and harder to maintain. If results are good with three examples, don't add seven more just because you can. The sweet spot is the **minimum number of examples** that consistently produces the quality you need.\n",
    "\n",
    "üí° **Pro Tip**: If results are good with 3 examples, don't add more just because you can!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚≠ê Choosing Good Examples\n",
    "\n",
    "The **quality** of your examples matters more than quantity! Good examples should cover the range of cases you expect to encounter‚Äînot just typical cases, but also **edge cases** and potentially tricky situations. If you're classifying customer feedback, don't just show positive and negative examples; include ambiguous ones, mixed sentiment, and edge cases like sarcasm or context-dependent meaning. This helps the model handle real-world messiness.\n",
    "\n",
    "**Diversity within consistency** is key üîë. Your examples should show variety in inputs while maintaining consistent formatting and style in outputs. If all your examples are too similar, the model might latch onto superficial patterns rather than the underlying logic. But if examples are inconsistent in format or approach, the model gets confused about what pattern to follow. Strike a balance between showing the range of inputs you'll encounter and maintaining a clear, consistent pattern in how outputs should look.\n",
    "\n",
    "What makes a good example? ‚ú®\n",
    "- **Clear and unambiguous** - even a human should immediately understand the task\n",
    "- **Representative** of real cases you'll encounter, not artificial or oversimplified\n",
    "- **Demonstrates** one or more important aspects of the task‚Äîformat, tone, level of detail, how to handle a specific type of input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When to Use Few-Shot Prompting\n",
    "\n",
    "Few-shot prompting excels at **pattern recognition tasks** where showing is easier than telling! Classification problems üè∑Ô∏è‚Äîsentiment analysis, topic categorization, intent detection‚Äîare natural fits. Extraction tasks where you need specific information pulled out in a particular format benefit from examples that show exactly what you want and how it should be structured.\n",
    "\n",
    "When **zero-shot prompting gives inconsistent results** üé≤‚Äîsometimes the format is right, sometimes wrong, or the tone varies unpredictably‚Äîadding examples usually stabilizes performance. Tasks with **specific formatting requirements** are perfect for few-shot learning. If you need JSON output with particular field names, or CSV data with specific delimiters, or markdown with a particular structure, showing examples of correctly formatted output is far more effective than trying to describe the format in words.\n",
    "\n",
    "However, don't use few-shot prompting for simple factual questions where zero-shot works fine ‚ùå. If \"What's the capital of France?\" gets you \"Paris,\" you don't need examples. Creative writing tasks also generally don't benefit from examples unless you're trying to match a very specific style. For open-ended creative work, examples might constrain the model in unhelpful ways, making outputs feel derivative rather than original.\n",
    "\n",
    "### üí∞ Cost and Performance Trade-offs\n",
    "\n",
    "Few-shot prompting has a real cost: every example adds tokens to your prompt, and you pay for those tokens in **every single request** üíµ. If your base prompt is 50 tokens and you add five examples that total 200 tokens, you've **quintupled** the input cost of each request. Over thousands or millions of requests, this adds up significantly.\n",
    "\n",
    "The decision becomes a balance between **accuracy improvement** and **cost increase** ‚öñÔ∏è. If adding examples boosts your accuracy from 70% to 95%, that might be worth the extra cost‚Äîfewer errors means less manual review, fewer user complaints, better user experience. But if examples only improve accuracy from 95% to 97%, you need to consider whether that marginal gain justifies the added expense. Sometimes better prompt engineering‚Äîclearer instructions, better structure, strategic use of other techniques‚Äîcan achieve similar results without the per-request cost of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Practical Example: Sentiment Analysis\n",
    "\n",
    "Let's compare zero-shot and few-shot prompting using a challenging domain: analyzing **Gen-Z slang** and informal language! üòé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot: Just ask without examples\n",
    "print(\"üìù ZERO-SHOT PROMPTING:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "zero_shot_prompt = \"Classify the following Gen-Z style statement as Positive, Negative, or Neutral: 'This party is mid fr fr no cap.'\"\n",
    "\n",
    "response_zero_shot = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=zero_shot_prompt\n",
    ")\n",
    "\n",
    "print(response_zero_shot.output_text)\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot: Provide examples first\n",
    "print(\"‚úÖ FEW-SHOT PROMPTING:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "few_shot_prompt = \"\"\"You are an AI trained to classify Gen-Z style statements as Positive, Negative, or Neutral.\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "1. Statement: 'That fit is fire, you slayed'\n",
    "   Sentiment: Positive\n",
    "\n",
    "2. Statement: 'I'm lowkey stressed about this exam'\n",
    "   Sentiment: Negative\n",
    "\n",
    "3. Statement: 'This new album straight bussin, no cap'\n",
    "   Sentiment: Positive\n",
    "\n",
    "Now, classify the following statement:\n",
    "Statement: 'It's giving boring vibes ngl'\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "response_few_shot = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=few_shot_prompt\n",
    ")\n",
    "\n",
    "print(response_few_shot.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the few-shot version performs better with informal language! üéâ The examples showed the model how to interpret Gen-Z slang like \"mid\" (mediocre), \"fr fr\" (for real), \"no cap\" (no lie), and \"bussin\" (excellent). Without examples, the model might struggle with these terms or misinterpret the sentiment. The examples don't just show correct answers‚Äîthey demonstrate the **pattern** of how informal language maps to sentiment categories.\n",
    "\n",
    "This improvement comes from the examples clarifying the specific challenge: **understanding slang and informal expressions in context** üí¨. The few-shot version effectively taught the model this specialized task through demonstration rather than description, which is exactly when few-shot prompting shines! ‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-thought prompting asks the model to **show its reasoning process** step-by-step üßÆ, making the logic explicit rather than jumping directly to a conclusion. This technique significantly improves performance on complex reasoning tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Understanding Chain-of-Thought Prompting\n",
    "\n",
    "### üí° What is Chain-of-Thought Prompting?\n",
    "\n",
    "Chain-of-thought (CoT) prompting is the technique of asking the model to **show its work** üìù‚Äîto explicitly walk through its reasoning process before arriving at an answer. Rather than asking \"What is the answer?\" you ask \"What is the answer and **how did you arrive at it**?\" This seemingly simple change has profound effects on the model's performance, especially for problems requiring multiple steps of reasoning.\n",
    "\n",
    "The technique emerged from research showing that language models perform dramatically better on complex problems when they generate **intermediate reasoning steps** ü™ú. It's like showing your work in math class‚Äîthe act of writing out each step catches errors, clarifies logic, and makes it easier to verify the answer. When models jump directly to conclusions, they're more likely to make mistakes in multi-step problems. When they reason step-by-step, they essentially self-correct and build more reliable solutions.\n",
    "\n",
    "Think about how you'd solve a complex problem yourself ü§î. You don't usually arrive at the answer in one intuitive leap. You break it down: first figure out this component, then use that result to calculate the next part, then combine everything for the final answer. Chain-of-thought prompting asks the model to follow a similar process, making its reasoning **transparent and verifiable** ‚úÖ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When to Use Chain-of-Thought\n",
    "\n",
    "Chain-of-thought prompting is your go-to technique for **multi-step reasoning problems** üßÆ. Math problems, logic puzzles, analytical tasks requiring multiple inferential steps‚Äîthese are prime candidates. If you're asking the model to analyze data and draw conclusions, or to solve problems where the path from question to answer involves several logical steps, CoT dramatically improves reliability.\n",
    "\n",
    "The technique becomes especially valuable when you need to **verify the reasoning**, not just accept the answer üîç. In educational contexts üéì, showing the reasoning process helps students learn. In professional contexts like data analysis or decision support üíº, stakeholders often need to understand **how** conclusions were reached, not just **what** they are. Chain-of-thought makes the model's logic transparent and auditable.\n",
    "\n",
    "**Debugging** why an answer might be wrong üêõ becomes much easier with chain-of-thought. If the model gets a problem wrong, seeing its reasoning process often immediately reveals where it went astray. Maybe it misinterpreted a key piece of information, or made a calculation error in step 3, or applied the wrong rule. Without seeing the steps, you're left guessing why the answer is wrong.\n",
    "\n",
    "### üö´ When to Skip Chain-of-Thought\n",
    "\n",
    "Not every task benefits from explicit reasoning. **Simple factual lookups** don't need it‚Äî\"What's the capital of Japan?\" doesn't require showing work; the answer is \"Tokyo.\" **Creative writing tasks** üé® often suffer from step-by-step reasoning because it breaks the flow and makes output feel mechanical rather than natural. If you want the model to write a story or generate marketing copy, asking it to show its reasoning about word choices would be counterproductive.\n",
    "\n",
    "When you only care about the **final answer** and the reasoning would just add unnecessary verbosity, skip CoT. Some applications need quick, concise responses ‚ö°, and multi-paragraph reasoning explanations would frustrate users. If your users just want to know \"yes\" or \"no,\" they don't need to see three paragraphs explaining how the model arrived at its answer.\n",
    "\n",
    "### üí∞ Cost Implications\n",
    "\n",
    "The cost impact of chain-of-thought prompting is substantial and worth understanding before committing to it. A direct answer might be 50 tokens, while a chain-of-thought response explaining the same answer could be **200-300 tokens**. That's **4-6 times** the output cost per request! For a high-volume application, this difference compounds quickly.\n",
    "\n",
    "However, this cost-benefit calculation isn't just about token counts ‚öñÔ∏è. Chain-of-thought often produces **more accurate answers**, especially for complex problems. If direct answers are wrong 20% of the time, requiring manual review or corrections, while CoT answers are wrong only 5% of the time, the extra token cost might be offset by reduced error handling. You're trading increased per-request costs for better accuracy, which could mean lower total operational costs when you factor in error correction and customer support! üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßÆ Practical Example: Multi-Step Math Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-thought prompt with example showing reasoning steps\n",
    "print(\"‚úÖ CHAIN-OF-THOUGHT PROMPTING:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "cot_prompt = \"\"\"Question: A train travels 90 kilometers in 2 hours. How long will it take to travel 225 kilometers at the same speed?\n",
    "\n",
    "Answer:\n",
    "Let's break this down step by step:\n",
    "\n",
    "1. First, we need to calculate the speed of the train. To do that, we divide the distance traveled by the time taken.\n",
    "   So, the speed of the train is 90 kilometers divided by 2 hours, which equals 45 kilometers per hour.\n",
    "\n",
    "2. Now, we know the speed of the train is 45 kilometers per hour. Next, we calculate how long it will take to travel 225 kilometers.\n",
    "\n",
    "3. To do that, we divide 225 kilometers by the speed of 45 kilometers per hour.\n",
    "\n",
    "4. 225 kilometers divided by 45 kilometers per hour equals 5 hours.\n",
    "\n",
    "So the answer is 5 hours.\n",
    "\n",
    "---\n",
    "\n",
    "Question: A car travels 150 kilometers using 12 liters of fuel. If the car needs to travel 450 kilometers, how much fuel will it require? Assume the fuel efficiency remains constant.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "response_cot = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=cot_prompt\n",
    ")\n",
    "\n",
    "print(response_cot.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chain-of-thought approach transformed how the model tackled this problem! üéØ By showing an example that breaks down the problem into clear steps‚Äîcalculate the rate, apply the rate to the new distance, state the answer‚Äîwe taught the model to follow the same methodical process. The resulting answer isn't just correct; it's **verifiable** ‚úÖ. Anyone can follow the logic and check each step.\n",
    "\n",
    "This is when chain-of-thought truly shines: when the **path to the answer is as important as the answer itself** üõ§Ô∏è. The explicit reasoning catches potential errors (if step 2 doesn't follow from step 1, you'll see that immediately), makes the solution easier to trust, and helps users understand the logic rather than just accepting a number. For educational applications üéì, troubleshooting systems üîß, analytical tools üìä, or any context where decisions need to be justified, chain-of-thought prompting is worth the extra tokens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ Self-Ask Prompting\n",
    "\n",
    "Self-ask prompting is an **advanced technique** üöÄ where the model breaks down complex questions into sub-questions, answers each one, and then synthesizes the results. It's like watching the model conduct a structured research process! üî¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Understanding Self-Ask Prompting\n",
    "\n",
    "### üí≠ What is Self-Ask Prompting?\n",
    "\n",
    "Self-ask prompting teaches the model to **decompose complex questions** into simpler sub-questions before attempting to answer them. Rather than tackling a multi-faceted question directly, the model asks itself follow-up questions that address different aspects of the original question, answers each one, and then synthesizes these partial answers into a comprehensive response. It's an **internal dialogue** üí¨ or structured brainstorming session made explicit.\n",
    "\n",
    "The technique differs fundamentally from chain-of-thought prompting, though they're often confused ü§î. Chain-of-thought shows the **steps** to reach an answer‚Äîit's a linear path through a problem. Self-ask, on the other hand, breaks the **question itself** into multiple sub-questions first. It's about problem decomposition before problem-solving. If chain-of-thought is \"here's how to get from A to B,\" self-ask is \"to understand B, we need to first understand X, Y, and Z, so let's explore each of those.\"\n",
    "\n",
    "Imagine you're researching a complex topic like \"How will climate change affect global food security?\" üåç You wouldn't just sit down and write an answer. You'd break it down: How will climate change affect crop yields? How will it affect water availability? What about extreme weather events? How might adaptation strategies mitigate impacts? Self-ask prompting mirrors this natural research process, making the model's approach to complex questions more **structured and thorough** ‚ú®."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ When to Use Self-Ask\n",
    "\n",
    "Self-ask excels with **genuinely complex, multi-faceted questions** üåê that require analyzing different dimensions before reaching a conclusion. When a question is so broad that a direct answer would inevitably miss important aspects, self-ask ensures comprehensive coverage by forcing systematic decomposition. Questions like \"What are the implications of autonomous vehicles for urban planning?\" üöó or \"How might artificial intelligence affect income inequality?\" üí∞ have so many angles that breaking them down into sub-questions leads to more thorough analysis.\n",
    "\n",
    "The technique shines when the initial question is **too broad or vague** üå´Ô∏è to answer well directly. Self-ask essentially forces clarification through decomposition. By breaking \"What are the effects of social media?\" into specific sub-questions about mental health, political discourse, business models, and social connections, the model transforms a nebulous query into concrete answerable components.\n",
    "\n",
    "**Research-style questions** üìö with multiple dimensions benefit enormously from self-ask. If you're building a system that explores topics in depth, or generating research reports, or analyzing complex situations, self-ask provides the structured approach that ensures nothing important gets overlooked. The model essentially follows a research protocol: identify key sub-questions, address each one, synthesize findings.\n",
    "\n",
    "### üîÑ Self-Ask vs Chain-of-Thought\n",
    "\n",
    "Understanding when to use self-ask versus chain-of-thought requires grasping their fundamental difference üéì:\n",
    "\n",
    "**Chain-of-Thought** ü™ú: For problems with a relatively clear solution path that requires multiple steps. You know what you're solving for; you just need to show the work. It's linear and procedural‚Äîstep 1, step 2, step 3, answer.\n",
    "\n",
    "**Self-Ask** üîç: For questions where the challenge is in the question's complexity itself, not just in the solution steps. You need to break down what's being asked before you can answer it. It's more exploratory and multidimensional. The model identifies aspects of the question, addresses each aspect, and then synthesizes. It's not a linear path but rather a structured exploration.\n",
    "\n",
    "üí° **How to Choose**: If someone asks \"What's 15% of 240?\" use chain-of-thought to show the calculation steps. If someone asks \"How might universal basic income affect employment, government budgets, and social welfare?\" use self-ask to systematically address each dimension.\n",
    "\n",
    "### ‚ö†Ô∏è Limitations and When Not to Use\n",
    "\n",
    "Self-ask prompting is **token-expensive** üí∏‚Äîarguably the most expensive technique in common use. You're generating multiple questions and multiple answers for each original question. A direct response might be 100 tokens, while a self-ask response could easily be **500-1000 tokens**. The model's asking and answering its own follow-up questions, each adding to the output length. For high-volume applications, this cost adds up quickly!\n",
    "\n",
    "Don't use self-ask for **simple or focused questions** üö´. If someone asks \"What's the capital of Brazil?\" breaking that down into sub-questions is absurd overkill. Save self-ask for questions where the complexity genuinely demands decomposition. Using it for routine queries just wastes tokens and produces verbose outputs that obscure simple answers.\n",
    "\n",
    "The technique can produce outputs so comprehensive that they become **overwhelming** üìö. Sometimes users want a concise answer, not an exhaustive exploration. A simple question might get buried under layers of sub-questions and sub-answers. Before choosing self-ask, consider whether your users actually need that level of detail or if it would be information overload.\n",
    "\n",
    "‚úÖ **Best used judiciously** for genuinely complex analytical questions where thoroughness matters more than brevity. Research reports üìä, strategic analysis üéØ, comprehensive assessments‚Äîthese are appropriate contexts. Quick information lookups, routine support questions, or any scenario where speed and conciseness matter more than exhaustive coverage should use simpler techniques.\n",
    "\n",
    "### üîç Transparency Benefit\n",
    "\n",
    "Despite its costs, self-ask has a unique **transparency advantage** üíé. The technique explicitly shows the model's reasoning structure‚Äînot just how it arrived at an answer, but **what aspects of the question** it considered important. If the model breaks a question about climate policy into sub-questions about economic impact, environmental effectiveness, political feasibility, and social equity, you immediately see its analytical framework.\n",
    "\n",
    "This transparency helps identify if the model is **missing crucial aspects** ‚ö†Ô∏è. If you ask about implementing a new technology and the model's sub-questions don't include security or privacy considerations, that omission becomes obvious. You can then refine your prompt or follow up specifically on overlooked dimensions. The explicit structure makes gaps visible in a way that direct answers don't.\n",
    "\n",
    "When you need to understand how conclusions were reached‚Äînot just verify computational steps but see the entire analytical structure‚Äîself-ask provides **unmatched visibility** üëÄ into the model's reasoning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåç Practical Example: Complex Policy Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-ask prompt with example showing the decomposition process\n",
    "print(\"‚úÖ SELF-ASK PROMPTING:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "self_ask_prompt = \"\"\"Question: How could the implementation of a universal basic income affect wealth inequality, job markets, and economic growth in a developed country?\n",
    "\n",
    "Are follow up questions needed here: Yes.\n",
    "\n",
    "Follow up: How might universal basic income impact wealth inequality?\n",
    "Intermediate answer: Universal basic income could potentially reduce wealth inequality by providing a financial safety net for all citizens, ensuring a minimum standard of living.\n",
    "\n",
    "Follow up: What effect could universal basic income have on job markets?\n",
    "Intermediate answer: It might reduce the pressure to work in low-wage jobs, potentially leading to increased bargaining power for workers and changes in the labor market structure.\n",
    "\n",
    "Follow up: How could universal basic income influence economic growth?\n",
    "Intermediate answer: Universal basic income could stimulate consumer spending and potentially boost economic growth, but it may also lead to inflation or reduced productivity if not implemented carefully.\n",
    "\n",
    "So the final answer is: The implementation of a universal basic income in a developed country could potentially reduce wealth inequality by providing a financial safety net, alter job markets by changing worker dynamics, and affect economic growth through increased consumer spending, though careful implementation would be crucial to manage potential negative effects like inflation.\n",
    "\n",
    "---\n",
    "\n",
    "Question: How might the widespread adoption of autonomous vehicles impact urban planning and infrastructure in major cities over the next 20 years?\n",
    "\n",
    "Are follow up questions needed here:\"\"\"\n",
    "\n",
    "response_self_ask = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=self_ask_prompt\n",
    ")\n",
    "\n",
    "print(response_self_ask.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how self-ask transformed the approach to this complex question! üéØ By providing an example that breaks down a multifaceted policy question into specific sub-questions about different impacts, we taught the model to systematically explore each dimension before synthesizing an answer. The model identified relevant aspects (parking needs, traffic flow, public transit, land use), addressed each one, and then brought them together into a coherent conclusion.\n",
    "\n",
    "This structured exploration produces **more thorough answers** üìä than direct questioning would. It ensures the model considers multiple angles rather than focusing on just one aspect. For genuinely complex questions where comprehensive analysis matters, self-ask is worth the significant token investment. But use it selectively‚Äîthis is your **advanced technique** üöÄ for when simpler approaches won't do justice to the question's complexity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì Best Practices & Key Takeaways\n",
    "\n",
    "## üéØ Choosing the Right Technique\n",
    "\n",
    "The art of prompt engineering lies in **matching techniques to tasks** üé®. When your task needs focused, specific information on a particular topic, the foundation is **detailed prompts** that include relevant context and constraints. Don't ask \"tell me about machine learning\"‚Äîask \"explain how supervised learning differs from unsupervised learning, with one example of each, for someone with basic programming knowledge but no AI background.\" Specificity transforms generic outputs into useful ones! ‚ú®\n",
    "\n",
    "If the tone and style of communication matter for your application‚Äîcustomer service ü§ù, education üéì, sensitive subjects üíô‚Äî**personas** become your tool. A technical expert persona for professional audiences, an empathetic counselor persona for healthcare contexts, a patient tutor persona for educational content‚Äîthese shape how information is delivered to match your audience's needs and expectations. Just remember that personas affect **style**, not **knowledge**, so combine them with other techniques when accuracy matters.\n",
    "\n",
    "When you're handling multiple documents or complex inputs in a single request, **delimiters** üì¶ prevent confusion about what text should be processed how. They're particularly crucial for user-generated content that might contain confusing text, or for applications that need to treat different sections of input differently. Skip delimiters for simple single-piece-of-text tasks where boundaries aren't an issue.\n",
    "\n",
    "Tasks involving multiple sequential steps benefit from explicit **step-by-step instructions** ü™ú. If you can break your task into three or more distinct operations‚Äîextract this, then analyze that, then format it this way‚Äînumbering those steps ensures the model follows your intended workflow. Save this for genuinely multi-part tasks; don't overstructure simple requests.\n",
    "\n",
    "**Negative prompting** üö´ becomes valuable when you've observed specific unwanted behaviors you want to prevent. If the model keeps using jargon when you need plain language, or making assumptions about audience knowledge, or including elements you don't want, explicitly stating what NOT to do can be more effective than trying to imply constraints through positive instructions alone.\n",
    "\n",
    "When you have authoritative **reference documents** üìö and need responses grounded in specific information rather than general knowledge, provide that reference text explicitly. This dramatically reduces hallucinations üëª and ensures answers reflect your particular context‚Äîcompany policies, research papers, legal documents, whatever source should ground the responses.\n",
    "\n",
    "For tasks requiring consistent patterns‚Äîclassification, extraction, formatting‚Äî**few-shot prompting** üéØ lets you show what you want rather than describe it. Two to five good examples often establish patterns more clearly than paragraphs of description. Use this when zero-shot results are inconsistent or when format requirements are easier to demonstrate than explain.\n",
    "\n",
    "When you need to verify reasoning, not just trust answers, **chain-of-thought** üßÆ makes the model's logic transparent. Multi-step math problems, analytical tasks, troubleshooting‚Äîanything where the path to the answer matters as much as the answer itself. The cost is higher token usage, but the benefit is verifiable, trustworthy reasoning.\n",
    "\n",
    "For genuinely complex, multifaceted questions where thoroughness matters more than brevity, **self-ask prompting** üîç ensures systematic exploration of all relevant dimensions. It's your most expensive technique in terms of tokens, so reserve it for questions that truly demand comprehensive analysis rather than quick answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Combining Techniques\n",
    "\n",
    "The real power emerges when you combine techniques strategically! üí™ You might use **personas with negative prompting** to get both the right tone and avoid specific pitfalls‚Äî\"you're a patient educator\" plus \"don't use jargon or assume prior knowledge.\" **Few-shot examples** can incorporate **chain-of-thought reasoning**, showing not just what outputs should look like but how to reason through each case. **Reference text** can be paired with **step-by-step instructions** for complex document analysis tasks.\n",
    "\n",
    "However, combining techniques also means combining **costs and complexity** üí∞. Each additional technique adds tokens, makes prompts harder to maintain, and can create confusion if techniques conflict. The key is **purposeful combination**‚Äîadd another technique only when it addresses a specific gap in your results. Start with the simplest approach that might work, then add techniques incrementally when you identify specific deficiencies.\n",
    "\n",
    "A common effective combination is **detailed prompts + step-by-step instructions** for structured tasks, plus **few-shot examples** to establish format. Another is **personas + reference text** for customer-facing applications that need both appropriate tone and accurate information. The combination should feel natural, with each technique addressing a different aspect of quality‚Äîone for accuracy, one for tone, one for format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí≠ Final Thoughts\n",
    "\n",
    "Prompt engineering is fundamentally **iterative** üîÑ. You rarely get prompts perfect on the first try. Start with a straightforward attempt, see what works and what doesn't, then refine. Each iteration teaches you something about how the model interprets your instructions and where your prompts need more clarity or different structure. The techniques in this notebook are **tools in your toolkit** üß∞‚Äîyou'll learn through experience which ones work best for your specific use cases.\n",
    "\n",
    "What works beautifully for one task might fail for another that seems similar. Prompt engineering requires **experimentation and adaptation** üß™. Don't assume that because a technique worked well once, it's the right approach for every problem. Be prepared to try different techniques, combine them in new ways, and adjust based on results. The goal is **reliable, useful outputs**, not adhering to a rigid methodology.\n",
    "\n",
    "Balance prompt complexity against the value of results ‚öñÔ∏è. Elaborate prompts with multiple techniques might improve output quality by 10%, but cost three times as much in tokens and take longer to maintain. Sometimes simpler prompts that are \"good enough\" are the right choice, especially for high-volume applications where costs accumulate. Save your most sophisticated prompt engineering for tasks where quality improvements truly matter.\n",
    "\n",
    "Finally, remember that **AI models continue evolving** üöÄ. Today's models behave differently than those from six months ago, and tomorrow's models will be different still. Prompt engineering techniques that are essential now might become less important as models improve, or new techniques might emerge. Stay curious, keep experimenting, and be willing to adapt your approach as the technology evolves. The principles‚Äî**clarity, specificity, appropriate technique selection**‚Äîremain constant even as specific tactics change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed this introduction to prompt engineering! You now understand:\n",
    "\n",
    "‚úÖ How **temperature** üå°Ô∏è and **tokens** üé´ affect model behavior and costs  \n",
    "‚úÖ Six tactics for writing clearer instructions üìù  \n",
    "‚úÖ How to ground responses in reference text üìö  \n",
    "‚úÖ When and how to use **few-shot prompting** üéØ  \n",
    "‚úÖ **Chain-of-thought** üßÆ for transparent reasoning  \n",
    "‚úÖ **Self-ask** üîç for complex question decomposition  \n",
    "‚úÖ How to choose and combine techniques effectively üé®  \n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "Practice is essential! Take these techniques and apply them to your own use cases. Start simple, experiment with different approaches, and build your intuition for what works when. Prompt engineering is a skill that develops through hands-on experience.\n",
    "\n",
    "**Happy prompting!** üéä‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
