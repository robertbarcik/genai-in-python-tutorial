{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Generating Knowledge Base Articles from Support Tickets\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you'll learn how to:\n",
    "- Transform messy support ticket notes into professional knowledge base articles\n",
    "- Use OpenAI's API to automate documentation creation\n",
    "- Validate and quality-check generated content\n",
    "- Generate multiple formats (KB articles, runbooks, email templates) from the same source\n",
    "- Track and optimize API costs\n",
    "\n",
    "## The Business Problem\n",
    "\n",
    "Support teams face a recurring challenge:\n",
    "\n",
    "**üî¥ The Problem:**\n",
    "- Support agents solve the same issues repeatedly\n",
    "- Knowledge is trapped in ticket notes (messy, inconsistent, full of jargon)\n",
    "- Ticket notes are written for technicians, not end-users\n",
    "- Users can't self-serve, creating high ticket volume\n",
    "- Manual KB article writing is time-consuming and often gets deprioritized\n",
    "\n",
    "**üü¢ The Solution:**\n",
    "- LLMs can transform technical ticket notes into polished, user-friendly guides\n",
    "- Automated generation makes it feasible to document every common issue\n",
    "- Users get self-service resources, reducing ticket volume\n",
    "- Support teams can focus on complex issues instead of repetitive ones\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Knowledge Base (KB)**: A self-service library of articles that help users solve problems independently\n",
    "- **Support Ticket**: A record of a user's issue and how it was resolved\n",
    "- **Documentation Automation**: Using AI to convert technical notes into user-friendly documentation\n",
    "\n",
    "## Cost Efficiency\n",
    "\n",
    "üí° **Key Point**: We'll use `gpt-5-nano` for all examples in this notebook. Generating one KB article typically costs ~500-800 tokens, making it very affordable to document your entire knowledge base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß Setup\n",
    "\n",
    "### Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure OpenAI API Key\n",
    "\n",
    "üí° **Two methods to set your API key:**\n",
    "1. **Recommended**: Store in Colab secrets (üîë icon in left sidebar)\n",
    "2. **Fallback**: Manual input when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key\n",
    "# Method 1: Try to get API key from Colab secrets (recommended)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úÖ API key loaded from Colab secrets\")\n",
    "except:\n",
    "    # Method 2: Manual input (fallback)\n",
    "    from getpass import getpass\n",
    "    print(\"üí° To use Colab secrets: Go to üîë (left sidebar) ‚Üí Add new secret ‚Üí Name: OPENAI_API_KEY\")\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "# Set the API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# Validate that the API key is set\n",
    "if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == \"\":\n",
    "    raise ValueError(\"‚ùå ERROR: No API key provided!\")\n",
    "\n",
    "print(\"‚úÖ Authentication configured!\")\n",
    "\n",
    "# Configure which OpenAI model to use\n",
    "OPENAI_MODEL = \"gpt-5-nano\"  # Using gpt-5-nano for cost efficiency\n",
    "print(f\"ü§ñ Selected Model: {OPENAI_MODEL}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Understanding the Problem\n",
    "\n",
    "Let's see the difference between ticket notes and knowledge base articles.\n",
    "\n",
    "### Example: Password Reset Issue\n",
    "\n",
    "**üìù TICKET NOTES (written by technician for technicians):**\n",
    "```\n",
    "User locked out. AD sync delay. Forced sync. Reset in portal. Fixed. 15min wait important.\n",
    "```\n",
    "\n",
    "**üìÑ KB ARTICLE (written for end-users):**\n",
    "\n",
    "---\n",
    "### How to Unlock Your Account After Multiple Failed Login Attempts\n",
    "\n",
    "**Problem**: You've entered your password incorrectly several times and now your account is locked.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "1. **Wait 15 minutes** - Your account will automatically unlock after 15 minutes\n",
    "2. **Don't keep trying to log in** - Additional login attempts will reset the timer\n",
    "3. **Use the password reset portal** if you've forgotten your password:\n",
    "   - Go to https://portal.company.com/reset\n",
    "   - Enter your username\n",
    "   - Follow the email instructions\n",
    "4. **Wait for synchronization** - After resetting, wait 2-3 minutes before trying to log in\n",
    "\n",
    "**‚ö†Ô∏è Common Mistakes:**\n",
    "- Trying to log in immediately after password reset (wait 2-3 minutes)\n",
    "- Continuing to attempt logins during the lockout period (this extends the lockout)\n",
    "\n",
    "**Still having issues?** Contact the helpdesk at ext. 5555\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Ticket Notes | KB Article |\n",
    "|--------------|------------|\n",
    "| Abbreviations (AD, sync) | Full terms explained |\n",
    "| Technical jargon | User-friendly language |\n",
    "| Missing steps | Complete step-by-step |\n",
    "| Assumes knowledge | Assumes no prior knowledge |\n",
    "| Quick reference | Comprehensive guide |\n",
    "\n",
    "üí° **Key Point**: LLMs bridge this gap by expanding abbreviations, adding context, structuring information, and adjusting tone for the target audience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üé≤ Mock Data Generation\n",
    "\n",
    "We'll create realistic support ticket data programmatically to simulate a real helpdesk environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_mock_tickets():\n    \"\"\"\n    Generate diverse support tickets covering common IT issues.\n    Returns a list of ticket dictionaries.\n    \"\"\"\n    tickets = [\n        {\n            \"ticket_id\": \"T001\",\n            \"category\": \"Password_Account\",\n            \"issue_summary\": \"User account locked after failed login attempts\",\n            \"short_notes\": \"User locked out. AD sync delay. Forced sync. Reset in portal. Fixed. 15min wait important.\",\n            \"solution_steps\": \"1. Wait 15min for auto-unlock 2. Use reset portal 3. Wait 2-3min after reset 4. Try login\",\n            \"common_mistakes\": \"Trying login immediately after reset, Multiple attempts during lockout\",\n            \"keywords\": \"account locked, password reset, login failed, AD sync\"\n        },\n        {\n            \"ticket_id\": \"T002\",\n            \"category\": \"VPN_Remote_Access\",\n            \"issue_summary\": \"VPN client won't connect from home\",\n            \"short_notes\": \"VPN stuck connecting. FW blocking port 443. Changed to port 1194. Works now. Check router settings.\",\n            \"solution_steps\": \"1. Open VPN client 2. Settings > Advanced 3. Change port 443 to 1194 4. Reconnect 5. Check router FW if still fails\",\n            \"common_mistakes\": \"Not restarting VPN after settings change, Home router blocking VPN ports\",\n            \"keywords\": \"VPN connection, remote access, firewall, port blocking\"\n        },\n        {\n            \"ticket_id\": \"T003\",\n            \"category\": \"Email_Outlook\",\n            \"issue_summary\": \"Outlook not syncing emails on mobile device\",\n            \"short_notes\": \"Mobile not syncing. Cache issue. Removed acct, re-added. Modern auth required. Works.\",\n            \"solution_steps\": \"1. Remove email account 2. Clear Outlook cache 3. Re-add account 4. Enable modern auth when prompted\",\n            \"common_mistakes\": \"Not clearing cache before re-adding, Using old password\",\n            \"keywords\": \"Outlook mobile, email sync, modern authentication, cache\"\n        },\n        {\n            \"ticket_id\": \"T004\",\n            \"category\": \"Printing\",\n            \"issue_summary\": \"Printer shows offline but is powered on\",\n            \"short_notes\": \"Printer offline. IP conflict. Released old lease. Renewed DHCP. Reset print spooler. Fixed.\",\n            \"solution_steps\": \"1. Check printer IP 2. Release/renew DHCP 3. Restart print spooler service 4. Re-add printer if needed\",\n            \"common_mistakes\": \"Not checking IP conflict, Wrong printer driver\",\n            \"keywords\": \"printer offline, IP conflict, DHCP, print spooler\"\n        },\n        {\n            \"ticket_id\": \"T005\",\n            \"category\": \"Software_Installation\",\n            \"issue_summary\": \"Software installation fails with error 1603\",\n            \"short_notes\": \"Install fails. Prev version remnants. Used cleanup tool. Rebooted. Install success.\",\n            \"solution_steps\": \"1. Uninstall old version 2. Run cleanup tool 3. Reboot system 4. Install new version as admin\",\n            \"common_mistakes\": \"Not running as administrator, Skipping reboot\",\n            \"keywords\": \"installation error, error 1603, software install, cleanup\"\n        }\n    ]\n    \n    return tickets\n\n# Generate tickets\nprint(\"üé≤ Generating mock support tickets...\")\ntickets = generate_mock_tickets()\nprint(f\"‚úÖ Generated {len(tickets)} support tickets\\n\")\n\n# Save to CSV\ncsv_file = \"/content/sample_tickets.csv\"\nfieldnames = [\"ticket_id\", \"category\", \"issue_summary\", \"short_notes\", \"solution_steps\", \"common_mistakes\", \"keywords\"]\n\nwith open(csv_file, 'w', newline='', encoding='utf-8') as f:\n    writer = csv.DictWriter(f, fieldnames=fieldnames)\n    writer.writeheader()\n    writer.writerows(tickets)\n\nprint(f\"üíæ Saved tickets to: {csv_file}\\n\")\n\n# Display sample tickets\nprint(\"üìã Sample Tickets:\\n\")\nprint(\"=\" * 80)\nfor ticket in tickets[:3]:\n    print(f\"üé´ Ticket ID: {ticket['ticket_id']}\")\n    print(f\"   Category: {ticket['category']}\")\n    print(f\"   Issue: {ticket['issue_summary']}\")\n    print(f\"   Notes: {ticket['short_notes']}\")\n    print(\"=\" * 80)\n\nprint(f\"\\n‚úÖ CSV file created successfully with {len(tickets)} tickets\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Basic KB Article Generation\n",
    "\n",
    "### Part A: Generate a Single Article\n",
    "\n",
    "Let's start by generating one KB article from a ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a ticket to work with\n",
    "selected_ticket = tickets[0]  # Password/Account issue\n",
    "\n",
    "print(f\"üìã Selected Ticket: {selected_ticket['ticket_id']}\")\n",
    "print(f\"Issue: {selected_ticket['issue_summary']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create the prompt for KB article generation\ndef create_kb_prompt(ticket):\n    \"\"\"\n    Create a detailed prompt for generating a user-friendly KB article.\n    \"\"\"\n    prompt = f\"\"\"You are a technical writer creating a knowledge base article for end-users (non-technical audience).\n\nBased on this support ticket information:\n\nIssue: {ticket['issue_summary']}\nTechnician Notes: {ticket['short_notes']}\nSolution Steps: {ticket['solution_steps']}\nCommon Mistakes: {ticket['common_mistakes']}\n\nWrite a professional, user-friendly knowledge base article following these requirements:\n\n1. Start with a clear, descriptive title (use ##)\n2. Begin with a brief problem statement that reflects common user frustration\n3. Provide step-by-step instructions with clear numbering\n4. Expand all abbreviations and technical terms\n5. Add a troubleshooting section for common issues\n6. Include warnings about common mistakes users make\n7. Use placeholders like [Screenshot: description] where helpful\n8. Target length: 400-600 words (about one page)\n9. Use a professional but friendly tone\n10. End with a \"Still need help?\" section\n\nWrite the article in markdown format.\"\"\"\n    \n    return prompt\n\n# Generate the KB article\nprint(\"ü§ñ Generating KB article...\\n\")\n\nprompt = create_kb_prompt(selected_ticket)\n\n# Make API call\nresponse = client.responses.create(\n    model=OPENAI_MODEL,\n    input=prompt,\n    text={\n        \"verbosity\": \"medium\",\n        \"format\": {\"type\": \"text\"}\n    },\n    reasoning={\n        \"effort\": \"minimal\"\n    }\n)\n\nkb_article = response.output_text\ntokens_used = response.usage.input_tokens + response.usage.output_tokens\n\nprint(\"‚úÖ Article generated!\\n\")\nprint(f\"üìä Tokens used: {tokens_used}\\n\")\nprint(\"=\" * 80)\nprint(kb_article)\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the article to a file\n",
    "os.makedirs(\"/content/kb_articles\", exist_ok=True)\n",
    "\n",
    "filename = f\"/content/kb_articles/KB_{selected_ticket['ticket_id']}_{selected_ticket['category']}.md\"\n",
    "\n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(kb_article)\n",
    "\n",
    "print(f\"üíæ Article saved to: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Before/After Comparison\n",
    "\n",
    "Let's see the transformation side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ TRANSFORMATION COMPARISON\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"BEFORE: Original Ticket Notes\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Ticket ID: {selected_ticket['ticket_id']}\")\n",
    "print(f\"Issue: {selected_ticket['issue_summary']}\")\n",
    "print(f\"\\nTechnician Notes:\\n{selected_ticket['short_notes']}\")\n",
    "print(f\"\\nSolution: {selected_ticket['solution_steps']}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AFTER: Generated KB Article\")\n",
    "print(\"=\" * 80)\n",
    "print(kb_article)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüí° Key Improvements:\")\n",
    "print(\"  ‚úÖ Abbreviations expanded (AD ‚Üí Active Directory)\")\n",
    "print(\"  ‚úÖ Steps clearly numbered and detailed\")\n",
    "print(\"  ‚úÖ User-friendly language (no technical jargon)\")\n",
    "print(\"  ‚úÖ Common mistakes highlighted\")\n",
    "print(\"  ‚úÖ Professional structure with troubleshooting section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîÅ Batch Processing\n",
    "\n",
    "Now let's process all tickets and generate KB articles for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def process_ticket_batch(tickets, model=OPENAI_MODEL):\n    \"\"\"\n    Process multiple tickets and generate KB articles for each.\n    \n    Args:\n        tickets: List of ticket dictionaries\n        model: OpenAI model to use\n    \n    Returns:\n        Dictionary with statistics and results\n    \"\"\"\n    results = {\n        \"total_processed\": 0,\n        \"successful\": 0,\n        \"failed\": 0,\n        \"total_tokens\": 0,\n        \"files_created\": [],\n        \"failures\": []\n    }\n    \n    # Create output directory\n    os.makedirs(\"/content/kb_articles\", exist_ok=True)\n    \n    # Process each ticket with progress bar\n    for ticket in tqdm(tickets, desc=\"Generating KB articles\"):\n        results[\"total_processed\"] += 1\n        \n        try:\n            # Create prompt\n            prompt = create_kb_prompt(ticket)\n            \n            # Make API call\n            response = client.responses.create(\n                model=model,\n                input=prompt,\n                text={\n                    \"verbosity\": \"medium\",\n                    \"format\": {\"type\": \"text\"}\n                },\n                reasoning={\n                    \"effort\": \"minimal\"\n                }\n            )\n            \n            article = response.output_text\n            tokens = response.usage.input_tokens + response.usage.output_tokens\n            results[\"total_tokens\"] += tokens\n            \n            # Save article\n            filename = f\"/content/kb_articles/KB_{ticket['ticket_id']}_{ticket['category']}.md\"\n            with open(filename, 'w', encoding='utf-8') as f:\n                f.write(article)\n            \n            results[\"successful\"] += 1\n            results[\"files_created\"].append(filename)\n            \n        except Exception as e:\n            results[\"failed\"] += 1\n            results[\"failures\"].append({\"ticket_id\": ticket['ticket_id'], \"error\": str(e)})\n            print(f\"\\n‚ùå Failed to process {ticket['ticket_id']}: {str(e)}\")\n    \n    return results\n\n# Estimate cost BEFORE processing\ntickets_to_process = tickets[:5]\navg_tokens_per_article = 600\nestimated_total_tokens = avg_tokens_per_article * len(tickets_to_process)\nestimated_cost = (estimated_total_tokens / 1_000_000) * 0.225\n\nprint(\"üí∞ COST ESTIMATE (before processing):\")\nprint(\"=\" * 80)\nprint(f\"Articles to generate: {len(tickets_to_process)}\")\nprint(f\"Estimated tokens (avg {avg_tokens_per_article} per article): {estimated_total_tokens:,}\")\nprint(f\"Estimated cost: ${estimated_cost:.4f}\")\nprint(\"=\" * 80)\nprint()\n\n# Process tickets\nprint(\"üöÄ Starting batch processing...\\n\")\nbatch_results = process_ticket_batch(tickets_to_process)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üìä BATCH PROCESSING RESULTS\")\nprint(\"=\" * 80)\nprint(f\"Total tickets processed: {batch_results['total_processed']}\")\nprint(f\"‚úÖ Successful: {batch_results['successful']}\")\nprint(f\"‚ùå Failed: {batch_results['failed']}\")\nprint(f\"üéØ Total tokens used: {batch_results['total_tokens']}\")\nprint(f\"üí∞ Average tokens per article: {batch_results['total_tokens'] // batch_results['successful'] if batch_results['successful'] > 0 else 0}\")\n\n# Actual cost\nactual_cost = (batch_results['total_tokens'] / 1_000_000) * 0.225\nprint(f\"üíµ Actual cost: ${actual_cost:.4f}\")\n\nprint(\"\\nüìÅ Files created:\")\nfor file in batch_results['files_created']:\n    print(f\"  ‚úÖ {file}\")\n\nif batch_results['failures']:\n    print(\"\\n‚ö†Ô∏è Failures:\")\n    for failure in batch_results['failures']:\n        print(f\"  ‚ùå {failure['ticket_id']}: {failure['error']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an index file listing all articles\n",
    "index_content = \"# Knowledge Base Article Index\\n\\n\"\n",
    "index_content += f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
    "index_content += f\"Total articles: {batch_results['successful']}\\n\\n\"\n",
    "index_content += \"## Articles by Category\\n\\n\"\n",
    "\n",
    "# Group by category\n",
    "categories = {}\n",
    "for ticket in tickets:\n",
    "    category = ticket['category']\n",
    "    if category not in categories:\n",
    "        categories[category] = []\n",
    "    categories[category].append(ticket)\n",
    "\n",
    "# Write index\n",
    "for category, cat_tickets in sorted(categories.items()):\n",
    "    index_content += f\"### {category.replace('_', ' ')}\\n\\n\"\n",
    "    for ticket in cat_tickets:\n",
    "        filename = f\"KB_{ticket['ticket_id']}_{ticket['category']}.md\"\n",
    "        index_content += f\"- [{ticket['issue_summary']}]({filename})\\n\"\n",
    "    index_content += \"\\n\"\n",
    "\n",
    "# Save index\n",
    "with open(\"/content/kb_articles/index.md\", 'w', encoding='utf-8') as f:\n",
    "    f.write(index_content)\n",
    "\n",
    "print(\"‚úÖ Created index file: /content/kb_articles/index.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Quality Checks\n",
    "\n",
    "Before publishing KB articles, we need to validate they meet minimum quality standards.\n",
    "\n",
    "### Theory: Why Validate?\n",
    "\n",
    "LLMs are powerful but not perfect. They can:\n",
    "- Generate articles that are too short or too verbose\n",
    "- Miss important sections\n",
    "- Use overly technical language\n",
    "- Hallucinate information\n",
    "\n",
    "Basic validation catches these issues before users see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check_article_length(article_text):\n",
    "    \"\"\"\n",
    "    Check 1: Validate article length (300-700 words)\n",
    "    \"\"\"\n",
    "    words = article_text.split()\n",
    "    word_count = len(words)\n",
    "    \n",
    "    status = \"‚úÖ PASS\"\n",
    "    if word_count < 300:\n",
    "        status = \"‚ùå FAIL: Too short\"\n",
    "    elif word_count > 700:\n",
    "        status = \"‚ö†Ô∏è WARNING: Too long\"\n",
    "    \n",
    "    return {\n",
    "        \"check\": \"Length Validation\",\n",
    "        \"word_count\": word_count,\n",
    "        \"status\": status,\n",
    "        \"details\": f\"{word_count} words (target: 300-700)\"\n",
    "    }\n",
    "\n",
    "def check_article_structure(article_text):\n",
    "    \"\"\"\n",
    "    Check 2: Validate article has required sections\n",
    "    \"\"\"\n",
    "    checks = {\n",
    "        \"has_title\": bool(re.search(r'^#{1,3}\\s+.+', article_text, re.MULTILINE)),\n",
    "        \"has_numbered_steps\": bool(re.search(r'^\\d+\\.\\s+', article_text, re.MULTILINE)),\n",
    "        \"has_problem_statement\": bool(re.search(r'(problem|issue|symptom):', article_text, re.IGNORECASE)),\n",
    "        \"has_troubleshooting\": bool(re.search(r'(troubleshoot|common (mistake|issue|problem)|still (having|need))', article_text, re.IGNORECASE))\n",
    "    }\n",
    "    \n",
    "    missing = [k.replace('has_', '').replace('_', ' ').title() for k, v in checks.items() if not v]\n",
    "    \n",
    "    status = \"‚úÖ PASS\" if not missing else f\"‚ö†Ô∏è WARNING: Missing {len(missing)} section(s)\"\n",
    "    \n",
    "    return {\n",
    "        \"check\": \"Structure Validation\",\n",
    "        \"status\": status,\n",
    "        \"sections_found\": sum(checks.values()),\n",
    "        \"sections_missing\": missing,\n",
    "        \"details\": f\"{sum(checks.values())}/4 required sections found\"\n",
    "    }\n",
    "\n",
    "def check_readability(article_text):\n",
    "    \"\"\"\n",
    "    Check 3: Basic readability checks\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'[.!?]+', article_text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    # Calculate average sentence length\n",
    "    words = article_text.split()\n",
    "    avg_sentence_length = len(words) / len(sentences) if sentences else 0\n",
    "    \n",
    "    # Check for action verbs (good for instructions)\n",
    "    action_verbs = ['click', 'open', 'navigate', 'select', 'enter', 'type', 'go to', 'press', 'check']\n",
    "    has_action_verbs = any(verb in article_text.lower() for verb in action_verbs)\n",
    "    \n",
    "    # Check for excessive technical jargon (basic check)\n",
    "    tech_terms = ['API', 'DNS', 'DHCP', 'LDAP', 'SQL', 'regex', 'backend', 'frontend']\n",
    "    jargon_count = sum(1 for term in tech_terms if term in article_text)\n",
    "    jargon_density = jargon_count / len(words) * 100 if words else 0\n",
    "    \n",
    "    issues = []\n",
    "    if avg_sentence_length > 25:\n",
    "        issues.append(\"Long sentences\")\n",
    "    if not has_action_verbs:\n",
    "        issues.append(\"Missing action verbs\")\n",
    "    if jargon_density > 2:\n",
    "        issues.append(\"High jargon density\")\n",
    "    \n",
    "    status = \"‚úÖ PASS\" if not issues else f\"‚ö†Ô∏è WARNING: {', '.join(issues)}\"\n",
    "    \n",
    "    return {\n",
    "        \"check\": \"Readability Check\",\n",
    "        \"status\": status,\n",
    "        \"avg_sentence_length\": round(avg_sentence_length, 1),\n",
    "        \"has_action_verbs\": has_action_verbs,\n",
    "        \"jargon_density\": round(jargon_density, 2),\n",
    "        \"details\": f\"Avg sentence: {round(avg_sentence_length, 1)} words, Jargon: {round(jargon_density, 2)}%\"\n",
    "    }\n",
    "\n",
    "def validate_article(article_text, ticket_id):\n",
    "    \"\"\"\n",
    "    Run all validation checks on an article\n",
    "    \"\"\"\n",
    "    validations = {\n",
    "        \"ticket_id\": ticket_id,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"checks\": [\n",
    "            check_article_length(article_text),\n",
    "            check_article_structure(article_text),\n",
    "            check_readability(article_text)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Overall status\n",
    "    fail_count = sum(1 for check in validations['checks'] if 'FAIL' in check['status'])\n",
    "    warning_count = sum(1 for check in validations['checks'] if 'WARNING' in check['status'])\n",
    "    \n",
    "    if fail_count > 0:\n",
    "        validations['overall_status'] = \"‚ùå FAILED\"\n",
    "    elif warning_count > 0:\n",
    "        validations['overall_status'] = \"‚ö†Ô∏è NEEDS REVIEW\"\n",
    "    else:\n",
    "        validations['overall_status'] = \"‚úÖ PASSED\"\n",
    "    \n",
    "    return validations\n",
    "\n",
    "print(\"üîç Running quality checks on generated articles...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate a few sample articles\n",
    "validation_reports = []\n",
    "\n",
    "# Select 3 articles to validate\n",
    "articles_to_validate = tickets[:3]\n",
    "\n",
    "for ticket in articles_to_validate:\n",
    "    filename = f\"/content/kb_articles/KB_{ticket['ticket_id']}_{ticket['category']}.md\"\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            article_text = f.read()\n",
    "        \n",
    "        validation = validate_article(article_text, ticket['ticket_id'])\n",
    "        validation_reports.append(validation)\n",
    "        \n",
    "        # Print report\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"üìÑ Article: {ticket['ticket_id']} - {ticket['issue_summary']}\")\n",
    "        print(f\"Overall Status: {validation['overall_status']}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for check in validation['checks']:\n",
    "            print(f\"\\n{check['check']}: {check['status']}\")\n",
    "            print(f\"  Details: {check['details']}\")\n",
    "        \n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File not found: {filename}\\n\")\n",
    "\n",
    "# Save validation report\n",
    "report_file = \"/content/validation_report.json\"\n",
    "with open(report_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(validation_reports, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Validation report saved to: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üé® Enhancement: Multi-Format Generation\n",
    "\n",
    "The same ticket can be transformed into different formats for different audiences:\n",
    "- **End-User KB Article**: Simple, patient, step-by-step\n",
    "- **Internal Runbook**: Technical, for support staff\n",
    "- **Email Template**: Concise response to send to users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create output directory for different formats\nos.makedirs(\"/content/formats\", exist_ok=True)\n\n# Select a ticket for multi-format generation\ndemo_ticket = tickets[1]  # VPN issue\n\nprint(f\"üéØ Generating multiple formats for: {demo_ticket['issue_summary']}\\n\")\n\n# Format 1: End-User KB Article\nkb_prompt = f\"\"\"Create a user-friendly knowledge base article for end-users about:\n\nIssue: {demo_ticket['issue_summary']}\nTechnical Notes: {demo_ticket['short_notes']}\nSolution: {demo_ticket['solution_steps']}\n\nWrite in simple language, include step-by-step instructions, and use a patient, helpful tone.\nTarget length: ~500 words.\"\"\"\n\n# Format 2: Internal Runbook\nrunbook_prompt = f\"\"\"Create a technical runbook for support staff about:\n\nIssue: {demo_ticket['issue_summary']}\nNotes: {demo_ticket['short_notes']}\nSolution: {demo_ticket['solution_steps']}\nCommon Mistakes: {demo_ticket['common_mistakes']}\n\nInclude technical details, troubleshooting commands, root cause analysis.\nUse technical language appropriate for IT support staff.\nTarget length: ~400 words.\"\"\"\n\n# Format 3: Email Template\nemail_prompt = f\"\"\"Create a concise email template to send to a user who reported:\n\nIssue: {demo_ticket['issue_summary']}\nSolution: {demo_ticket['solution_steps']}\n\nWrite a professional, friendly email that:\n- Acknowledges their issue\n- Provides clear steps to resolve\n- Offers further assistance\nTarget length: ~150 words.\"\"\"\n\nprompts = {\n    \"kb_article\": kb_prompt,\n    \"runbook\": runbook_prompt,\n    \"email_template\": email_prompt\n}\n\ngenerated_formats = {}\n\n# Generate all three formats\nfor format_type, prompt in prompts.items():\n    print(f\"üìù Generating {format_type.replace('_', ' ')}...\")\n    \n    response = client.responses.create(\n        model=OPENAI_MODEL,\n        input=prompt,\n        text={\n        \"verbosity\": \"medium\",\n        \"format\": {\"type\": \"text\"}\n    },\n    reasoning={\n        \"effort\": \"minimal\"\n    }\n    )\n    \n    content = response.output_text\n    generated_formats[format_type] = content\n    \n    # Save to file\n    filename = f\"/content/formats/{format_type}_{demo_ticket['ticket_id']}.md\"\n    with open(filename, 'w', encoding='utf-8') as f:\n        f.write(content)\n    \n    print(f\"  ‚úÖ Saved to {filename}\")\n\nprint(\"\\n‚úÖ All formats generated!\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all three formats side-by-side\n",
    "print(\"üìä MULTI-FORMAT COMPARISON\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for format_type, content in generated_formats.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FORMAT: {format_type.replace('_', ' ').upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(content)\n",
    "    print(f\"\\nWord count: {len(content.split())} words\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nüí° Key Insight: Same source data ‚Üí Different outputs based on audience and purpose!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üí∞ Cost Tracking & Optimization\n",
    "\n",
    "Let's analyze the costs and explore optimization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_generation_cost(total_tokens, model=\"gpt-5-nano\"):\n",
    "    \"\"\"\n",
    "    Calculate costs based on token usage.\n",
    "    \n",
    "    Note: Adjust pricing based on actual model costs.\n",
    "    Example pricing used here (fictional):\n",
    "    - gpt-5-nano: $0.0001 per 1K tokens\n",
    "    \"\"\"\n",
    "    # Pricing per 1K tokens (example rates)\n",
    "    pricing = {\n",
    "        \"gpt-5-nano\": 0.0001,\n",
    "        \"gpt-4\": 0.03,  # For comparison\n",
    "        \"gpt-3.5-turbo\": 0.002  # For comparison\n",
    "    }\n",
    "    \n",
    "    rate = pricing.get(model, 0.0001)\n",
    "    cost = (total_tokens / 1000) * rate\n",
    "    \n",
    "    return cost\n",
    "\n",
    "# Calculate costs for our batch processing\n",
    "total_tokens = batch_results['total_tokens']\n",
    "articles_generated = batch_results['successful']\n",
    "\n",
    "print(\"üí∞ COST ANALYSIS\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total articles generated: {articles_generated}\")\n",
    "print(f\"Total tokens used: {total_tokens:,}\")\n",
    "print(f\"Average tokens per article: {total_tokens // articles_generated if articles_generated > 0 else 0}\")\n",
    "print(\"\\nCost with gpt-5-nano:\")\n",
    "nano_cost = track_generation_cost(total_tokens, \"gpt-5-nano\")\n",
    "print(f\"  ${nano_cost:.4f}\")\n",
    "print(f\"  (${nano_cost/articles_generated:.6f} per article)\" if articles_generated > 0 else \"\")\n",
    "\n",
    "# Show comparison with other models\n",
    "print(\"\\nüìä Cost Comparison (for same token usage):\")\n",
    "for model in [\"gpt-5-nano\", \"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "    cost = track_generation_cost(total_tokens, model)\n",
    "    print(f\"  {model:20} ${cost:.4f}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost projection for larger scale\n",
    "print(\"\\nüìà COST PROJECTION\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "avg_tokens = total_tokens // articles_generated if articles_generated > 0 else 600\n",
    "scales = [50, 100, 500, 1000]\n",
    "\n",
    "print(f\"Assuming {avg_tokens} tokens per article:\\n\")\n",
    "print(f\"{'Articles':<15} {'Total Tokens':<20} {'Cost (gpt-5-nano)'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for scale in scales:\n",
    "    projected_tokens = avg_tokens * scale\n",
    "    projected_cost = track_generation_cost(projected_tokens, \"gpt-5-nano\")\n",
    "    print(f\"{scale:<15} {projected_tokens:<20,} ${projected_cost:.2f}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Cost Optimization Tips\n",
    "\n",
    "1. **Use the right model**: `gpt-5-nano` is perfect for draft generation (20-30x cheaper than GPT-4)\n",
    "2. **Set appropriate max_tokens**: Avoid over-generation by setting realistic limits (800 for ~500 words)\n",
    "3. **Batch processing**: Process during off-peak hours if you have high volume\n",
    "4. **Cache common sections**: Store and reuse troubleshooting templates when applicable\n",
    "5. **Filter before generating**: Only generate articles for frequently occurring issues\n",
    "6. **Progressive enhancement**: Generate basic articles with gpt-5-nano, use GPT-4 only for critical/complex topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö Best Practices & Key Takeaways\n",
    "\n",
    "### Best Practices Summary\n",
    "\n",
    "‚úÖ **Do:**\n",
    "- Keep articles focused (one issue per article)\n",
    "- Validate article quality before publishing\n",
    "- Use consistent naming for easy organization\n",
    "- Track generation costs for budgeting\n",
    "- Review generated content before making public\n",
    "- Update articles as solutions evolve\n",
    "- Include screenshots or placeholders for visuals\n",
    "- Test instructions yourself before publishing\n",
    "\n",
    "‚ö†Ô∏è **Review Carefully:**\n",
    "- Security-sensitive procedures (password resets, access controls)\n",
    "- Complex, multi-system issues\n",
    "- Compliance-related documentation\n",
    "- Instructions involving user data\n",
    "\n",
    "‚ùå **Not Suitable For:**\n",
    "- Issues requiring case-by-case judgment\n",
    "- Problems without established solutions\n",
    "- Highly variable scenarios\n",
    "- Emergency procedures (require human oversight)\n",
    "\n",
    "### When to Use This Approach\n",
    "\n",
    "‚úÖ **Good for:**\n",
    "- Common, repetitive issues with established solutions\n",
    "- Creating documentation backlog quickly\n",
    "- Standardizing support responses\n",
    "- Onboarding documentation\n",
    "- User guides for new software rollouts\n",
    "- Converting tribal knowledge to documented procedures\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "1. **Building Self-Service Knowledge Base**: Process historical tickets to create comprehensive KB\n",
    "2. **New Software Rollouts**: Generate user guides from testing notes\n",
    "3. **Onboarding Documentation**: Convert training materials into searchable guides\n",
    "4. **Knowledge Preservation**: Document departing employees' expertise\n",
    "5. **Multi-Language Support**: Generate articles in multiple languages\n",
    "6. **Runbook Creation**: Create internal procedures for support teams\n",
    "\n",
    "### Key Metrics to Track\n",
    "\n",
    "- üìä Ticket deflection rate (% of users finding solutions in KB)\n",
    "- üìà Article usage (views, helpfulness ratings)\n",
    "- üí∞ Cost per article generated\n",
    "- ‚è±Ô∏è Time saved vs manual writing\n",
    "- ‚úÖ Article quality scores\n",
    "- üîÑ Update frequency needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Student Exercises\n",
    "\n",
    "Practice what you've learned with these hands-on exercises!\n",
    "\n",
    "### Exercise 1: Add New Ticket Categories\n",
    "\n",
    "**Task**: Create 5 new tickets for a new category (e.g., \"Mobile Device Setup\"), generate KB articles, and validate quality.\n",
    "\n",
    "**Steps**:\n",
    "1. Create a function that generates 5 tickets for mobile device issues\n",
    "2. Add them to the ticket list\n",
    "3. Generate KB articles for each\n",
    "4. Run validation checks\n",
    "5. Review articles that need improvement\n",
    "\n",
    "**Bonus**: Calculate the cost and compare it to manual writing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# TODO: Create function to generate mobile device setup tickets\n",
    "# TODO: Generate KB articles\n",
    "# TODO: Validate articles\n",
    "# TODO: Calculate costs\n",
    "\n",
    "def generate_mobile_device_tickets():\n",
    "    \"\"\"\n",
    "    Generate 5 tickets related to mobile device setup/issues.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# mobile_tickets = generate_mobile_device_tickets()\n",
    "# print(f\"Created {len(mobile_tickets)} mobile device tickets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create Multi-Language Support\n",
    "\n",
    "**Task**: Modify the prompt to generate the same article in two languages (e.g., English and Spanish).\n",
    "\n",
    "**Steps**:\n",
    "1. Select one ticket\n",
    "2. Create prompts for generating in English and Spanish\n",
    "3. Generate both versions\n",
    "4. Save with language identifiers (e.g., `KB_T001_en.md`, `KB_T001_es.md`)\n",
    "5. Compare token usage between languages\n",
    "\n",
    "**Bonus**: Create a function that generates articles in any specified language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "# TODO: Create multi-language generation function\n",
    "# TODO: Generate articles in English and Spanish\n",
    "# TODO: Compare token usage\n",
    "\n",
    "def generate_multilingual_article(ticket, languages=['en', 'es']):\n",
    "    \"\"\"\n",
    "    Generate KB article in multiple languages.\n",
    "    \n",
    "    Args:\n",
    "        ticket: Ticket dictionary\n",
    "        languages: List of language codes (e.g., ['en', 'es', 'fr'])\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with language codes as keys and articles as values\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# articles = generate_multilingual_article(tickets[0], ['en', 'es'])\n",
    "# print(f\"Generated articles in {len(articles)} languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Build Article Update System\n",
    "\n",
    "**Task**: Create a system that takes an existing article and ticket updates, then regenerates the article incorporating new information.\n",
    "\n",
    "**Steps**:\n",
    "1. Load an existing KB article\n",
    "2. Create \"update\" information (e.g., new troubleshooting step)\n",
    "3. Generate a prompt that includes the existing article and updates\n",
    "4. Regenerate the article\n",
    "5. Compare old vs new versions to see what changed\n",
    "6. Track token usage for updates vs fresh generation\n",
    "\n",
    "**Bonus**: Create a diff view showing exactly what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "# TODO: Create article update function\n",
    "# TODO: Load existing article\n",
    "# TODO: Generate updated version\n",
    "# TODO: Compare versions\n",
    "\n",
    "def update_kb_article(article_path, updates, ticket_info):\n",
    "    \"\"\"\n",
    "    Update an existing KB article with new information.\n",
    "    \n",
    "    Args:\n",
    "        article_path: Path to existing article\n",
    "        updates: Dictionary with update information\n",
    "        ticket_info: Original ticket information\n",
    "    \n",
    "    Returns:\n",
    "        Updated article text and change summary\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# Example update:\n",
    "# updates = {\n",
    "#     \"new_steps\": \"Step 5: If issue persists, check for Windows updates\",\n",
    "#     \"new_troubleshooting\": \"Some users report success after disabling antivirus temporarily\"\n",
    "# }\n",
    "# updated_article = update_kb_article(\"/content/kb_articles/KB_T001_Password_Account.md\", updates, tickets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've learned how to:\n",
    "- ‚úÖ Transform support tickets into professional KB articles\n",
    "- ‚úÖ Automate documentation creation at scale\n",
    "- ‚úÖ Validate content quality\n",
    "- ‚úÖ Generate multiple formats for different audiences\n",
    "- ‚úÖ Track and optimize API costs\n",
    "- ‚úÖ Implement best practices for AI-generated documentation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Try with real data**: Use actual support tickets from your organization\n",
    "2. **Customize validation**: Add checks specific to your quality standards\n",
    "3. **Integrate with systems**: Connect to ticket systems (Zendesk, ServiceNow, etc.)\n",
    "4. **Add human review workflow**: Implement approval process before publishing\n",
    "5. **Track metrics**: Measure ticket deflection and user satisfaction\n",
    "6. **Iterate prompts**: Refine prompts based on feedback\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- OpenAI API Documentation: https://platform.openai.com/docs\n",
    "- Prompt Engineering Guide: https://platform.openai.com/docs/guides/prompt-engineering\n",
    "- Token Usage Optimization: https://platform.openai.com/docs/guides/tokens\n",
    "\n",
    "---\n",
    "\n",
    "**Happy documenting! üìö‚ú®**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}